<html>
<head>
<title>Checking it’s all in Place: Placeholders and Dependent Types</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">检查是否全部到位:占位符和依赖类型</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/checking-its-all-in-place-placeholders-and-dependent-types-1dc60e153335?source=collection_archive---------19-----------------------#2017-09-18">https://medium.com/hackernoon/checking-its-all-in-place-placeholders-and-dependent-types-1dc60e153335?source=collection_archive---------19-----------------------#2017-09-18</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="87f2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">上周，我们进入了依赖型的世界。我们把张量和它们在字体层次上的形状联系起来。这给了我们的程序一些额外的类型安全，并允许我们避免某些运行时错误。</p><p id="18af" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">本周，我们将解决另一个运行时难题:缺少占位符。我们将添加一些更依赖类型的机器，以确保我们已经插入了所有必要的占位符！但是我们会看到这不像形状那么简单。</p><p id="5aa1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了理解本文中的代码，请看一下我的Haskell Tensor Flow Github存储库中的<a class="ae jp" href="https://github.com/jhb563/HTensor/tree/dependent-placeholders" rel="noopener ugc nofollow" target="_blank">这个分支</a>！本文所有代码都在<a class="ae jp" href="https://github.com/jhb563/HTensor/blob/dependent-placeholders/src/DepShape.hs" rel="noopener ugc nofollow" target="_blank"> DepShape.hs </a>中。像往常一样，我在文章的底部列出了必要的编译器扩展和导入。如果你想自己运行代码，你必须先运行Haskell和Tensor Flow。看看我们的<a class="ae jp" href="https://www.mmhaskell.com/tensorflow" rel="noopener ugc nofollow" target="_blank"> Haskell张量流</a>指南！</p><p id="2fb5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在开始，让我们提醒自己张量流中的占位符是什么，以及我们如何使用它们。</p><h1 id="b49d" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">占位符审核</h1><p id="7c05" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">占位符表示在不同的应用程序运行中可能具有不同值的张量。当我们对不同的数据样本进行训练时，经常会出现这种情况。这是我们用Python写的一个非常简单的例子。我们将创建一对占位符张量，只提供它们的形状，不提供值。然后当我们实际运行这个会话时，我们将为这些张量中的每一个提供一个值。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="6735" class="lc jr hu ky b fv ld le l lf lg">node1 = tf.placeholder(tf.float32)<br/>node2 = tf.placeholder(tf.float32)<br/>adderNode = tf.add(node1, node2)<br/>sess = tf.Session()<br/>result1 = sess.run(adderNode, {node1: 3, node2: 4.5 })</span></pre><p id="83ac" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这里的缺点是没有任何东西强迫我们为那些张量提供值！我们可以尝试在没有它们的情况下运行我们的程序，但我们会遇到运行时崩溃:</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="e460" class="lc jr hu ky b fv ld le l lf lg">...<br/>sess = tf.Session()<br/>result1 = sess.run(adderNode)<br/>print(result1)<br/>…</span><span id="b84f" class="lc jr hu ky b fv lh le l lf lg">Terminal Output:</span><span id="00f6" class="lc jr hu ky b fv lh le l lf lg">InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float<br/>   [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device="/job:localhost/replica:0/task:0/cpu:0"]()]]</span></pre><p id="2b3f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">不幸的是，Haskell张量流库在这里实际上并没有做得更好。当我们想要填充占位符时，我们提供一个“提要”列表。但是我们的程序仍然会编译，即使我们传递一个空列表！我们会遇到类似的运行时错误:</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="b36c" class="lc jr hu ky b fv ld le l lf lg">(node1 :: Tensor Value Float) &lt;- placeholder [1]<br/>(node2 :: Tensor Value Float) &lt;- placeholder [1]<br/>let adderNode = node1 `add` node2<br/>let runStep = \node1Feed node2Feed -&gt; runWithFeeds [] adderNode<br/>runStep (encodeTensorData [1] input1) (encodeTensorData [1] input2)<br/>…</span><span id="a9b4" class="lc jr hu ky b fv lh le l lf lg">Terminal Output:</span><span id="f767" class="lc jr hu ky b fv lh le l lf lg">TensorFlowException TF_INVALID_ARGUMENT "You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [1]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]"</span></pre><p id="5632" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在<a class="ae jp" href="https://mmhaskell.com/blog/2017/8/21/digging-in-deep-solving-a-real-problem-with-haskell-tensor-flow" rel="noopener ugc nofollow" target="_blank"> Iris </a>和<a class="ae jp" href="https://mmhaskell.com/blog/2017/9/4/deeper-still-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank"> MNIST </a>的例子中，我们将对<code class="eh li lj lk ky b">runWithFeeds</code>的调用隐藏在我们的神经网络API中。我们只提供一个<code class="eh li lj lk ky b">Model</code>对象。这个模型对象迫使我们提供预期的输入和输出张量。所以任何使用我们模型的人都不会进行人工<code class="eh li lj lk ky b">runWithFeeds</code>呼叫。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="3796" class="lc jr hu ky b fv ld le l lf lg">data Model = Model<br/>  { train :: TensorData Float<br/>          -&gt; TensorData Int64<br/>          -&gt; Session ()<br/>  , errorRate :: TensorData Float<br/>              -&gt; TensorData Int64<br/>              -&gt; SummaryTensor<br/>              -&gt; Session (Float, ByteString)<br/>  }</span></pre><p id="2fa3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这是一个不错的解决方案！但是有趣的是，我们可以用依赖类型来挑战极限，所以让我们试试吧！</p><h1 id="ebc6" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">添加更多“安全”类型</h1><p id="32a5" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">我们要做的第一步是增加张量流的<code class="eh li lj lk ky b">TensorData</code>类型。我们希望它有像<code class="eh li lj lk ky b">SafeTensor</code>和<code class="eh li lj lk ky b">SafeShape</code>的形状信息。但是我们还会给每条数据附加一个名称。这将允许我们确定用哪个张量来代替数据。在类型级别，我们将这个名称称为<code class="eh li lj lk ky b">Symbol</code>。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="6109" class="lc jr hu ky b fv ld le l lf lg">data SafeTensorData a (n :: Symbol) (s :: [Nat]) where<br/>  SafeTensorData :: (TensorType a) =&gt; TensorData a -&gt; SafeTensorData a n s</span></pre><p id="e856" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">接下来，我们需要对我们的<code class="eh li lj lk ky b">SafeTensor</code>类型做一些改变。首先，每个<code class="eh li lj lk ky b">SafeTensor</code>将获得一个新的类型参数。此参数指的是名称(符号)到形状(仍然是自然列表)的映射。我们称之为占位符列表。所以每个张量都有它所依赖的占位符的类型级信息。每个不同的占位符都有一个名称和一个形状。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="9f6c" class="lc jr hu ky b fv ld le l lf lg">data SafeTensor v a (s :: [Nat]) (p :: [(Symbol, [Nat])]) where<br/>  SafeTensor :: (TensorType a) =&gt; Tensor v a -&gt; SafeTensor v a s p</span></pre><p id="b5df" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在，回想一下当我们替换占位符时，我们使用了提要列表。但是这个列表没有关于其提要的名称或维度的信息。让我们创建一个新的类型，包含提要所需的不同元素。它还应该包含关于占位符列表的正确类型信息。定义类型的第一步，这样它就有了它所包含的占位符列表，比如<code class="eh li lj lk ky b">SafeTensor</code>。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="fe44" class="lc jr hu ky b fv ld le l lf lg">data FeedList (pl :: [(Symbol, [Nat])]) where</span></pre><p id="e27d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这个结构看起来像一个链表，就像我们的<code class="eh li lj lk ky b">SafeShape</code>。因此，我们将从定义一个“空”构造函数开始:</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="330b" class="lc jr hu ky b fv ld le l lf lg">data FeedList (pl :: [(Symbol, [Nat])]) where<br/>  EmptyFeedList :: FeedList '[]</span></pre><p id="c56b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在我们将通过创建另一个类型操作符<code class="eh li lj lk ky b">:--:</code>来添加一个类似“Cons”的构造函数。我们的链表的每个“片段”将包含两个不同的条目。首先，我们代入的张量。接下来，它将包含我们将用于替换的数据。我们可以使用类型参数来强制它们的形状和数据类型匹配。然后我们需要得到的占位符类型。我们必须将包含符号和形状的类型元组添加到前面的列表中。这就完成了我们的定义。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="70ce" class="lc jr hu ky b fv ld le l lf lg">data FeedList (pl :: [(Symbol, [Nat])]) where<br/>  EmptyFeedList :: FeedList '[]<br/>  (:--:) :: (KnownSymbol n)<br/>    =&gt; (SafeTensor Value a s p, SafeTensorData a n s) <br/>    -&gt; FeedList pl<br/>    -&gt; FeedList ( '(n, s) ': pl)</span><span id="0da5" class="lc jr hu ky b fv lh le l lf lg">infixr 5 :--:</span></pre><p id="2af6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">注意，我们强制张量是一个<code class="eh li lj lk ky b">Value</code>张量。我们只能用数据代替渲染的张量，因此有这个限制。让我们添加一个快速的<code class="eh li lj lk ky b">safeRender</code>，这样我们就可以渲染我们的<code class="eh li lj lk ky b">SafeTensor</code>项目。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="1ccb" class="lc jr hu ky b fv ld le l lf lg">safeRender :: (MonadBuild m) =&gt; SafeTensor Build a s pl -&gt; m (SafeTensor Value a s pl)<br/>safeRender (SafeTensor t1) = do<br/>  t2 &lt;- render t1<br/>  return $ SafeTensor t2</span></pre><h1 id="3539" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">制作占位符</h1><p id="d10d" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">现在我们可以编写我们的<code class="eh li lj lk ky b">safePlaceholder</code>函数了。我们将添加一个<code class="eh li lj lk ky b">KnownSymbol</code>作为类型约束。然后我们用一个<code class="eh li lj lk ky b">SafeShape</code>给我们自己形状的类型信息。结果是一个新的张量，它映射占位符列表中的符号和形状。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="9908" class="lc jr hu ky b fv ld le l lf lg">safePlaceholder :: (MonadBuild m, TensorType a, KnownSymbol sym) =&gt; <br/>  SafeShape s -&gt; m (SafeTensor Value a s '[ '(sym, s)])<br/>safePlaceholder shp = do<br/>  pl &lt;- placeholder (toShape shp)<br/>  return $ SafeTensor pl</span></pre><p id="bb70" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这看起来有点疯狂，而且有点疯狂！但是我们现在已经创建了一个张量，它在类型级别存储自己的占位符信息！</p><h1 id="7ad7" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">更新旧代码</h1><p id="61d5" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">现在我们已经这样做了，我们还必须更新一些旧的代码。第一部分非常简单。我们需要更改<code class="eh li lj lk ky b">safeConstant</code>使其具有类型信息。它将有一个空的占位符列表。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="fded" class="lc jr hu ky b fv ld le l lf lg">safeConstant :: (TensorType a, ShapeProduct s ~ n) =&gt; <br/>  Vector n a -&gt; SafeShape s -&gt; SafeTensor Build a s '[]<br/>safeConstant elems shp = SafeTensor (constant (toShape shp) (toList elems))</span></pre><p id="d434" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">不过，我们的数学运算将会有点棘手。考虑添加两个任意的张量。它们可能共享占位符依赖关系，但可能不共享。得到的张量的占位符类型应该是什么？显然是输入张量的两个占位符映射的结合！幸运的是，我们可以使用<code class="eh li lj lk ky b">type-list</code>库中的<code class="eh li lj lk ky b">Union</code>来表示这个概念。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="7974" class="lc jr hu ky b fv ld le l lf lg">safeAdd :: (TensorType a, a /= Bool, TensorKind v)<br/>  =&gt; SafeTensor v a s p1<br/>  -&gt; SafeTensor v a s p2<br/>  -&gt; SafeTensor Build a s (Union p1 p2)<br/>safeAdd (SafeTensor t1) (SafeTensor t2) = SafeTensor (t1 `add` t2)</span></pre><p id="ed76" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们将使用矩阵乘法进行同样的更新:</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="58f5" class="lc jr hu ky b fv ld le l lf lg">safeMatMul :: (TensorType a, a /= Bool, a /= Int8, a /= Int16,<br/>               a /= Int64, a /= Word8, a /= ByteString, TensorKind v)<br/>   =&gt; SafeTensor v a '[i,n] p1 -&gt; SafeTensor v a '[n,o] p2 -&gt; SafeTensor Build a '[i,o] (Union p1 p2)<br/>safeMatMul (SafeTensor t1) (SafeTensor t2) = SafeTensor (t1 `matMul` t2)</span></pre><h1 id="52ad" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">使用占位符运行</h1><p id="2a0a" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">现在我们已经有了编写<code class="eh li lj lk ky b">safeRun</code>函数所需的所有信息。这将采用<code class="eh li lj lk ky b">SafeTensor</code>，也将采用相同占位符类型的<code class="eh li lj lk ky b">FeedList</code>。记住，一个<code class="eh li lj lk ky b">FeedList</code>包含一系列<code class="eh li lj lk ky b">SafeTensorData</code>项。它们必须将符号对符号和形状对形状与<code class="eh li lj lk ky b">SafeTensor</code>中的占位符相匹配。让我们看看类型签名:</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="3e31" class="lc jr hu ky b fv ld le l lf lg">safeRun :: (TensorType a, Fetchable (Tensor v a) r) =&gt;<br/>  FeedList pl -&gt; SafeTensor v a s pl -&gt; Session r</span></pre><p id="0c93" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><code class="eh li lj lk ky b">Fetchable</code>约束强制我们实际上可以从张量中得到“结果”<code class="eh li lj lk ky b">r</code>。例如，我们可以从使用<code class="eh li lj lk ky b">Float</code>作为其基础值的张量中“提取”一个浮点向量。</p><p id="06a7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">接下来，我们将定义一个尾部递归帮助器函数来构建我们的<code class="eh li lj lk ky b">FeedList</code>的普通“提要列表”。通过模式匹配，我们可以选择要替换的张量和我们正在使用的数据。我们可以将这些合并到一个提要中，并添加到不断增长的列表中:</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="afb8" class="lc jr hu ky b fv ld le l lf lg">safeRun = ...<br/>  where<br/>    buildFeedList :: FeedList ss -&gt; [Feed] -&gt; [Feed]<br/>    buildFeedList EmptyFeedList accum = accum<br/>    buildFeedList ((SafeTensor tensor_, SafeTensorData data_) :--: rest) accum = <br/>      buildFeedList rest ((feed tensor_ data_) : accum)</span></pre><p id="fc47" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在我们要做的就是用我们创建的列表调用正常的<code class="eh li lj lk ky b">runWithFeeds</code>函数！</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="2e51" class="lc jr hu ky b fv ld le l lf lg">safeRun :: (TensorType a, Fetchable (Tensor v a) r) =&gt;<br/>  FeedList pl -&gt; SafeTensor v a s pl -&gt; Session r<br/>safeRun feeds (SafeTensor finalTensor) = runWithFeeds (buildFeedList feeds []) finalTensor<br/>  where<br/>  ...</span></pre><p id="8544" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">以下是在我们的简单示例中实际使用它的情况。请注意，类型签名确实有点麻烦。我们在初始占位符张量上的签名是必要的。否则编译器不会知道我们给了他们什么标签！包含类型联合的签名是不必要的。如果我们愿意，我们可以删除它，让类型推理来完成它的工作。</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="472a" class="lc jr hu ky b fv ld le l lf lg">main3 :: IO (VN.Vector Float)<br/>main3 = runSession $ do<br/>  let (shape1 :: SafeShape '[2,2]) = fromJust $ fromShape (Shape [2,2])<br/>  (a :: SafeTensor Value Float '[2,2] '[ '("a", '[2,2])]) &lt;- safePlaceholder shape1<br/>  (b :: SafeTensor Value Float '[2,2] '[ '("b", '[2,2])] ) &lt;- safePlaceholder shape1<br/>  let result = a `safeAdd` b<br/>  (result_ :: SafeTensor Value Float '[2,2] '[ '("b", '[2,2]), '("a", '[2,2])]) &lt;- safeRender result<br/>  let (feedA :: Vector 4 Float) = fromJust $ fromList [1,2,3,4]<br/>  let (feedB :: Vector 4 Float) = fromJust $ fromList [5,6,7,8]<br/>  let fullFeedList = (b, safeEncodeTensorData shape1 feedB) :--:<br/>                     (a, safeEncodeTensorData shape1 feedA) :--:<br/>                     EmptyFeedList<br/>  safeRun fullFeedList result_</span><span id="a592" class="lc jr hu ky b fv lh le l lf lg">{- It runs!<br/>[6.0,8.0,10.0,12.0]<br/>-}</span></pre><p id="b69b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在假设我们的类型犯了一些错误。在这里，我们将从提要列表中删除“A”提要:</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="efff" class="lc jr hu ky b fv ld le l lf lg">-- Let’s take out Feed A!<br/>main = …<br/>  let fullFeedList = (b, safeEncodeTensorData shape1 feedB) :--:<br/>                     EmptyFeedList<br/>  safeRun fullFeedList result_</span><span id="c323" class="lc jr hu ky b fv lh le l lf lg">{- Compiler Error!<br/>• Couldn't match type ‘'['("a", '[2, 2])]’ with ‘'[]’<br/>      Expected type: SafeTensor Value Float '[2, 2] '['("b", '[2, 2])]<br/>        Actual type: SafeTensor<br/>                       Value Float '[2, 2] '['("b", '[2, 2]), '("a", '[2, 2])]<br/>-}</span></pre><p id="0915" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">以下是当我们试图用错误的大小替换向量时会发生的情况。它会发现我们的元素数量不对！</p><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="a14f" class="lc jr hu ky b fv ld le l lf lg">main = …<br/>  -- Wrong Size!<br/>  let (feedA :: Vector 8 Float) = fromJust $ fromList [1,2,3,4,5,6,7,8]<br/>  let (feedB :: Vector 4 Float) = fromJust $ fromList [5,6,7,8]<br/>  let fullFeedList = (b, safeEncodeTensorData shape1 feedB) :--:<br/>                     (a, safeEncodeTensorData shape1 feedA) :--:<br/>                     EmptyFeedList<br/>  safeRun fullFeedList result_</span><span id="527a" class="lc jr hu ky b fv lh le l lf lg">{- Compiler Error!<br/>Couldn't match type ‘4’ with ‘8’<br/>        arising from a use of ‘safeEncodeTensorData’<br/>-}</span></pre><h1 id="b8ec" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">结论:赞成和反对</h1><p id="8b14" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">让我们后退一步，看看我们在这里构建了什么。我们已经设法为自己提供了一些非常酷的编译时保证。我们还在代码中添加了事实上的文档。任何熟悉代码库的人一眼就能看出每个张量需要什么占位符。现在编写不正确的代码要困难得多。当然，仍然存在错误条件。但是如果我们聪明的话，我们可以编写代码来预先处理这些问题。这样我们可以优雅地失败，而不是在某个地方抛出一个随机的运行时崩溃。</p><p id="4bc4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">但是也有缺点。想象一下，作为一个Haskell新手，走进这个代码库。你不会真正知道发生了什么(两个月前我不会知道)。过一段时间后，这些类型会变得非常麻烦，所以继续写下来会变得非常乏味。尽管我提到过，类型推理可以处理很多这样的问题。但是如果你不跟踪它们，类型联合可能会对占位符的顺序非常挑剔。不过我们可以用另一种类型的家庭来解决这个问题。</p><p id="38c3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所有这些因素都可能真正阻碍发展。但是话说回来，跟踪运行时错误也可以做到这一点。张量流的错误信息仍然有点含糊不清。这使得很难找到根本原因。</p><p id="2552" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">由于我仍然是依赖类型的新手，这段代码有点乱。下周我们将会看到一个更好的库，它使用了神经网络的依赖类型。我们将看到<a class="ae jp" href="https://github.com/HuwCampbell/grenade" rel="noopener ugc nofollow" target="_blank">手榴弹</a>库如何让我们在短短几行代码中指定一个学习系统！</p><p id="8998" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果您是Haskell的新手，我希望这种依赖型的疯狂不会吓到您！这门语言比最近几篇帖子看起来要简单得多！尝试一下，并下载我们的<a class="ae jp" href="https://www.mmhaskell.com/checklist" rel="noopener ugc nofollow" target="_blank">入门清单</a>。它会给你一些指导和工具来帮助你学习！</p><p id="15be" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你是一个有经验的Haskeller并且想尝试张量流，下载我们的<a class="ae jp" href="https://www.mmhaskell.com/tensorflow" rel="noopener ugc nofollow" target="_blank">张量流指南</a>！它将引导您将这个库合并到一个堆栈项目中！</p><h1 id="21f9" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">附录:编译器扩展和导入</h1><pre class="kt ku kv kw fq kx ky kz la aw lb dt"><span id="e871" class="lc jr hu ky b fv ld le l lf lg">{-# LANGUAGE GADTs                #-}<br/>{-# LANGUAGE DataKinds            #-}<br/>{-# LANGUAGE KindSignatures       #-}<br/>{-# LANGUAGE TypeOperators        #-}<br/>{-# LANGUAGE ScopedTypeVariables  #-}<br/>{-# LANGUAGE TypeFamilies         #-}<br/>{-# LANGUAGE FlexibleContexts     #-}<br/>{-# LANGUAGE UndecidableInstances #-}</span><span id="92ff" class="lc jr hu ky b fv lh le l lf lg">import           Data.ByteString (ByteString)<br/>import           Data.Int (Int64, Int8, Int16)<br/>import           Data.Maybe (fromJust)<br/>import           Data.Proxy (Proxy(..))<br/>import           Data.Type.List (Union)<br/>import qualified Data.Vector as VN<br/>import           Data.Vector.Sized (Vector, toList, fromList)<br/>import           Data.Word (Word8)<br/>import           GHC.TypeLits (Nat, KnownNat, natVal)<br/>import           GHC.TypeLits</span><span id="0003" class="lc jr hu ky b fv lh le l lf lg">import           TensorFlow.Core<br/>import           TensorFlow.Core (Shape(..), TensorType, Tensor, Build)<br/>import           TensorFlow.Ops (constant, add, matMul, placeholder)<br/>import           TensorFlow.Session (runSession, run)<br/>import           TensorFlow.Tensor (TensorKind)</span></pre></div></div>    
</body>
</html>