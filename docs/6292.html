<html>
<head>
<title>Mastering Python Web Scraping: Get Your Data Back</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">掌握Python Web抓取:取回您的数据</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/mastering-python-web-scraping-get-your-data-back-e9a5cc653d88?source=collection_archive---------0-----------------------#2017-09-12">https://medium.com/hackernoon/mastering-python-web-scraping-get-your-data-back-e9a5cc653d88?source=collection_archive---------0-----------------------#2017-09-12</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/f7997c120260d40001578f0ceb5ed110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vwopJ1dvp-4rZlryvkfKNg.png"/></div></div></figure><p id="44a8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你有没有发现自己处于这样一种情况，你需要从一个网站获取信息，而这个网站<em class="ka">很方便</em>没有导出选项？</p><p id="5feb" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我的一个客户就遇到过这种情况，他迫切需要一个平台的电子邮件地址列表，这个平台不允许你导出自己的数据，并把数据隐藏在一系列UI障碍之后。这位客户正准备花大价钱让一名数据录入人员手动复印每封电子邮件。幸运的是，她记得网络抓取是未来的方式，也是我最喜欢的反抗“老大哥”的方式之一。我很快(15分钟)就解决了一些问题，为她省了很多钱。我知道其他人也面临类似的问题。所以我想分享如何编写一个程序，像你一样使用网络浏览器，并取回数据！</p><p id="d0f0" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们将通过一个简单的例子来实践这一点:抓取Google搜索。抱歉，不是很有创意:)但这是一个很好的开始方式。</p><h1 id="a9c0" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">要求</h1><p id="776f" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">Python(我用的是2.7)</p><ul class=""><li id="c807" class="le lf hu je b jf jg jj jk jn lg jr lh jv li jz lj lk ll lm dt translated">碎片(基于硒)</li><li id="5e61" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz lj lk ll lm dt translated">熊猫</li></ul><p id="088d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">铬</p><p id="4fe1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ls" href="http://splinter.readthedocs.io/en/0.1.1/setup-chrome.html" rel="noopener ugc nofollow" target="_blank"> Chromedriver </a></p><p id="93e7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你没有熊猫并且很懒，我推荐你去<a class="ae ls" href="https://www.anaconda.com/download/" rel="noopener ugc nofollow" target="_blank"> Anaconda </a>获取他们的Python发行版，其中包括这个重要的&amp;超级有用的库。</p><p id="f6f7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">否则，用pip从终端/命令行下载它及其所有依赖项。<br/> <code class="eh lt lu lv lw b">pip install pandas</code></p><p id="085f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你没有Splinter(使用Anaconda的Python的<strong class="je hv">也不是</strong>，只需从终端/命令行用pip下载即可。<br/> <code class="eh lt lu lv lw b">pip install splinter</code></p><p id="ab50" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你没有Splinter(而<strong class="je hv">是</strong>用的是Anaconda的Python)，用Anaconda的包管理器从终端/命令行下载。<br/> <code class="eh lt lu lv lw b">conda install splinter</code></p><p id="1128" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你想在虚拟环境中设置它(它有很多优点)但是不知道从哪里开始，试着阅读我们关于虚拟环境的另一篇<a class="ae ls" href="https://codingstartups.com/3-best-practices-better-setting-django-project/" rel="noopener ugc nofollow" target="_blank">博客文章。</a></p><h1 id="822f" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">步骤1:库和浏览器</h1><p id="95ad" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">在这里，我们将导入我们需要的所有库，并设置一个浏览器对象。</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="36bd" class="mf kc hu lw b fv mg mh l mi mj">from splinter import Browser<br/>import pandas as pd</span><span id="95b4" class="mf kc hu lw b fv mk mh l mi mj"># open a browser<br/>browser = Browser('chrome')</span></pre><p id="f6fd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你试图抓取的页面是有响应的，使用set_window_size来确保所有你需要的元素都显示出来。</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="62c9" class="mf kc hu lw b fv mg mh l mi mj"># Width, Height<br/>browser.driver.set_window_size(640, 480)</span></pre><p id="d78a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">上面的代码将打开一个Google Chrome浏览器。既然浏览器都设置好了，那我们就访问Google吧。</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="1a92" class="mf kc hu lw b fv mg mh l mi mj">browser.visit('https://www.google.com')</span></pre><h1 id="5d5c" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">第二步:浏览网站</h1><p id="9576" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">太好了，目前我们已经上了头版。现在我们需要专注于如何浏览网站。实现这一目标有两个主要步骤:</p><ol class=""><li id="2f0e" class="le lf hu je b jf jg jj jk jn lg jr lh jv li jz ml lk ll lm dt translated">寻找某物(一个HTML元素)</li><li id="2f86" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz ml lk ll lm dt translated">对其执行操作</li></ol><p id="f516" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">要找到一个HTML元素，你需要使用Chrome开发者工具。右键点击网站，选择“检查”。这将在Chrome浏览器的右侧打开一个框。然后点击检查图标(以红色突出显示)。</p><figure class="lx ly lz ma fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mm"><img src="../Images/ca6dad25adc53ff8dba322fff9cd6fd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*a0ltDImWEuEUkhVI.png"/></div></div></figure><p id="363a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">接下来，使用检查器光标单击您想要控制的网站部分。单击后，创建该部分的HTML将在右侧突出显示。在下面的照片中，我点击了搜索栏，这是一个输入。</p><figure class="lx ly lz ma fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mm"><img src="../Images/64b92b6b720fd22a29ced463508b8eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zhAxrY5Jw0Avylh-.png"/></div></div></figure><p id="9b4f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">接下来右键单击HTML元素，并选择“复制”-&gt;“复制XPath”</p><figure class="lx ly lz ma fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mn"><img src="../Images/826c97a16f9ae01d6fd2ddf4b5761e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S04ghXcttheCa-KZ.png"/></div></div></figure><p id="3075" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">恭喜你。你现在拿到了王国的钥匙。让我们继续讨论如何使用Splinter来控制Python中HTML元素。</p><h1 id="6472" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">第三步:控制网站</h1><p id="39d0" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">XPath是最重要的信息！首先，通过粘贴到Python中的一个变量来保证XPath的安全。</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="1090" class="mf kc hu lw b fv mg mh l mi mj"># I recommend using single quotes<br/>search_bar_xpath = '//*[@id="lst-ib"]'</span></pre><p id="f067" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">接下来，我们将把这个XPath传递给Splinter Browser对象的一个伟大方法:find_by_xpath()。<strong class="je hv">这个方法将提取所有与传递给它的XPath匹配的元素，并返回一个元素对象列表。</strong>如果只有一个元素，它将返回一个长度为1的列表。还有其他方法如find_by_tag()、find_by_name()、find_by_text()等。</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="fba5" class="mf kc hu lw b fv mg mh l mi mj"># I recommend using single quotes<br/>search_bar_xpath = '//*[@id="lst-ib"]'</span><span id="c6ee" class="mf kc hu lw b fv mk mh l mi mj"># index 0 to select from the list<br/>search_bar = browser.find_by_xpath(search_bar_xpath)[0] </span></pre><p id="4f60" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">上面的代码现在为您提供了这个单独的HTML元素的导航。我使用两种有用的方法进行爬行:fill()和click()</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="267e" class="mf kc hu lw b fv mg mh l mi mj">search_bar.fill("CodingStartups.com")</span><span id="75db" class="mf kc hu lw b fv mk mh l mi mj"># Now let's set up code to click the search button!<!-- --> <!-- -->search_button_xpath = '//*[@id="tsf"]/div[2]/div[3]/center/input[1]'<!-- --> <!-- -->search_button = browser.find_by_xpath(search_button_xpath)[0]<!-- --> <!-- -->search_button.click()</span></pre><p id="7d1c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">上面的代码在搜索栏中键入CodingStartups.com，然后单击搜索按钮。一旦您执行了最后一行，您将被带到搜索结果页面！</p><p id="ec93" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">提示:使用fill()和click()导航登录页面；)</p><h1 id="2e86" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">第四步:刮！</h1><p id="d882" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">出于本练习的目的，我们将在第一页上去掉每个搜索结果的标题和链接。</p><figure class="lx ly lz ma fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mm"><img src="../Images/7971d6f4726b5631a49571b5579a10e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_ge155MIp0G-2UyW.png"/></div></div></figure><p id="2b6d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">注意，每个搜索结果都存储在带有类“r”的h3标签中。还要注意，我们想要的标题和链接都存储在a标签中。</p><p id="85a4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">突出显示的标签的XPath是:</p><p id="bd92" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">//*[@ id = " rso "]/div/div/div[1]/div/div/H3/a</p><p id="932f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">但这只是第一个环节。我们希望搜索页面上的所有链接，而不仅仅是第一个。所以我们要稍微改变一下，确保我们的find_by_xpath方法在一个列表中返回所有的搜索结果。下面是怎么做的。参见下面的代码:</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="d027" class="mf kc hu lw b fv mg mh l mi mj">search_results_xpath = '//h3[@class="r"]/a'<!-- --> # simple, right?</span><span id="7cd5" class="mf kc hu lw b fv mk mh l mi mj">search_results = browser.find_by_xpath(search_results_xpath)</span></pre><p id="abe1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这个XPath告诉Python寻找所有带有类“r”的h3标签。然后在其中的每一个里面，提取a标签&amp;它的所有数据。</p><p id="64be" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在，让我们遍历find_by_xpath方法返回的搜索结果链接元素。我们将提取每个搜索结果的标题和链接。很简单:</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="5622" class="mf kc hu lw b fv mg mh l mi mj">scraped_data = []<br/>for search_result in search_results:<br/>     title = search_result.text.encode('utf8')  # trust me<br/>     link = search_result["href"]<br/>     scraped_data.append((title, link))  # put in tuples</span></pre><p id="5edd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">清理<code class="eh lt lu lv lw b">search_result.text</code>中的数据有时是最令人沮丧的部分。网上的文字很乱。以下是一些清理数据的有用方法:</p><p id="a30f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ls" href="https://www.tutorialspoint.com/python/string_replace.htm" rel="noopener ugc nofollow" target="_blank">。替换()</a></p><p id="7d04" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ls" href="https://www.tutorialspoint.com/python/string_encode.htm" rel="noopener ugc nofollow" target="_blank">。encode() </a></p><p id="fd80" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ls" href="https://www.tutorialspoint.com/python/string_strip.htm" rel="noopener ugc nofollow" target="_blank">。strip() </a></p><p id="e904" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">所有的标题和链接现在都在scraped_data列表中。现在将我们的数据导出到csv。我喜欢使用熊猫数据框，而不是csv库混乱。只有两行:</p><pre class="lx ly lz ma fq mb lw mc md aw me dt"><span id="b3f0" class="mf kc hu lw b fv mg mh l mi mj">df = pd.DataFrame(data=scraped_data, columns=["Title", "Link"])<!-- --> <!-- -->df.to_csv("links.csv")</span></pre><p id="5327" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">上面的代码创建了一个csv文件，标题为Title、Link，然后是scraped_data列表中的所有数据。恭喜你。现在去把数据拿回来！</p><p id="a7d6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你想要一个大的图片视图，这里是我们的GitHub账户上的<a class="ae ls" href="https://github.com/CodingStartups/scraping-with-python" rel="noopener ugc nofollow" target="_blank">完整代码。</a></p><p id="8584" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">感谢阅读！如果你有问题，请随意评论&amp;我会尽量回复你。</p><figure class="lx ly lz ma fq iv fe ff paragraph-image"><div class="fe ff mo"><img src="../Images/a2693ae6881f4d0191d145a363aa8b5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*H7LHQqYm2aZtRGwSBWdjVw.jpeg"/></div></figure><p id="d67f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在Instagram上与我联系<a class="ae ls" href="https://www.instagram.com/lauren__glass/" rel="noopener ugc nofollow" target="_blank">@ Lauren _ _ glass</a>&amp;<a class="ae ls" href="https://www.linkedin.com/in/laurenjglass/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a></p><p id="4aea" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在亚马逊上查看我的<a class="ae ls" href="http://bit.ly/my_essentials" rel="noopener ugc nofollow" target="_blank">必需品清单</a></p><p id="ecb3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ls" href="https://www.laurenglass.me" rel="noopener ugc nofollow" target="_blank">访问我的网站！</a></p><figure class="lx ly lz ma fq iv fe ff paragraph-image"><div class="fe ff mp"><img src="../Images/704cab53566f8ef978de5e98726ddb63.png" data-original-src="https://miro.medium.com/v2/resize:fit:376/format:webp/1*-8d7RE-lbcOiiR1w5rP3Gw.jpeg"/></div><figcaption class="mq mr fg fe ff ms mt bd b be z ek">Search for me using my nametag on Instagram!</figcaption></figure></div></div>    
</body>
</html>