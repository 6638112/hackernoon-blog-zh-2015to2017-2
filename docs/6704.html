<html>
<head>
<title>A new kind of pooling layer for faster and sharper convergence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种新的池层，实现更快、更清晰的融合</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/a-new-kind-of-pooling-layer-for-faster-and-sharper-convergence-1043c756a221?source=collection_archive---------2-----------------------#2017-10-01">https://medium.com/hackernoon/a-new-kind-of-pooling-layer-for-faster-and-sharper-convergence-1043c756a221?source=collection_archive---------2-----------------------#2017-10-01</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="c95b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">假设有一些conv网的先验知识</p><h2 id="8cc5" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">介绍</h2><p id="9d1e" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">在最大池层(用于几乎所有的视觉任务，甚至一些NLP任务)，你丢弃了大约75%的激活。我想设计一种新的池层，消除一些与之相关的问题。</p><p id="11c4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这些问题是:</p><ol class=""><li id="4474" class="kp kq hu it b iu iv iy iz jc kr jg ks jk kt jo ku kv kw kx dt translated">空间信息的丢失。当您丢弃75%的激活时，关于这些激活来自哪里的信息就丢失了。</li><li id="1d66" class="kp kq hu it b iu ky iy kz jc la jg lb jk lc jo ku kv kw kx dt translated">最大池不能使用来自多次激活的信息。</li><li id="9cbe" class="kp kq hu it b iu ky iy kz jc la jg lb jk lc jo ku kv kw kx dt translated">反向传播只会提高最大池化激活，即使其他激活可能具有错误的值。</li></ol><p id="4572" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我想设计一种新的池层，尽可能多地解决这些问题。在这个过程中，我想出了一个非常简单的技巧来解决第二和第三个问题。</p><h2 id="36e2" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">想法和动机</h2><p id="4335" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">不是取4次激活中的最大值，而是按升序对4次激活进行排序。将它们乘以4个权重[w1，w2，w3，w4]并将这4个值相加。</p><p id="5f7d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这个想法背后的动机非常简单:</p><ol class=""><li id="f9f2" class="kp kq hu it b iu iv iy iz jc kr jg ks jk kt jo ku kv kw kx dt translated">这样，网络仍然能够<a class="ae ld" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank">学习</a>对应于[w1，w2，w3，w4] = [1，0，0，0]的良好的旧最大池。</li><li id="907a" class="kp kq hu it b iu ky iy kz jc la jg lb jk lc jo ku kv kw kx dt translated">后面的层可以访问更多的信息。因此，如果非最大激活对降低损失函数有用，网络可以学习使用其他值。</li><li id="b36e" class="kp kq hu it b iu ky iy kz jc la jg lb jk lc jo ku kv kw kx dt translated">渐变流过前一层中的所有4个值(相比之下，最大池中只有1个值)。</li></ol><p id="a777" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">因此，我的直觉是，由于这些原因，这个想法会比最大池好得多。这是一个非常罕见的DL实验，一切都如我所料。</p><h2 id="c72a" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">具体定义</h2><p id="39f2" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">设汇集前层的输出为张量T，大小为[B，H，W，C]。我定义了一个超参数pool_range，它可以是[1，2，3，4]之一。pool_range指定激活的数量(按排序顺序)。意思是给定张量T的4个激活，它们将被汇集，我首先将它们按照[a1，a2，a3，a4]的顺序排序，其中a1 ≥ a2 ≥ a3 ≥ a4。然后我保留它们中的第一个pool_range。我称这个新的载体为<strong class="it hv">激活载体</strong>。</p><p id="9478" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我定义了一个大小为pool_range [w{1}的<strong class="it hv">权重向量</strong>，....w{pool_range}]。这里需要注意的是，如果这些权重中的任何一个是负的，那么激活向量按强度排序并且我们取加权平均值的假设就不成立。因此，我没有直接使用权重，而是对权重向量取一个softmax，并将结果乘以激活向量。为了测试添加softmax的重要性，我在fuzzy-mnist数据集上进行了一个玩具实验，有和没有softmax，pool_range=3。以下是测试数据集的结果。</p><div class="le lf lg lh fq ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/e6dc28286964f262f1c0447b82210acb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*jmaEgu6akNFUkaSzRVHmfQ.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/5bc1661667de7271ab5e1720f11fe1b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Lff-sAzIqgRemWZ9KnXqwQ.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on test data for cluttered-mnist dataset</figcaption></figure></div><p id="ba9b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">显然，softmax是这里的赢家。</p><p id="d11e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我也可以对不同的通道使用不同的权重，但是为了保持与max_pooling的可比性，我在通道之间使用了相同的4个权重。</p><h2 id="c3e2" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">实施细节</h2><p id="45a6" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">我用tensorflow写这一层的代码。tensorflow的top_k层在CPU上速度很快，在GPU上速度非常慢。因此，我没有使用它，而是编写了自己的排序例程来对4个浮点数进行排序。测试sort_pool2d的代码在<a class="ae ld" href="https://github.com/singlasahil14/sortpool2d/blob/master/sortpool2d_test.py" rel="noopener ugc nofollow" target="_blank">这个文件</a>中给出。导入并使用它作为图层的代码是这个文件中的<a class="ae ld" href="https://github.com/singlasahil14/sortpool2d/blob/master/sort_pool2d.py" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="4756" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">结果</h2><p id="35af" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">我在许多不同的数据集和架构上尝试了这个想法，它在所有数据集和架构上都优于基线最大池。所有实验都是用pool_range的所有四个值来执行的:1、2、3、4。pool_range=1对应于最大池。</p><p id="0b74" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">以下是我的实验结果:</p><h2 id="db07" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">杂乱主义者和时尚主义者的玩具实验</h2><p id="e8b6" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated"><strong class="it hv">乱糟糟的人</strong></p><div class="le lf lg lh fq ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/5a5671335f62598c2ad8c381ca29d022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*UVugPIoTSIgHhAkDfQ9CBg.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/091fc5719564c2ac19e77ba833743480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*oR66gUnmsfuhuxaHr7Uwpw.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on train data for cluttered-mnist dataset</figcaption></figure></div><div class="ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/26c92d663535072a30b86ec269f878b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qD4LwUYBnWFPRbQbUPnCYA.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/2f759a83f15d0d7b9cdf71c9492ddbfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*sH2jur7RYhmW3gjCblJ_dg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on test data for cluttered-mnist dataset</figcaption></figure></div><figure class="le lf lg lh fq lj fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff mc"><img src="../Images/dbd9c8c46bfecea6545cd5d4e652fb26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*eEomXeyu7Th4j5Z_X5g-9w.png"/></div></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">Values of best accuracy and cross_entropy throughout training on test data</figcaption></figure><p id="f977" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">网络实现的训练损失和准确度是相同的，但是pool_range = 2，3，4的验证准确度远远好于标准最大池。</p><p id="3a7e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">时尚达人</strong></p><div class="le lf lg lh fq ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/349a219ce3d5211133a67a99c18df89a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Efxe6kx2n0T6ntpboUXCLg.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/6eacae4427e641fd47d50abfd0fcd42a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*4lZYT3xnAOW-1k912Lgclg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on training data for fashion-mnist dataset</figcaption></figure></div><div class="ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/273d4ed1b462bf4919581c117738afd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*rV7UBSeaXc5vOTVMAX4JUw.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/c70ce5acd501385742e88d16b368dbd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*MpXIqgAPzvVO3TQGGsKOAA.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on test data for fashion-mnist dataset</figcaption></figure></div><figure class="le lf lg lh fq lj fe ff paragraph-image"><div class="fe ff md"><img src="../Images/152d6e546d6b0a09350c4d287bdb3b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*6MjVa3GpnqtNwNigSKnOmA.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">Values of best accuracy and cross_entropy throughout training on test data</figcaption></figure><p id="7d09" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">pool_range&gt;1的结果要好得多。</p><h2 id="c359" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">对最先进模型的实验</h2><p id="ca4d" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated"><strong class="it hv">resnet上的cifar-10</strong></p><div class="le lf lg lh fq ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/c260ccde4d7c4343eeff417370deaebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*usk8dKSjpgUdWHor9J-gAg.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/50c1507cb06b78e7ff0f9b84ab434f12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*WXl6gIExjPnI33jXkCZGVg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on training data for cifar-10 dataset</figcaption></figure></div><div class="ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/2db3a4085e6f7f345020224e7cd35a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mzcqKyiBtVzj3pAyBorp8A.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/bc5d7673ab1eee722c25e3dee31e40dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*yRyqSCv24erhPB23tx44LA.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on test data for cifar-10 dataset</figcaption></figure></div><figure class="le lf lg lh fq lj fe ff paragraph-image"><div class="fe ff me"><img src="../Images/1ea662e875202036e3daafba3aa1f574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*pme9-T8QPLGZgrPI3P9gMg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">Values of best accuracy and cross_entropy throughout training on test data</figcaption></figure><p id="daac" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">pool_range&gt;1的结果也更好。</p><p id="12da" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">resnet上的cifar-100</strong></p><div class="le lf lg lh fq ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/2d3157574d67a1c83d3c061d02f2b0ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*7K6Y0hW2Kxg17zz7MEs53Q.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/0faf3f9ca31fa987beeec3dcd2c1c116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*v5GPGIzz4ogIPlq8H7whKw.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on training data for cifar-100 dataset</figcaption></figure></div><div class="ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/3b419296094ea478804e55f8a157e1ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Eud_A5w1f7khKOtpbX-oCw.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/ab9a08fd8378860882fcbcfd9052061c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*5v7RZv2Xlhaz0iZoncM0AQ.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and cross entropy on test data for cifar-100 dataset</figcaption></figure></div><figure class="le lf lg lh fq lj fe ff paragraph-image"><div class="fe ff md"><img src="../Images/c9f5f47f11d16774107244a5b3056915.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*POzqxkl2vch1eJ9VDFmAkg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">Values of best accuracy and cross_entropy throughout training on test data</figcaption></figure><p id="1229" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">pool_range&gt;1的结果也更好。此处的结果优于cifar-10的结果，因为cifar100的每类数据较少。这表明，这种想法特别适用于每类数据较少的问题。</p><p id="49f3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">匹配网络上的omniglot</strong></p><p id="ad3d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我尝试在omniglot数据集上使用“<a class="ae ld" href="https://arxiv.org/abs/1606.04080" rel="noopener ugc nofollow" target="_blank">一次学习论文的匹配网络</a>”中提出的架构比较一次20路分类的结果。</p><div class="le lf lg lh fq ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/aa92f40c06796672fa6b54fcad605dc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*wl3aCxq3q_3Qif80z9uxig.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/bbad8e70bcd84d1a4d2e39db9deb4e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Z5_ith5V1kaUPMcMhIHCYg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and loss on training data for omniglot dataset</figcaption></figure></div><div class="ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/d3d2b6825513359386df6f0958237fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*J_Lp_zQtGqphWC1YjKGQfg.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/a2036a660f3cfc9c8f246ea2e1502e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*NoXGgM4-yRkASMAFu24nTw.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of accuracy and loss on validation data for omniglot dataset</figcaption></figure></div><figure class="le lf lg lh fq lj fe ff paragraph-image"><div class="fe ff mf"><img src="../Images/72b7ad9be92e8eb0ca011ba2159c1bf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*7v6u99ly4JT03fgsoG-TXg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">Values of best accuracy and loss throughout training on validation data</figcaption></figure><p id="761f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">请注意，这种实现方式使用了论文中已经规范化的最新实现方式。因此，这些改进是在许多现有技巧之上的。</p><p id="4434" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> omniglot关于学习记忆罕见事件的论文</strong></p><p id="9e42" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我尝试在omniglot数据集上使用“<a class="ae ld" href="https://arxiv.org/abs/1703.03129" rel="noopener ugc nofollow" target="_blank">学习记忆罕见事件</a>”论文中提出的架构比较1次拍摄、5次分类的结果。</p><figure class="le lf lg lh fq lj fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/e94ab35425d8fce7bae79141063302b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*iq_nK6wEQ5KLkSrvbON5AQ.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">Comparison of loss on training data for omniglot dataset</figcaption></figure><div class="le lf lg lh fq ab cb"><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/6e0f15029492b863b4d845847f0782f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*y5NU6nYmDQYi0Q_UxJe9Mg.png"/></div></figure><figure class="li lj lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/d8125e5ea697c77d8f1cbb7ae9da6fa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*LvK2efpzR96aRj-tPGEsVg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek lz di ma mb">Comparison of 1-shot, 2-shot accuracy on validation data for omniglot dataset</figcaption></figure></div><p id="13a8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">pool_range=2，pool_range=4的收敛比使用基线最大池快得多。</p><p id="7953" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">同样，这种加速也超过了论文的现有技术水平。因此，这些改进是在许多现有技巧之上的。</p><h2 id="041a" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated"><strong class="ak">用于再现结果的代码和命令行参数</strong></h2><p id="d6f3" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">所有这些实验都可以从<a class="ae ld" href="https://github.com/singlasahil14/sortpool2d" rel="noopener ugc nofollow" target="_blank">这个报告</a>中重现。</p><p id="bca0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在这里给出了在杂乱mnist和时尚mnist上重现结果的命令行参数<a class="ae ld" href="https://github.com/singlasahil14/sortpool2d" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="78f4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">此处的<a class="ae ld" href="https://github.com/singlasahil14/sortpool2d/tree/master/resnet" rel="noopener ugc nofollow" target="_blank">给出了在采用resnet架构的cifar10和cifar100上重现结果的命令行参数。</a></p><p id="16c2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在omniglot上使用<a class="ae ld" href="https://arxiv.org/abs/1606.04080" rel="noopener ugc nofollow" target="_blank">匹配网络</a>架构再现结果的命令行参数在<a class="ae ld" href="https://github.com/singlasahil14/sortpool2d/tree/master/matching_networks" rel="noopener ugc nofollow" target="_blank">这里给出</a>。</p><p id="12ff" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在omniglot上重现结果的命令行参数与<a class="ae ld" href="https://arxiv.org/abs/1703.03129" rel="noopener ugc nofollow" target="_blank">学习记忆罕见事件</a>架构在<a class="ae ld" href="https://github.com/singlasahil14/sortpool2d/tree/master/learning_to_remember_rare_events" rel="noopener ugc nofollow" target="_blank">这里</a>给出。</p><h2 id="0541" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated"><strong class="ak">结论</strong></h2><p id="f090" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">这个池层(我称之为sort_pool2d)在所有数据集和架构上比max_pool2d做得好得多。时差也不显著。并且每次迭代的时间可以通过编写高度优化的C代码和cuda代码来进一步优化。</p><p id="5c96" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">虽然，这并没有解决丢失空间信息的问题。而是为解决这一问题提供了一个有希望的方向。</p><figure class="le lf lg lh fq lj"><div class="bz el l di"><div class="mh mi l"/></div></figure></div></div>    
</body>
</html>