<html>
<head>
<title>Automatic recognition of speed limit signs — Deep learning with Keras and Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">限速标志的自动识别Keras和Tensorflow深度学习</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/automatic-recognition-of-speed-limit-signs-deep-learning-with-keras-and-tensorflow-310d90af9826?source=collection_archive---------13-----------------------#2017-12-07">https://medium.com/hackernoon/automatic-recognition-of-speed-limit-signs-deep-learning-with-keras-and-tensorflow-310d90af9826?source=collection_archive---------13-----------------------#2017-12-07</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="14e4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在我来德国之前，我对德国道路上没有限速的故事很感兴趣。令我失望的是，限速几乎无处不在。高速公路(autobahn)上只有某些区域被指定为无速度限制区，汽车和其他车辆可以在那里测试其工程极限。</p><p id="8b20" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果一个司机超速行驶，突然进入一个必须遵守一定速度限制的区域，该怎么办？解决这个问题的一种方法，也是最常见的方法，是驾驶员手动刹车，降低加速度。但是，嘿，我们已经到了2017年，计算机现在可以识别的不仅仅是猫和狗！所以让我们试着让我们的电脑自动识别限速标志吧！</p><p id="a4e6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我的实现基于一篇名为<a class="ae jp" href="https://www.youtube.com/watch?v=WIhI1W6NoZ0" rel="noopener ugc nofollow" target="_blank">使用TensorFlow和Keras的卷积神经网络简介</a>的教程，作者是<a class="ae jp" href="http://zeigermann.eu/" rel="noopener ugc nofollow" target="_blank"> Oliver Zeigermann </a>。这是一次非常好的演讲，我喜欢他从工程师的角度而不是从研究人员的角度来探讨实现。我一直在积极尝试这两种方法，在这里我学到了一些数学知识，也学到了如何使用各种库来实现它。</p><p id="236f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我在本教程中发现的一个关键东西是微软Azure笔记本。在他的教程中，Zeigermann要求观众要么在本地运行笔记本电脑，要么在云上运行。他说他更喜欢云，因为云机器比他的机器更强大，规格也更多。我的机器也是如此。在此之前，我一直在我的CPU上使用Jupyter笔记本电脑，我的机器很快就会发热。所以我决定试用Azure笔记本，我有一个非常好的体验。它们速度很快，可以很快安装好。而且他们是免费的！我不得不寻找捕获物，但是没有！对于刚刚开始学习python和数据科学的人来说，Azure笔记本可以帮助他们快速起步。</p><p id="a02a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">实施任何数据科学或人工智能项目的首要任务是找到一个合适的数据集。本教程的数据集由主讲人提供。他在视频中提到，该教程是基于<a class="ae jp" rel="noopener" href="/@waleedka">瓦利德·阿卜杜拉</a>的<a class="ae jp" rel="noopener" href="/@waleedka/traffic-sign-recognition-with-tensorflow-629dffc391a6">类似项目</a>。我假设他从另一个项目中获得了数据。在这种情况下，它基于一个名为<a class="ae jp" href="http://btsd.ethz.ch/shareddata/" rel="noopener ugc nofollow" target="_blank">比利时交通标志数据集的数据集。</a></p><p id="8549" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在获得数据之后，我们仍然需要以机器学习模型可以使用的形式准备我们的数据。数据集中的图像为. ppm格式。我们使用库skimage将它转换成可用于分析的形式。下面是执行转换的函数。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="e726" class="jz ka hu jv b fv kb kc l kd ke">import os<br/>import skimage.data</span><span id="fb03" class="jz ka hu jv b fv kf kc l kd ke">def load_data(data_dir):<br/>    directories = [d for d in os.listdir(data_dir)<br/>                  if os.path.isdir(os.path.join(data_dir, d))]<br/>    labels = []<br/>    images = []<br/>    for d in directories:<br/>        label_dir = os.path.join(data_dir, d)<br/>        file_names = [os.path.join(label_dir, f)<br/>                      for f in os.listdir(label_dir) if f.endswith(".ppm")]<br/>        for f in file_names:<br/>            images.append(skimage.data.imread(f))<br/>            labels.append(int(d))<br/>    return images, labels</span></pre><p id="beb1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">使用load_data函数加载数据后，我们尝试查看图像和标签是如何组织的。我们写了一个函数，让我们可以可视化我们的数据。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="910f" class="jz ka hu jv b fv kb kc l kd ke">import matplotlib<br/>import matplotlib.pyplot as plt</span><span id="8f12" class="jz ka hu jv b fv kf kc l kd ke">def display_images_and_labels(images, labels):<br/>    """Display the first image of each label."""<br/>    unique_labels = set(labels)<br/>    plt.figure(figsize=(15, 15))<br/>    i = 1<br/>    for label in unique_labels:<br/>        # Pick the first image for each label.<br/>        image = images[labels.index(label)]<br/>        plt.subplot(8, 8, i)  # A grid of 8 rows x 8 columns<br/>        plt.axis('off')<br/>        plt.title("Label {0} ({1})".format(label, labels.count(label)))<br/>        i += 1<br/>        _ = plt.imshow(image)<br/>    plt.show()<br/>display_images_and_labels(images, labels)</span></pre><p id="f336" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这将导致以下结果。</p><figure class="jq jr js jt fq kh fe ff paragraph-image"><div class="fe ff kg"><img src="../Images/d0a4bf52130eba3efe60a5c3b3c6fda8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*yTLgtKiwfDAytXkJZOJbtw.png"/></div><figcaption class="kk kl fg fe ff km kn bd b be z ek">Speed limit images with their respective labels and counts</figcaption></figure><p id="41ff" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们看到我们的数据集有6个不同类别的限速图像。我们有图像显示30，50，70，80，100和120，每个类别分别有79，81，68，53，41和57个样本。这不是一个非常大的数据集，但对于我们的问题来说已经足够好了。</p><p id="4e30" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">观察了图像的组织方式后，现在让我们看看每张图像的形状，以及它的最小和最大RGB颜色值。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="7aef" class="jz ka hu jv b fv kb kc l kd ke">for image in images[:5]:<br/>    print("shape: {0}, min: {1}, max: {2}".format(image.shape, image.min(), image.max()))</span><span id="4d57" class="jz ka hu jv b fv kf kc l kd ke">Output:</span><span id="cdf3" class="jz ka hu jv b fv kf kc l kd ke">shape: (21, 22, 3), min: 27, max: 248<br/>shape: (23, 23, 3), min: 10, max: 255<br/>shape: (43, 42, 3), min: 11, max: 254<br/>shape: (61, 58, 3), min: 3, max: 255<br/>shape: (28, 27, 3), min: 8, max: 65</span></pre><p id="9a2f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">从输出中我们可以清楚地看到，每个图像的形状随着最小和最大RGB值分布的大变化而变化。我们的神经网络模型期望我们所有的图像都具有相同的形状。在调整大小时，让我们也将最小和最大RGB值归一化到0和1之间。我们使用skimage的转换功能将图像转换为64x64像素，RGB有3个通道。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="2260" class="jz ka hu jv b fv kb kc l kd ke">import skimage.transform<br/>images64 = [skimage.transform.resize(image, (64,64)) for image in images]</span></pre><p id="fda1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最后，我们执行数据准备的最后一步，将图像和标签转换为numpy数组。我们还使用to _ categorical函数将我们的标签转换为不同的分类数组，如果特定的类别用else 0表示，则数组包含1。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="71f3" class="jz ka hu jv b fv kb kc l kd ke">import numpy as np<br/>from keras.utils.np_utils import to_categorical</span><span id="a9b4" class="jz ka hu jv b fv kf kc l kd ke">y = np.array(labels)<br/>X = np.array(images64)<br/>num_categories = 6<br/>y = to_categorical(y, num_categories)</span></pre><p id="a8e1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在这个阶段之后，Zeigermann解释了他如何通过训练一个简单的keras模型进行实验，该模型在训练数据上表现良好，但在测试数据上表现不佳。他还讨论了为什么RMSProp与SGD、Adagrad等其他方法相比似乎是更好的优化器。</p><p id="82ef" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最后，实验将他引向卷积神经网络。卷积神经网络或CNN是一种明确假设输入是图像的神经网络。计算机视觉中的许多深度学习革命都是由CNN领导的。这是他们建筑的一个例子。</p><figure class="jq jr js jt fq kh fe ff paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="fe ff ko"><img src="../Images/eead39f777df596500de0be856c25dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2SWb6CmxzbPZijmevFbe-g.jpeg"/></div></div><figcaption class="kk kl fg fe ff km kn bd b be z ek">CNN Architecture. Source: <a class="ae jp" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/convolutional-networks/</a></figcaption></figure><p id="3ef4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">因为我们在这里关注的是CNN的应用方面，所以我不会详细讨论每一层是什么以及我们如何调整超参数。我们通过使用Keras库来运行CNN。Keras是基于Tensorflow和Theano(不再维护Theano)构建的高级API。现在让我们来看看代码。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="e3b5" class="jz ka hu jv b fv kb kc l kd ke">from keras.models import Model<br/>from keras.layers import Dense, Flatten, Input, Dropout<br/>from keras.layers import Convolution2D, MaxPooling2D<br/>from sklearn.model_selection import train_test_split</span><span id="99d9" class="jz ka hu jv b fv kf kc l kd ke">inputs = Input(shape=(64,64,3))</span><span id="77fe" class="jz ka hu jv b fv kf kc l kd ke">x = Convolution2D(32, 4,4, border_mode='same', activation='relu')(inputs)<br/>x = Convolution2D(32, 4,4, border_mode='same', activation='relu')(x)<br/>x = Convolution2D(32, 4,4, border_mode='same', activation='relu')(x)<br/>x = MaxPooling2D(pool_size=(2,2))(x)<br/>x = Dropout(0.25)(x)</span><span id="4035" class="jz ka hu jv b fv kf kc l kd ke"># one more block<br/>x = Convolution2D(64, 4, 4, border_mode='same', activation='relu')(x)<br/>x = Convolution2D(64, 4, 4, border_mode='same', activation='relu')(x)<br/>x = MaxPooling2D(pool_size=(2, 2))(x)<br/>x = Dropout(0.25)(x)</span><span id="b7a6" class="jz ka hu jv b fv kf kc l kd ke">x = Flatten()(x)<br/># fully connected, 256 nodes<br/>x = Dense(256, activation='relu')(x)<br/>x = Dropout(0.50)(x)</span><span id="a239" class="jz ka hu jv b fv kf kc l kd ke"># softmax activation, 6 categories<br/>predictions = Dense(6, activation='softmax')(x)</span><span id="52a3" class="jz ka hu jv b fv kf kc l kd ke">model = Model(input=inputs, output=predictions)<br/>model.compile(optimizer='rmsprop',<br/>              loss='categorical_crossentropy',<br/>              metrics=['accuracy'])</span><span id="0d37" class="jz ka hu jv b fv kf kc l kd ke">model.fit(X_train, y_train, nb_epoch=50, batch_size=100)</span></pre><p id="5ca2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">该模型现在运行50个时期，批量大小为100。它对之前使用sklearn的train_test_split函数拆分的总数据的80%进行训练。这是我们运行50个纪元后得到的结果。</p><figure class="jq jr js jt fq kh fe ff paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="fe ff kt"><img src="../Images/b3b12df0fa2031a03dd280252ef8bb63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFyRm20Q4V9dzKlRJQ3uaQ.jpeg"/></div></div><figcaption class="kk kl fg fe ff km kn bd b be z ek">CNN output on training data after 50 epochs</figcaption></figure><p id="c915" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">该模型收敛，损失为0.2489，精度约为92%。对于一个没有在超参数调整上做任何努力的模型来说还不错！让我们看看模型在训练数据集上的准确性。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="1cf5" class="jz ka hu jv b fv kb kc l kd ke">train_loss, train_accuracy = model.evaluate(X_train,y_train, batch_size=32)<br/>train_loss, train_accuracy</span></pre><p id="cffc" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们在训练数据上得到83.49%的准确率，损失0.41。让我们看看我们的测试数据集的性能。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="eb5a" class="jz ka hu jv b fv kb kc l kd ke">test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=32)<br/>test_loss, test_accuracy</span></pre><p id="b89b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们得到大约68 %的准确度，损失为1.29。这没那么好。但是这里发生了一些有趣的事情，这也是泽格曼提到的。这是我第二次运行这个模型。在我之前的运行中，我得到了大约95%的测试准确率。显然，模型输出是不确定的。也许有办法让它更稳定。我将不得不在那上面读更多。</p><p id="7824" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最后，让我们在测试数据集上可视化我们的模型的一些预测。我们从测试数据集中随机抽取10幅图像，并使用matplotlib来绘制预测。我们显示了预测类及其基础真值。如果我们模型的预测是正确的，我们把它涂成绿色，否则涂成红色。</p><pre class="jq jr js jt fq ju jv jw jx aw jy dt"><span id="7c23" class="jz ka hu jv b fv kb kc l kd ke">import random<br/>random.seed(3)<br/>sample_indexes = random.sample(range(len(X_test)), 10)<br/>sample_images = [X_test[i] for i in sample_indexes]<br/>sample_labels = [y_test[i] for i in sample_indexes]</span><span id="de80" class="jz ka hu jv b fv kf kc l kd ke">#get the indices of the array using argmax<br/>ground_truth = np.argmax(sample_labels, axis=1)<br/>X_sample = np.array(sample_images)<br/>prediction = model.predict(X_sample)</span><span id="8e40" class="jz ka hu jv b fv kf kc l kd ke">predicted_categories = np.argmax(prediction, axis=1)</span><span id="4772" class="jz ka hu jv b fv kf kc l kd ke"># Display the predictions and the ground truth visually.<br/>def display_prediction (images, true_labels, predicted_labels):<br/>    fig = plt.figure(figsize=(10, 10))<br/>    for i in range(len(true_labels)):<br/>        truth = true_labels[i]<br/>        prediction = predicted_labels[i]<br/>        plt.subplot(5, 2,1+i)<br/>        plt.axis('off')<br/>        color='green' if truth == prediction else 'red'<br/>        plt.text(80, 10, "Truth:  {0}\nPrediction:    {1}".format(truth, prediction), <br/>                 fontsize=12, color=color)<br/>        plt.imshow(images[i])</span><span id="5e68" class="jz ka hu jv b fv kf kc l kd ke">display_prediction(sample_images, ground_truth, predicted_categories)</span></pre><p id="70be" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">正如您在下面看到的，我们的模型正确预测了测试数据集中8/10的随机采样图像。还不错！上次我在测试数据集上获得了95%的准确率，它正确预测了10/10的图像！</p><figure class="jq jr js jt fq kh fe ff paragraph-image"><div class="fe ff ku"><img src="../Images/04b81155c72f7b71677e983d15f5cd28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*Mun51lCSNDQl_sC6W8QvLg.png"/></div></figure><p id="d94c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这是一个伟大的项目！我确实学到了很多。感谢Oliver Zeigermann的教程(和代码)和Waleed Abdulla的博客文章。我期待着做更多的演练，探索这个令人惊讶的人工智能的疯狂世界！</p></div></div>    
</body>
</html>