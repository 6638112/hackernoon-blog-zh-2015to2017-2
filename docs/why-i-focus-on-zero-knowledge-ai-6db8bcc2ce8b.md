# 为什么我关注零知识人工智能

> 原文：<https://medium.com/hackernoon/why-i-focus-on-zero-knowledge-ai-6db8bcc2ce8b>

深度学习和我想去的地方正好相反。原因如下:

深度学习和神经网络之所以出名，是因为它们*只是工作*。遗漏的含义是，您有一整个数据中心的资源可以消耗。简单来说，我没有那些资源。

我所拥有的是对那些庞大模型内部可能发生的事情的洞察力。我敢打赌，这些模型的训练速度会比最优模型慢几个数量级，而且总的来说建造成本会比最优模型高几个数量级。这是我的保证金。

我已经在几个 OpenAI 游戏中测试了简单的试探法。令人惊讶的是简单的方法可以完成复杂的任务:

该演示仅涉及基于 4 个激光雷达阵列输入的左/右决策。这是原始视频，激光雷达的概念甚至没有很好的定义，但它仍然工作，有点。

这是我寻找**神经柏拉图立体**的开始。在研究中，我认为神经网络中存在重复出现的模式，一旦消除重复，将导致训练、空间和计算需求至少提高 1000 倍。

看到即将发生的事情真是太棒了。看前沿研究和产品是令人兴奋的，毫无疑问。但是我会坚持我的方法，因为我是一个惯坏的人。我会继续清理和梳理这些网，让它们恢复到应有的、原始的、田园诗般的状态。希望它不会涉及太多的数学，因为那可能会超出我的理解范围。

> [黑客中午](http://bit.ly/Hackernoon)是黑客如何开始他们的下午。我们是 [@AMI](http://bit.ly/atAMIatAMI) 家庭的一员。我们现在[接受投稿](http://bit.ly/hackernoonsubmission)并乐意[讨论广告&赞助](mailto:partners@amipublications.com)机会。
> 
> 要了解更多信息，请[阅读我们的“关于”页面](https://goo.gl/4ofytp)、[在脸书上给我们点赞/发消息](http://bit.ly/HackernoonFB)，或者简单地说， [tweet/DM @HackerNoon。](https://goo.gl/k7XYbx)
> 
> 如果你喜欢这个故事，我们推荐你阅读我们的[最新科技故事](http://bit.ly/hackernoonlatestt)和[趋势科技故事](https://hackernoon.com/trending)。直到下一次，不要把世界的现实想当然！