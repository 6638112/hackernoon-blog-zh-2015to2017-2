<html>
<head>
<title>Grenade! Dependently Typed Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">手榴弹！相关型神经网络</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/grenade-dependently-typed-neural-networks-c139efdbaa43?source=collection_archive---------31-----------------------#2017-09-25">https://medium.com/hackernoon/grenade-dependently-typed-neural-networks-c139efdbaa43?source=collection_archive---------31-----------------------#2017-09-25</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="d5fa" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae jp" href="https://mmhaskell.com/blog/2017/9/11/deep-learning-and-deep-types-tensor-flow-and-dependent-types" rel="noopener ugc nofollow" target="_blank">在过去的</a> <a class="ae jp" href="https://www.mmhaskell.com/blog/2017/9/18/checking-its-all-in-place-placeholders-and-dependent-types" rel="noopener ugc nofollow" target="_blank">几周</a>里，我们探讨了我在这个博客上提出的最复杂的话题之一。我们检查了使用张量流时可能发生的潜在运行时故障。这些问题包括尺寸不匹配和缺少占位符。在理想的情况下，我们应该在编译时捕捉这些问题。在目前阶段，Haskell张量流库不支持这一点。但是我们演示了通过使用依赖类型来添加一个层来实现这一点是可能的。</p><p id="f434" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在，我仍然是依赖类型的新手，所以我提出的解决方案相当笨拙。本周我将展示一个来自另一个库的更好的例子。手榴弹库到处都使用依赖类型。它允许我们极其简洁地构建可验证有效的神经网络。所以让我们一起来看看这到底是怎么回事吧！</p><h1 id="9daa" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">形状和层</h1><p id="d301" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">使用这个库首先要学习的是形状和层这两个概念。形状最好与张量流中的张量相比较，除了它们存在于文字级别。在张量流中，我们可以建立任意维数的张量。手雷目前最多只支持三维。因此，不同的形状类型要么以<code class="eh kt ku kv kw b">D1, D2</code>开始，要么以<code class="eh kt ku kv kw b">D3</code>开始，这取决于形状的维度。然后，每个类型构造函数都接受一组自然数参数。因此，以下是手榴弹中所有有效的“形状”类型:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="8088" class="lf jr hu kw b fv lg lh l li lj">D1 5<br/>D2 4 12<br/>D3 8 10 2</span></pre><p id="348f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">第一个表示具有5个元素的向量。第二个表示4行12列的矩阵。第三个代表一个8x10x2的矩阵(或者张量，如果你喜欢的话)。不同的数字代表类型级别的值<strong class="it hv">，而不是术语级别的值。如果这看起来令人困惑，这里有一个<a class="ae jp" href="https://www.schoolofhaskell.com/user/konn/prove-your-haskell-for-great-safety/dependent-types-in-haskell" rel="noopener ugc nofollow" target="_blank">很好的教程</a>，它更深入地讲述了依赖类型的基础知识。最重要的想法是，<code class="eh kt ku kv kw b">D1 5</code>类型的东西可以<strong class="it hv">只有</strong>有5个元素。4或6个元素的向量不会进行类型检查。</strong></p><p id="118a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在我们知道了形状，让我们检查层。层描述了我们的形状之间的关系。它们封装了发生在我们数据上的转换。以下是所有有效的图层类型:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="33cc" class="lf jr hu kw b fv lg lh l li lj">Relu<br/>FullyConnected 10 20<br/>Convolution 1 10 5 5 1 1</span></pre><p id="99c4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">层<code class="eh kt ku kv kw b">Relu</code>描述了接收任何形状的数据并输出相同形状的层。在此期间，它将<code class="eh kt ku kv kw b">relu</code>激活功能应用于输入数据。既然不改变形状，就不需要任何参数。</p><p id="9dc3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一个<code class="eh kt ku kv kw b">FullyConnected</code>层代表神经网络的规范层。它有两个参数，一个用于输入神经元的数量，一个用于输出神经元的数量。在这种情况下，该层将接受10个输入并产生20个输出。</p><p id="0a77" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一个<code class="eh kt ku kv kw b">Convolution</code>层代表一个2D卷积，就像我们在<a class="ae jp" href="https://mmhaskell.com/blog/2017/9/4/deeper-still-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank"> MNIST </a>网络中看到的那样。此特定示例有1个输入要素，10个输出要素，使用5x5面片大小和1x1面片偏移。</p><h1 id="a3be" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">描述网络</h1><p id="b935" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">现在我们对形状和层有了基本的了解，我们可以看到它们是如何组合在一起形成一个完整的网络的。网络类型有两个类型参数。第二个参数是我们的数据在整个网络中任何给定点的形状列表。第一个参数是表示数据变换的图层列表。假设我们想描述一个非常简单的网络。它将采用4个输入，并使用全连接层产生10个输出。然后它将执行一个<code class="eh kt ku kv kw b">Relu</code>激活。这个网络看起来像这样:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="961c" class="lf jr hu kw b fv lg lh l li lj">type SimpleNetwork = Network<br/>  ‘[FullyConnected 4 10, Relu]<br/>  ‘[ ‘D1 4, ‘D1 10, ‘D1 10]</span></pre><p id="c377" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">列表和<code class="eh kt ku kv kw b">D1</code>术语前面的撇号表示这些是提升的构造函数。所以它们是类型而不是术语。为了“读取”这种类型，我们从第一种数据格式开始。我们通过应用转换层来处理每个连续的数据格式。例如，我们从一个四维向量开始，然后用一个完全连通的层将其转换成一个十维向量。然后我们通过应用<code class="eh kt ku kv kw b">relu</code>将这个10-向量转换成另一个10-向量。这就是全部了！我们可以在上面应用另一个<code class="eh kt ku kv kw b">FullyConnected</code>层，它将有3个输出，如下所示:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="8a9e" class="lf jr hu kw b fv lg lh l li lj">type SimpleNetwork = Network<br/>  ‘[FullyConnected 4 10, Relu, FullyConnected 10 3]<br/>  ‘[ ‘D1 4, ‘D1 10, ‘D1 10, `D1 3]</span></pre><p id="5411" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们看看MNIST，看看一个更复杂的例子。我们将从28x28的数据图像开始。然后我们将执行我上面提到的卷积层。这给了我们一个大小为24x24x10的三维张量。然后，我们可以在此基础上执行2x2 max合并，从而得到12x12x10张量。最后，我们可以应用一个<code class="eh kt ku kv kw b">Relu</code>层，保持它的大小不变:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="d2ed" class="lf jr hu kw b fv lg lh l li lj">type MNISTStart = MNISTStart<br/>  ‘[Convolution 1 10 5 5 1 1, Pooling 2 2 2 2, Relu]<br/>  ‘[D2 28 28, D3 24 24 10, D3 12 12 10, D3 12 12 10]</span></pre><p id="412d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">下面是一个完整的MNIST示例(根据库的Github页面上的<a class="ae jp" href="https://github.com/HuwCampbell/grenade" rel="noopener ugc nofollow" target="_blank">自述文件</a>):</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="d0b2" class="lf jr hu kw b fv lg lh l li lj">type MNIST = Network<br/>    '[ Convolution 1 10 5 5 1 1, Pooling 2 2 2 2, Relu<br/>     , Convolution 10 16 5 5 1 1, Pooling 2 2 2 2, FlattenLayer, Relu<br/>     , FullyConnected 256 80, Logit, FullyConnected 80 10, Logit]<br/>    '[ 'D2 28 28, 'D3 24 24 10, 'D3 12 12 10, 'D3 12 12 10<br/>     , 'D3 8 8 16, 'D3 4 4 16, 'D1 256, 'D1 256<br/>     , 'D1 80, 'D1 80, 'D1 10, 'D1 10]</span></pre><p id="1902" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这是一个比我们在张量流中得到的对我们网络的更简单和更简洁的描述！让我们来看看这个库使用依赖类型的方式。</p><h1 id="8b1f" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">依赖类型的魔力</h1><p id="9b9c" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">如果您以前从未使用过依赖类型，那么将我们的网络描述为类型似乎是一个奇怪的想法。但是它给了我们一些额外的好处！</p><p id="be91" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们获得的第一个重大胜利是，生成我们网络的起始值非常容易。既然它有特定的类型，我们可以让类型推理来指导我们！我们不需要任何特定于我们网络形态的术语级代码。我们需要做的就是附上类型签名并调用<code class="eh kt ku kv kw b">randomNetwork</code>！</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="384e" class="lf jr hu kw b fv lg lh l li lj">randomSimple :: MonadRandom m =&gt; m SimpleNetwork<br/>randomSimple = randomNetwork</span></pre><p id="9044" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这会给我们所有需要的初始值，所以我们可以开始了！</p><p id="4ab9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">第二个(也是更重要的)胜利是我们不能建立一个无效的网络！假设我们试图把我们的简单网络，以某种方式不正确地格式化。例如，我们可以说输入形状的大小不是4，而是7:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="3b9e" class="lf jr hu kw b fv lg lh l li lj">type SimpleNetwork = Network<br/>  ‘[FullyConnected 4 10, Relu, FullyConnected 10 3]<br/>  ‘[ ‘D1 7, ‘D1 10, ‘D1 10, `D1 3]<br/>-- ^^ Notice this 7</span></pre><p id="9a76" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这将导致编译错误，因为各层之间不匹配。第一层期望输入为4，但第一个数据格式的长度为7！</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="32ec" class="lf jr hu kw b fv lg lh l li lj">Could not deduce (Layer (FullyConnected 4 10) ('D1 7) ('D1 10))<br/>        arising from a use of ‘randomNetwork’<br/>      from the context: MonadRandom m<br/>        bound by the type signature for:<br/>                   randomSimple :: MonadRandom m =&gt; m SimpleNetwork<br/>        at src/IrisGrenade.hs:29:1-48</span></pre><p id="b688" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">换句话说，它注意到使用<code class="eh kt ku kv kw b">FullyConnected 4 10</code>层从<code class="eh kt ku kv kw b">D1 7</code>到<code class="eh kt ku kv kw b">D1 10</code>的链是无效的。所以它不让我们制造这个网络。如果我们使层本身无效，同样的事情也会发生。例如，我们可以使两个完全连接的层的输出和输入不匹配:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="6686" class="lf jr hu kw b fv lg lh l li lj">-- We changed the second to take 20 as the number of input elements.<br/>type SimpleNetwork = Network <br/>  '[FullyConnected 4 10, Relu, FullyConnected 20 3]<br/>  '[ 'D1 4, 'D1 10, 'D1 20, 'D1 3]</span><span id="7003" class="lf jr hu kw b fv lk lh l li lj">…</span><span id="9c1f" class="lf jr hu kw b fv lk lh l li lj">/Users/jamesbowen/HTensor/src/IrisGrenade.hs:30:16: error:<br/>    • Could not deduce (Layer (FullyConnected 20 3) ('D1 10) ('D1 3))<br/>        arising from a use of ‘randomNetwork’<br/>      from the context: MonadRandom m<br/>        bound by the type signature for:<br/>                   randomSimple :: MonadRandom m =&gt; m SimpleNetwork<br/>        at src/IrisGrenade.hs:29:1-48</span></pre><p id="20d4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">因此，通过提供关于网络有效性的编译时保证，Grenade使我们的程序更加安全。维度导致的运行时错误是不可能的！</p><h1 id="3f62" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">在Iris上培训网络</h1><p id="a899" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">现在让我们快速浏览一下我们实际上是如何训练这个神经网络的。眼尖的读者可能已经注意到，我们建立的<code class="eh kt ku kv kw b">SimpleNetwork</code>就是我们用来训练虹膜数据集的同一个网络。因此，我们将在那里进行一次训练，使用以下步骤:</p><ol class=""><li id="b372" class="ll lm hu it b iu iv iy iz jc ln jg lo jk lp jo lq lr ls lt dt translated">写下网络类型并从中生成一个随机网络</li><li id="fe0f" class="ll lm hu it b iu lu iy lv jc lw jg lx jk ly jo lq lr ls lt dt translated">将我们的输入数据读入手雷使用的格式</li><li id="8a2d" class="ll lm hu it b iu lu iy lv jc lw jg lx jk ly jo lq lr ls lt dt translated">编写一个运行训练迭代的函数。</li><li id="a3cc" class="ll lm hu it b iu lu iy lv jc lw jg lx jk ly jo lq lr ls lt dt translated">运行它！</li></ol><h1 id="eb81" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">1.写出网络类型并生成网络</h1><p id="3236" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">所以我们已经在很大程度上完成了第一步。不过我们会稍微调整一下名字。请注意，我将把导入列表作为本文的附录。还有，代码在我的<code class="eh kt ku kv kw b">IrisGrenade.hs</code>中的<a class="ae jp" href="https://github.com/jhb563/HTensor" rel="noopener ugc nofollow" target="_blank"> Haskell张量流</a>库的<code class="eh kt ku kv kw b"><a class="ae jp" href="https://github.com/jhb563/HTensor/tree/grenade" rel="noopener ugc nofollow" target="_blank">grenade</a></code> <a class="ae jp" href="https://github.com/jhb563/HTensor/tree/grenade" rel="noopener ugc nofollow" target="_blank">分支</a>上！</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="6ec7" class="lf jr hu kw b fv lg lh l li lj">type IrisNetwork = Network <br/>  '[FullyConnected 4 10, Relu, FullyConnected 10 3]<br/>  '[ 'D1 4, 'D1 10, 'D1 10, 'D1 3]</span><span id="7e8c" class="lf jr hu kw b fv lk lh l li lj">randomIris :: MonadRandom m =&gt; m IrisNetwork<br/>randomIris = randomNetwork</span><span id="8064" class="lf jr hu kw b fv lk lh l li lj">runIris :: FilePath -&gt; FilePath -&gt; IO ()<br/>runIris trainingFile testingFile = do<br/>  initialNetwork &lt;- randomIris<br/>  ...</span></pre><h1 id="3db2" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">2.接受我们的输入数据</h1><p id="f9c2" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">我们将利用第一次使用Iris时使用的<code class="eh kt ku kv kw b">readIrisFromFile</code>函数。然后我们将创建一个名为<code class="eh kt ku kv kw b">IrisRow</code>的依赖类型，它使用了<code class="eh kt ku kv kw b">S</code>类型。这个<code class="eh kt ku kv kw b">S</code>类型是一个形状的容器。我们希望我们的输入数据对4个输入特征使用<code class="eh kt ku kv kw b">D1 4</code>。那么我们的输出数据应该使用<code class="eh kt ku kv kw b">D1 3</code>来表示三个可能的类别。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="445c" class="lf jr hu kw b fv lg lh l li lj">-- Dependent type on the dimensions of the row<br/>type IrisRow = (S ('D1 4), S ('D1 3))</span></pre><p id="c2f0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果我们有格式错误的数据，类型将不会匹配，所以我们需要返回一个<code class="eh kt ku kv kw b">Maybe</code>来确保成功。注意，我们通过除以8来标准化数据。这会将所有数据放在0和1之间，从而获得更好的训练结果。我们是这样解析数据的:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="059d" class="lf jr hu kw b fv lg lh l li lj">parseRecord :: IrisRecord -&gt; Maybe IrisRow<br/>parseRecord record = case (input, output) of<br/>  (Just i, Just o) -&gt; Just (i, o)<br/>  _ -&gt; Nothing<br/>  where<br/>    input = fromStorable $ VS.fromList $ float2Double &lt;$&gt;<br/>      [ field1 record / 8.0, field2 record / 8.0, field3 record / 8.0, field4 record / 8.0]<br/>    output = oneHot (fromIntegral $ label record)</span></pre><p id="eef4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">然后，我们将这些纳入我们的主要功能:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="53c7" class="lf jr hu kw b fv lg lh l li lj">runIris :: FilePath -&gt; FilePath -&gt; IO ()<br/>runIris trainingFile testingFile = do<br/>  initialNetwork &lt;- randomIris<br/>  trainingRecords &lt;- readIrisFromFile trainingFile<br/>  testRecords &lt;- readIrisFromFile testingFile</span><span id="60b6" class="lf jr hu kw b fv lk lh l li lj">  let trainingData = mapMaybe parseRecord (V.toList trainingRecords)<br/>  let testData = mapMaybe parseRecord (V.toList testRecords)</span><span id="35f2" class="lf jr hu kw b fv lk lh l li lj">  -- Catch if any were parsed as Nothing<br/>  if length trainingData /= length trainingRecords || length testData /= length testRecords<br/>    then putStrLn "Hmmm there were some problems parsing the data"<br/>    else …</span></pre><h1 id="d965" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">3.编写一个函数来训练输入数据</h1><p id="3037" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">这是一个多步骤的过程。首先，我们将建立我们的学习参数。我们还将编写一个函数，允许我们在特定的行元素上调用<code class="eh kt ku kv kw b">train</code>函数:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="50b5" class="lf jr hu kw b fv lg lh l li lj">learningParams :: LearningParameters<br/>learningParams = LearningParameters 0.01 0.9 0.0005</span><span id="a0fe" class="lf jr hu kw b fv lk lh l li lj">-- Train the network!<br/>trainRow :: LearningParameters -&gt; IrisNetwork -&gt; IrisRow -&gt; IrisNetwork<br/>trainRow lp network (input, output) = train lp network input output</span></pre><p id="53e7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">接下来，我们将编写另外两个帮助函数来帮助我们测试结果。第一个需要网络和一个测试行。它会将其转换为网络的预测输出和实际输出。第二个函数将获取这些输出，并反转<code class="eh kt ku kv kw b">oneHot</code>过程以获取标签(0、1或2)。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="6921" class="lf jr hu kw b fv lg lh l li lj">-- Takes a test row, returns predicted output and actual output from the network.<br/>testRow :: IrisNetwork -&gt; IrisRow -&gt; (S ('D1 3), S ('D1 3))<br/>testRow net (rowInput, predictedOutput) = (predictedOutput, runNet net rowInput)</span><span id="433c" class="lf jr hu kw b fv lk lh l li lj">-- Goes from probability output vector to label<br/>getLabels :: (S ('D1 3), S ('D1 3)) -&gt; (Int, Int)<br/>getLabels (S1D predictedLabel, S1D actualOutput) = <br/>  (maxIndex (extract predictedLabel), maxIndex (extract actualOutput))</span></pre><p id="cd96" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最后，我们将编写一个函数，它将接受我们的训练数据、测试数据、网络和迭代次数。它将返回新训练的网络，并记录一些关于我们做得如何的结果。我们将首先只取训练数据的一个样本，并调整我们的参数，以便学习变得更慢。然后，我们将通过折叠采样数据来训练网络。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="355b" class="lf jr hu kw b fv lg lh l li lj">run :: [IrisRow] -&gt; [IrisRow] -&gt; IrisNetwork -&gt; Int -&gt; IO IrisNetwork<br/>run trainData testData network iterationNum = do<br/>  sampledRecords &lt;- V.toList &lt;$&gt; chooseRandomRecords (V.fromList trainData)<br/>  -- Slowly drop the learning rate<br/>  let revisedParams = learningParams <br/>        { learningRate = learningRate learningParams * 0.99 ^ iterationNum}<br/>  let newNetwork = foldl' (trainRow revisedParams) network sampledRecords<br/>  ....</span></pre><p id="4b46" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">然后，我们将通过查看我们的测试数据来总结这个函数，看看我们做对了多少！</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="3bcf" class="lf jr hu kw b fv lg lh l li lj">run :: [IrisRow] -&gt; [IrisRow] -&gt; IrisNetwork -&gt; Int -&gt; IO IrisNetwork<br/>    run trainData testData network iterationNum = do<br/>      sampledRecords &lt;- V.toList &lt;$&gt; chooseRandomRecords (V.fromList trainData)<br/>      -- Slowly drop the learning rate<br/>      let revisedParams = learningParams <br/>            { learningRate = learningRate learningParams * 0.99 ^ iterationNum}<br/>      let newNetwork = foldl' (trainRow revisedParams) network sampledRecords<br/>      let labelVectors = fmap (testRow newNetwork) testData<br/>      let labelValues = fmap getLabels labelVectors<br/>      let total = length labelValues<br/>      let correctEntries = length $ filter ((==) &lt;$&gt; fst &lt;*&gt; snd) labelValues<br/>      putStrLn $ "Iteration: " ++ show iterationNum<br/>      putStrLn $ show correctEntries ++ " correct out of: " ++ show total<br/>      return newNetwork</span></pre><h1 id="3ca0" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">4.运行它！</h1><p id="57c6" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">我们现在从我们的主函数调用它，迭代100次，我们就完成了！</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="aa60" class="lf jr hu kw b fv lg lh l li lj">runIris :: FilePath -&gt; FilePath -&gt; IO ()<br/>runIris trainingFile testingFile = do<br/> ...<br/>  if length trainingData /= length trainingRecords || length testData /= length testRecords<br/>    then putStrLn "Hmmm there were some problems parsing the data"<br/>    else foldM_ (run trainingData testData) initialNetwork [1..100]</span></pre><h1 id="2ffd" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">与张量流相比</h1><p id="cf49" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">现在我们已经看到了一个不同的库，我们可以考虑它是如何与张量流相抗衡的。所以首先，优势。手榴弹的主要优势是它提供了依赖型设施。这意味着编写不正确的程序更加困难。你建立的基本网络保证有正确的维度。此外，它不使用“占位符”系统，因此您也可以避免这些类型的错误。这意味着你可能会有更少的运行时错误使用手雷。</p><p id="ad88" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">简洁是另一个主要优点。当把我们的数据转换成手榴弹的格式时，训练代码有点复杂。但并不比张量流复杂。当涉及到网络本身的精确定义时，我们只用几行代码就完成了。如果您是依赖类型的新手，理解这些行的含义会很复杂。但是看了几个简单的例子后，你应该能理解大致的模式了。</p><p id="d955" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当然，这并不意味着张量流没有优势。正如我们几周前看到的，在张量流程序中加入非常全面的测井并不困难。张量板应用程序将为您提供这些数据的可视化效果。用手雷获得中间测井结果有些困难。网络的内在价值没有太多的透明度(至少我发现是这样的)。尽管网络类型是可组合的。所以有可能得到你操作的中间步骤。但是如果你把你的网络分成不同的类型，然后把它们缝合在一起，你将会去掉一些网络的简洁。</p><p id="0a0d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">此外，张量流还有更丰富的机器学习工具生态系统可供访问。手雷仍然局限于最常见的机器学习层的子集，如卷积和最大池。张量流的API允许支持向量机和线性模型等方法。所以张量流给了你更多的选择。</p><p id="9443" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我将在以后的文章中探讨的一个问题是比较这两个库的性能。我怀疑张量流更快，因为它是如何把所有的数学都归结到C层的。但是我还不太熟悉HMatrix(手雷的数学依赖于它)和它的效率。所以我肯定是错的。</p><h1 id="67ee" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">结论</h1><p id="aae9" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">手榴弹提供了一些真正可怕的设施，建立一个简洁的神经网络。一个手榴弹程序可以在编译时证明网络结构良好。它还允许一种难以置信的简洁方式来定义你的神经网络有哪些层。它没有张量流那样的谷歌级支持。所以它缺少很多很酷的功能，比如日志和可视化。但是就其范围而言，它是一个非常整洁的库。我没有提到的一件事是它的生成/对抗网络的机制。我很想尽快尝试一下！</p><p id="0433" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">与张量流相比，手榴弹是一个更简单的库，可以合并到堆栈中。如果你想比较这两者，你应该看看我们的<a class="ae jp" href="https://www.mmhaskell.com/tensorflow" rel="noopener ugc nofollow" target="_blank"> Haskell张量流指南</a>，这样你就可以安装TF并开始使用了！</p><p id="5a9d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你以前从未写过一行Haskell，不要害怕！下载我们的<a class="ae jp" href="https://www.mmhaskell.com/checklist" rel="noopener ugc nofollow" target="_blank">入门清单</a>，获取一些免费资源，开始您的Haskell教育！</p><h1 id="85d4" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">附录:编译器扩展和导入</h1><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="b245" class="lf jr hu kw b fv lg lh l li lj">{-# LANGUAGE DataKinds #-}<br/>{-# LANGUAGE BangPatterns #-}<br/>{-# LANGUAGE TupleSections #-}<br/>{-# LANGUAGE GADTs #-}</span><span id="aa65" class="lf jr hu kw b fv lk lh l li lj">import           Control.Monad (foldM_)<br/>import           Control.Monad.Random (MonadRandom)<br/>import           Control.Monad.IO.Class (liftIO)<br/>import           Data.Foldable (foldl')<br/>import           Data.Maybe (mapMaybe)<br/>import qualified Data.Vector.Storable as VS<br/>import qualified Data.Vector as V<br/>import           GHC.Float (float2Double)<br/>import           Grenade<br/>import           Grenade.Core.LearningParameters (LearningParameters(..))<br/>import           Grenade.Core.Shape (fromStorable)<br/>import           Grenade.Utils.OneHot (oneHot)<br/>import           Numeric.LinearAlgebra (maxIndex)<br/>import           Numeric.LinearAlgebra.Static (extract)</span><span id="9ec5" class="lf jr hu kw b fv lk lh l li lj">import           Processing (IrisRecord(..), readIrisFromFile, chooseRandomRecords)</span></pre></div></div>    
</body>
</html>