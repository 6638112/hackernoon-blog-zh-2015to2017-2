<html>
<head>
<title>Latent space visualization — Deep Learning bits #2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">潜在空间可视化—深度学习比特#2</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/latent-space-visualization-deep-learning-bits-2-bd09a46920df?source=collection_archive---------1-----------------------#2017-02-24">https://medium.com/hackernoon/latent-space-visualization-deep-learning-bits-2-bd09a46920df?source=collection_archive---------1-----------------------#2017-02-24</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="992f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">精选</em>:插值，t-SNE投影(附gif&amp;示例！)</p><div class="jq jr js jt fq ab cb"><figure class="ju jv jw jx jy jz ka paragraph-image"><img src="../Images/d0301ca0e7b5fc1d6734432d21f01713.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/1*4zP8u3RUYJVwbEj74xkFyQ.gif"/></figure><figure class="ju jv kd jx jy jz ka paragraph-image"><img src="../Images/6cebfa4b2c2eb865f4f22c368a2d5ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*vEZE5VcjUr5RUbt_OWfR_w.gif"/></figure></div><p id="1197" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在“<em class="jp">深度学习bits </em>”系列中，我们将<strong class="it hv">而不是</strong>看到如何像我们在<a class="ae ke" rel="noopener" href="/@juliendespois/talk-to-you-computer-with-you-eyes-and-deep-learning-a-i-odyssey-part-2-7d3405ab8be1"><strong class="it hv"><em class="jp">a . I . Odyssey</em></strong></a><strong class="it hv"><em class="jp">中所做的那样，端到端地使用深度学习来解决复杂问题。</em> </strong>我们更愿意看看不同的技术，以及一些<strong class="it hv">例子和应用。</strong>别忘了看看<a class="ae ke" href="https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694" rel="noopener ugc nofollow" target="_blank"> <em class="jp">深度学习比特#1 </em> </a>！</p><blockquote class="kf kg kh"><p id="17dc" class="ir is jp it b iu iv iw ix iy iz ja jb ki jd je jf kj jh ji jj kk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="hu">如果你喜欢人工智能，一定要去</em> </strong> <a class="ae ke" href="http://eepurl.com/cATXvT" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv"> <em class="hu">订阅时事通讯</em> </strong> </a> <strong class="it hv"> <em class="hu">来接收关于文章和更多的更新！</em> </strong></p></blockquote></div><div class="ab cl kl km hc kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="hn ho hp hq hr"><h1 id="e7ef" class="ks kt hu bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp dt translated">介绍</h1><p id="16fe" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated"><a class="ae ke" href="https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694" rel="noopener ugc nofollow" target="_blank">上次</a>，我们已经了解了什么是自动编码器，以及它们是如何工作的。今天，我们将看到它们如何帮助我们以非常酷的方式将数据可视化。为此，我们将使用卷积自动编码器架构(<em class="jp"> CAE </em>)来处理图像。</p><h2 id="2155" class="lv kt hu bd ku lw lx ly ky lz ma mb lc jc mc md lg jg me mf lk jk mg mh lo mi dt translated">又有什么潜在空间？</h2><p id="367a" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">自动编码器由两部分组成，这里有一个快速提示。<strong class="it hv"> <em class="jp">编码器</em> </strong>将来自高维输入的数据带到一个<strong class="it hv"> <em class="jp">瓶颈</em> </strong>层，这里的神经元数量最少。然后，<strong class="it hv"> <em class="jp">解码器</em> </strong>获取该编码输入，并将其转换回原始输入形状——在我们的例子中是图像。<strong class="it hv"> <em class="jp">潜在空间是</em> </strong>数据位于瓶颈层的空间。</p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="fe ff mj"><img src="../Images/53f869fc20a9c706dd985676a962d062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*op0VO_QK4vMtCnXtmigDhA.png"/></div></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">Convolutional Encoder-Decoder architecture</figcaption></figure><p id="ef6c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">潜在空间包含图像的<strong class="it hv">压缩</strong>表示，这是<strong class="it hv">允许解码器使用的唯一信息</strong>以尽可能忠实地 <strong class="it hv">重建输入<strong class="it hv"/>。为了表现良好，网络必须学会提取瓶颈中最相关的特征。</strong></p><p id="0471" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们看看我们能做些什么！</p><h1 id="7bbc" class="ks kt hu bd ku kv ms kx ky kz mt lb lc ld mu lf lg lh mv lj lk ll mw ln lo lp dt translated">数据集</h1><p id="c19f" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">我们将改变上次的数据集。与其看着<a class="ae ke" href="https://hackernoon.com/talk-to-you-computer-with-you-eyes-and-deep-learning-a-i-odyssey-part-2-7d3405ab8be1#.scd7s8ej4" rel="noopener ugc nofollow" target="_blank">我的眼睛</a>或<a class="ae ke" href="https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694#.6qgkt12jm" rel="noopener ugc nofollow" target="_blank">蓝色方块</a>，我们将致力于可能是计算机视觉最著名的<em class="jp">:</em>手写数字<em class="jp">的<a class="ae ke" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>数据集</em>。我通常更喜欢使用不太传统的数据集，只是为了多样化，但是MNIST对于我们今天要做的事情来说非常方便。</p><p id="2837" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp">注意:</em> </strong>虽然MNIST可视化在互联网上很常见<em class="jp"/>，但这篇文章中的图像是100%从代码中生成的<strong class="it hv">，</strong>，所以你可以在你自己的模型中使用这些技术。</p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff mx"><img src="../Images/a5513434b7242ab75db1b7e574a68555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vuZioaSR5BJSGqoghottfw.png"/></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">MNIST is a labelled dataset of 28x28 images of handwritten digits</figcaption></figure><h1 id="d67e" class="ks kt hu bd ku kv ms kx ky kz mt lb lc ld mu lf lg lh mv lj lk ll mw ln lo lp dt translated">基线—自动编码器的性能</h1><p id="e7b8" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">为了理解编码器能够从输入中提取出什么样的特征，我们可以先看一下图像的<strong class="it hv">重建。</strong>如果这个<strong class="it hv">听起来很熟悉</strong>，那很正常，我们上次已经做过了。然而，这一步是<strong class="it hv">必要的</strong>，因为它为我们对模型的<em class="jp">期望</em>设定了基线。</p><p id="79e2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp">注:</em> </strong>对于这个岗位来说，瓶颈层只有<strong class="it hv"> 32个单位</strong>，这是有些<em class="jp">真的</em>，<em class="jp">真的</em>野蛮降维。如果它是一个图像，它甚至不会是6x6 像素。</p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="fe ff my"><img src="../Images/74df9bbd820509586738b8de98e4b3b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oHdV8gmgw0wnCqGrOydzWA.png"/></div></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">Each digit is displayed next to its blurry reconstruction</figcaption></figure><p id="debd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们可以看到自动编码器<strong class="it hv">成功地</strong>重建了数字。<strong class="it hv">重建模糊</strong>，因为输入在瓶颈层被<strong class="it hv">压缩</strong>。我们需要查看<em class="jp">验证样本</em>的原因是<em class="jp"> </em>以确保我们没有<em class="jp">过度拟合</em>训练集。</p><p id="d7f8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp">加成</em> </strong> : <em class="jp">下面是训练过程动画</em></p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff mz"><img src="../Images/d0301ca0e7b5fc1d6734432d21f01713.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/1*4zP8u3RUYJVwbEj74xkFyQ.gif"/></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">Reconstruction of <strong class="bd na">training</strong>(left) and <strong class="bd na">validation</strong>(right) samples at each step</figcaption></figure><h1 id="9114" class="ks kt hu bd ku kv ms kx ky kz mt lb lc ld mu lf lg lh mv lj lk ll mw ln lo lp dt translated">t-SNE可视化</h1><h2 id="771b" class="lv kt hu bd ku lw lx ly ky lz ma mb lc jc mc md lg jg me mf lk jk mg mh lo mi dt translated">什么是t-SNE？</h2><p id="e635" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">当处理数据集时，我们想做的第一件事是以一种<em class="jp">有意义的</em>方式<strong class="it hv">可视化</strong>数据。在我们的例子中，<strong class="it hv">图像</strong> <em class="jp">(或像素)</em> <strong class="it hv">空间</strong>有784个维度(28 <em class="jp"> *28*1 </em>)，我们显然<em class="jp">无法</em>出图。挑战在于将所有这些维度压缩到我们可以把握的东西中，比如2D或3D。</p><p id="2123" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这里出现了<a class="ae ke" href="http://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" rel="noopener ugc nofollow" target="_blank"> t-SNE </a>，一种将<strong class="it hv">高维空间</strong>映射到<strong class="it hv"> 2D或3D空间</strong>的算法，同时试图<strong class="it hv">保持点<strong class="it hv">之间的距离</strong>相同</strong>。我们将使用这种技术来绘制数据集的嵌入，<em class="jp">首先直接来自<strong class="it hv">图像空间</strong>，然后<em class="jp">来自<strong class="it hv">较小的</strong> <strong class="it hv">潜在空间</strong>。</em></em></p><p id="4a5f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp">注:</em> </strong> <em class="jp"> t-SNE比它的表亲</em><a class="ae ke" href="http://www.cs.cmu.edu/~elaw/papers/pca.pdf" rel="noopener ugc nofollow" target="_blank"><em class="jp">PCA</em></a><em class="jp">和</em><a class="ae ke" href="http://www2.hawaii.edu/~kyungim/papers/baek_cvprip02.pdf" rel="noopener ugc nofollow" target="_blank"><em class="jp">ICA</em></a><em class="jp">更好的可视化。</em></p><h2 id="354a" class="lv kt hu bd ku lw lx ly ky lz ma mb lc jc mc md lg jg me mf lk jk mg mh lo mi dt translated">投影像素空间</h2><p id="97be" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">让我们从绘制数据集的t-SNE嵌入(来自图像空间)开始，看看它看起来像什么。</p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="fe ff nb"><img src="../Images/9f8dd48e92742ddf59b50ad2abc162ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IPmyksaiYuo0fflQSUB4BQ.png"/></div></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">t-SNE projection of<strong class="bd na"> image space</strong> representations from the validation set</figcaption></figure><p id="c0ab" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们已经可以看到有些数字是<em class="jp">大致</em> <strong class="it hv">簇在一起</strong>的。那是因为数据集真的很简单*，我们可以在像素<em class="jp"> </em>上使用简单的<em class="jp">试探法</em>对样本进行分类。看看数字<strong class="it hv"> 8、5、7和3 </strong>怎么没有聚类，那是因为它们都是由<strong class="it hv">相同的像素</strong>组成的，只有微小的变化才能区分它们。</p><p id="281f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">*对更复杂的数据，如</em> <a class="ae ke" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> <em class="jp"> RGB图像</em></a><strong class="it hv"><em class="jp">只有</em> </strong> <em class="jp"> </em> <strong class="it hv"> <em class="jp">簇</em> </strong> <em class="jp">才会对</em><strong class="it hv"><em class="jp"/></strong><em class="jp">的图像产生相同的一般颜色。</em></p><h2 id="1980" class="lv kt hu bd ku lw lx ly ky lz ma mb lc jc mc md lg jg me mf lk jk mg mh lo mi dt translated">投射潜在空间</h2><p id="81ce" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">我们知道<em class="jp">潜在空间</em>包含<strong class="it hv"/><strong class="it hv">比像素空间<strong class="it hv"/>更简单的图像表示</strong>，所以我们可以希望t-SNE会给我们一个有趣的<strong class="it hv">潜在空间</strong>的二维投影。</p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="fe ff nc"><img src="../Images/496a98c06d09ab61f417a3d14332d3aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_RLj3E4Lt8cZzlwtmcbqlA.png"/></div></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">t-SNE projection of <strong class="bd na">latent space</strong> representations from the validation set</figcaption></figure><p id="2b89" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">虽然<em class="jp">并不完美</em>，但是投影显示了<strong class="it hv">更密集的</strong>星团。这表明在潜在空间中，相同的数字彼此接近。我们可以看到数字<strong class="it hv"> 8、7、5和3 </strong>现在更容易区分，并且出现在<em class="jp">小</em>簇中。</p><h1 id="f123" class="ks kt hu bd ku kv ms kx ky kz mt lb lc ld mu lf lg lh mv lj lk ll mw ln lo lp dt translated">插入文字</h1><p id="8082" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">现在我们知道了模型能够提取的细节层次，我们可以探测潜在空间的结构。为此，我们将比较<strong class="it hv">插值</strong>在<em class="jp">图像空间</em>和<em class="jp">潜在空间</em>中的样子。</p><h2 id="20e0" class="lv kt hu bd ku lw lx ly ky lz ma mb lc jc mc md lg jg me mf lk jk mg mh lo mi dt translated">图像空间中的线性插值</h2><p id="b889" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">我们首先从数据集中获取<strong class="it hv">两幅图像，并在它们之间进行线性插值。实际上，这个<em class="jp">以一种<strong class="it hv">幽灵般的</strong>方式混合</em>图像。</strong></p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="fe ff nd"><img src="../Images/559c017d721a0cf8724ae22b93baa396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PCEH9lP4BvXxZ1U4ikqgCQ.png"/></div></div></figure><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff ne"><img src="../Images/03314b5ae30d1ff2525e7febd742745e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*AmMmPP2KTzw_MEbdRAS3hw.png"/></div></figure><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff nf"><img src="../Images/b20f4120d75490c4adddf0735e1ccb30.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*kT5ZbcJuLejn67HsWVADcQ.png"/></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">Interpolation in <strong class="bd na">pixel space</strong></figcaption></figure><p id="4095" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这种杂乱过渡的原因是像素空间本身的<strong class="it hv">结构。在图像空间中，从一幅图像平滑地过渡到另一幅图像是不可能的。这就是为什么混合空玻璃杯<em class="jp">的图像和满玻璃杯<em class="jp">的图像</em>不会给出半满玻璃杯<em class="jp">的图像的原因。</em></em></strong></p><h2 id="fe7a" class="lv kt hu bd ku lw lx ly ky lz ma mb lc jc mc md lg jg me mf lk jk mg mh lo mi dt translated">潜在空间中的线性插值</h2><p id="0913" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">现在，让我们在潜在空间做同样的事情。我们获取相同的开始和结束图像，然后<strong class="it hv">将它们馈送给编码器</strong>以获得它们的<em class="jp">潜在空间表示。</em>然后，我们在两个潜在向量之间进行插值，并将这些插入到<strong class="it hv">解码器</strong>中。</p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="fe ff ng"><img src="../Images/cf74c2d2f28eaf5df519cbe829405461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOdlSOh6MfMJb0s-7oIW9Q.png"/></div></div></figure><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff ne"><img src="../Images/4f2835ddee858209ec0945c1483e90f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*uNpKu6L8ekkbSdiJLeTRZA.png"/></div></figure><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff nf"><img src="../Images/c7e4abfc9b7204c3320b47dc00eedac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*M6o7VPlxQL4IsxBLUgb37w.png"/></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">Interpolation in <strong class="bd na">latent space</strong></figcaption></figure><p id="eabe" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">结果是<strong class="it hv">更有说服力</strong>。我们清楚地看到，这两个数字的形状慢慢地从一个<em class="jp">转变为另一个</em>，而不是有一个<em class="jp">褪色</em> <em class="jp">叠加</em>。这显示了潜在空间<strong class="it hv">对图像结构</strong>的理解程度。</p><p id="005d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp">奖励:</em> </strong>这里有几个两个空间插值的动画</p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/77141467b5a2f3992e83ce39cf0ca341.png" data-original-src="https://miro.medium.com/v2/resize:fit:200/1*o3UpMhqHRO4xQiQxThrNRQ.gif"/></div></figure><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/fd786d984166f1863a89ad6c353ba256.png" data-original-src="https://miro.medium.com/v2/resize:fit:200/1*ai5BR1i9qnHPfrKWBy01wQ.gif"/></div></figure><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/b794735a8a62bc4b929205f82bada5c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:200/1*vR5kbTi1Icqg8_g6dSE43A.gif"/></div></figure><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/3409ae53d00acb79a19181d71c6fdb69.png" data-original-src="https://miro.medium.com/v2/resize:fit:200/1*vRiXZd55FUkEzjVKql-2qw.gif"/></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">Linear interpolation in <strong class="bd na">image space</strong> (left) and<strong class="bd na"> latent space</strong> (right)</figcaption></figure><h1 id="28ce" class="ks kt hu bd ku kv ms kx ky kz mt lb lc ld mu lf lg lh mv lj lk ll mw ln lo lp dt translated">更多技术和示例</h1><h2 id="8c2d" class="lv kt hu bd ku lw lx ly ky lz ma mb lc jc mc md lg jg me mf lk jk mg mh lo mi dt translated">插值示例</h2><p id="c368" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">在<strong class="it hv">更丰富的</strong>数据集上，借助<strong class="it hv">更好的</strong>模型，我们可以获得<em class="jp">难以置信的</em>视觉效果。</p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff ni"><img src="../Images/ffd462d016024d4fbaea6129d3fc14c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*N-sWs5uTF1IYh0DkZlhmyg.jpeg"/></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek"><a class="ae ke" href="https://arxiv.org/pdf/1609.04468.pdf" rel="noopener ugc nofollow" target="_blank">3-way <strong class="bd na">Latent space</strong> interpolation for<strong class="bd na"> faces</strong></a></figcaption></figure><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff nj"><img src="../Images/6cebfa4b2c2eb865f4f22c368a2d5ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*vEZE5VcjUr5RUbt_OWfR_w.gif"/></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">Interpolation of <a class="ae ke" href="http://3dgan.csail.mit.edu" rel="noopener ugc nofollow" target="_blank"><strong class="bd na">3D shapes</strong></a></figcaption></figure><h2 id="d7e6" class="lv kt hu bd ku lw lx ly ky lz ma mb lc jc mc md lg jg me mf lk jk mg mh lo mi dt translated">潜在空间算法</h2><p id="a141" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">我们还可以在潜空间<strong class="it hv">里做<strong class="it hv">算术</strong>。</strong>这意味着用<strong class="it hv">代替</strong> <strong class="it hv">插值，我们可以加减</strong>潜在空间表示法。</p><p id="f66d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">比如有脸，戴眼镜的男人——不戴眼镜的男人+不戴眼镜的女人=戴眼镜的女人。这项技术带来了令人兴奋的结果。</em></p><figure class="jq jr js jt fq jv fe ff paragraph-image"><div class="fe ff nj"><img src="../Images/94c03d2fa8964a40747b47ad7a02cb5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*yMFJ-7fokU0Xkx89pSFfew.gif"/></div><figcaption class="mo mp fg fe ff mq mr bd b be z ek">Arithmetics on <a class="ae ke" href="http://3dgan.csail.mit.edu" rel="noopener ugc nofollow" target="_blank"><strong class="bd na">3D shapes</strong></a></figcaption></figure><p id="81a6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp">注意:</em> </strong>我已经在代码中为其添加了一个函数，但在MNIST上看起来很糟糕。</p><h1 id="03b6" class="ks kt hu bd ku kv ms kx ky kz mt lb lc ld mu lf lg lh mv lj lk ll mw ln lo lp dt translated">结论</h1><p id="e75a" class="pw-post-body-paragraph ir is hu it b iu lq iw ix iy lr ja jb jc ls je jf jg lt ji jj jk lu jm jn jo hn dt translated">在这篇文章中，我们看到了几种技术来可视化嵌入在自动编码器神经网络潜在空间中的<strong class="it hv">学习到的</strong>特征<em class="jp">。这些可视化有助于理解网络正在学习什么。由此，我们可以为<strong class="it hv"><em class="jp"/></strong><strong class="it hv"><em class="jp">压缩</em> </strong>以及许多其他应用开发潜在空间。</em></p><blockquote class="kf kg kh"><p id="422b" class="ir is jp it b iu iv iw ix iy iz ja jb ki jd je jf kj jh ji jj kk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="hu">如果你喜欢人工智能，一定要去</em> </strong> <a class="ae ke" href="http://eepurl.com/cATXvT" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv"> <em class="hu">订阅时事通讯</em> </strong> </a> <strong class="it hv"> <em class="hu">来接收关于文章和更多的更新！</em>T41】</strong></p></blockquote><p id="e9dd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">你可以玩那边的代码:</p><div class="nk nl fm fo nm nn"><a href="https://github.com/despoisj/LatentSpaceVisualization" rel="noopener  ugc nofollow" target="_blank"><div class="no ab ej"><div class="np ab nq cl cj nr"><h2 class="bd hv fv z el ns eo ep nt er et ht dt translated">GitHub-desp oisj/LatentSpaceVisualization:一个潜在空间的可视化技术…</h2><div class="nu l"><h3 class="bd b fv z el ns eo ep nt er et ek translated">Keras中卷积自动编码器潜在空间的可视化技术</h3></div><div class="nv l"><p class="bd b gc z el ns eo ep nt er et ek translated">github.com</p></div></div></div></a></div><p id="b25c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">感谢阅读这篇文章，敬请关注！</p></div></div>    
</body>
</html>