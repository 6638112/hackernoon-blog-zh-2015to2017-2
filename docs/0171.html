<html>
<head>
<title>Spark Data Source API. Extending Our Spark SQL Query Engine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark数据源API。扩展我们的Spark SQL查询引擎</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/extending-our-spark-sql-query-engine-5f4a088de986?source=collection_archive---------3-----------------------#2016-01-10">https://medium.com/hackernoon/extending-our-spark-sql-query-engine-5f4a088de986?source=collection_archive---------3-----------------------#2016-01-10</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="d2a0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在上一篇文章<a class="ae jp" rel="noopener" href="/@anicolaspp/apache-spark-as-a-distributed-sql-engine-4373e254e0f9#.x4kyh8jqr">Apache Spark as a Distributed SQL Engine</a>中，我们解释了如何使用SQL查询存储在Hadoop中的数据。我们的引擎能够从分布式文件系统中读取<strong class="it hv"> CSV </strong>文件，从文件中自动发现模式，并通过<em class="jq"> Hive </em>元存储将它们公开为表格。所有这些都是为了能够将标准的SQL客户端连接到我们的引擎，并在不手动定义文件模式的情况下探索我们的数据集，从而避免ETL工作。</p><p id="6853" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Spark提供了一个可以扩展的框架，我们将通过扩展它的一些功能来进一步提升它的能力。</p><h1 id="7e11" class="jr js hu bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dt translated">Spark数据源API</h1><p id="0b40" class="pw-post-body-paragraph ir is hu it b iu kp iw ix iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo hn dt translated"><em class="jq">数据源API </em>允许我们管理任何格式的结构化数据。Spark已经内置了一些标准结构，比如Avro和Parquet，但是第三方已经通过扩展这个API为<strong class="it hv"> CSV、JSON </strong>和其他格式创建了新的<em class="jq">阅读器</em>。今天我们要创造我们自己的。</p><p id="782f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们有两个理由来扩展API。</p><p id="2c2d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">首先，我们想要一个能够读取我们的<em class="jq">遗留</em>格式的库，并将我们当前的数据源转换成一个更易于使用的新数据源。</p><p id="efc9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">其次，我们希望在使用我们数据的所有应用程序之间共享这个库，避免为了实现相同的目标而需要共享的应用程序的复杂打包。</p><h1 id="814a" class="jr js hu bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dt translated">数据源</h1><p id="eadc" class="pw-post-body-paragraph ir is hu it b iu kp iw ix iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo hn dt translated">我们的数据源由文件集合组成，其中每个文件本身就是一个实体。为了这个例子，我们定义了一个简单的格式，其中每个文件都是一个包含用户信息的文本文件，每个字段一行。让我们看一个文件的例子。</p><pre class="ku kv kw kx fq ky kz la lb aw lc dt"><span id="3619" class="ld js hu kz b fv le lf l lg lh">pepe<br/>20<br/>Miami<br/>Cuba</span></pre><p id="555b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这个文件代表一个名叫“pepe”的用户，今年20岁，住在迈阿密，出生在古巴。</p><p id="1a33" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在现实世界中，格式可以像我们想要的那样复杂，但我们要解释的过程不会改变。</p><p id="9dfc" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">每个文件都有相同的格式，我们有数百万个这样的文件。我们还想公开它们，以便在SQL中进行查询。</p><h1 id="e1c2" class="jr js hu bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dt translated">我们的实施</h1><p id="7f40" class="pw-post-body-paragraph ir is hu it b iu kp iw ix iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo hn dt translated">为了扩展<em class="jq">数据源API </em>，我们需要从Spark框架中实现某些类，这样我们的自定义阅读器就可以被加载和使用。</p><p id="6b9c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们首先创建一个Spark应用程序作为我们示例的入口点。我们可以通过跟踪帖子<a class="ae jp" rel="noopener" href="/@anicolaspp/sbt-scala-and-spark-6a57c0a2623a#.kqiew1f4r"> SBT、Scala和Spark </a>来实现。</p><p id="080a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一旦创建了应用程序，我们需要做的第一件事就是链接正确的Spark库。我们将在Spark <em class="jq"> 1.5.1 </em>上运行示例，我们的<strong class="it hv"> sbt </strong>文件定义如下。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><h1 id="a577" class="jr js hu bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dt translated">创建我们的模式</h1><p id="fefe" class="pw-post-body-paragraph ir is hu it b iu kp iw ix iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo hn dt translated"><em class="jq">数据源API </em>的起始扩展点是<strong class="it hv">关系提供者<em class="jq"> </em> </strong>类。<strong class="it hv"> RelationProvider </strong>类将用于创建我们数据的必要关系。</p><p id="32a9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们还需要混合<strong class="it hv"> SchemaRelationProvider </strong>特征、<strong class="it hv"> </strong>，这允许我们创建我们想要的模式。</p><p id="40c6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们需要创建一个名为<strong class="it hv"> DefaultSource </strong>的类，Spark将在给定的包中寻找它。<strong class="it hv"> DefaultSource </strong>类将<em class="jq">扩展</em> <strong class="it hv"> RelationProvider </strong>并混合<strong class="it hv"> SchemaRelationProvider </strong></p><p id="c096" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">到目前为止，我们的代码如下所示:</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="41cd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在代码中，我们基本上是在创建一个<strong class="it hv"> LegacyRelation </strong>对象，它定义了我们想要创建的<em class="jq">关系</em>。把关系想象成一个具有已知模式的元组集合。</p><p id="fe20" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们看看我们的<em class="jq">关系</em>类是如何实现的。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="83d8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这里我们用<em class="jq">覆盖了</em>的<em class="jq">模式</em>函数，因此它返回了我们想要的模式。在这个例子中，我们知道数据的模式，但是在这里，我们可以做任何我们想做的事情来获得所需的模式。如果数据是<strong class="it hv"> CSV </strong>，我们可以使用文件头来推断模式，或者执行我们需要的任何其他操作。</p><p id="c90a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">注意，我们只想要<em class="jq">名称</em>和<em class="jq">年龄</em>字段，而不是实体的全部内容。</p><p id="4291" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">下一步是测试我们是否得到了正确的模式，我们可以通过将下面的代码添加到我们的<em class="jq">应用</em>中来完成。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="65c6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这段代码从中创建了一个<strong class="it hv"> SparkContext </strong>和一个<strong class="it hv"> SQLContext </strong>。使用<strong class="it hv"> SQLContext </strong>我们通过传递<em class="jq">包名</em>来设置格式(记住Spark会在这个包中寻找<strong class="it hv"> DefaultSource </strong>类)。然后我们<em class="jq">使用我们的提供者将指定路径中的数据加载到<strong class="it hv">数据帧</strong>中。</em></p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="0247" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">将打印我们定义的模式，输出应该如下所示。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="cd52" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">此时，我们只创建了我们想要的模式，但是没有说明如何准备数据以及如何将数据组织到我们定义的模式中。</p><h1 id="d441" class="jr js hu bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dt translated">将数据读入我们的模式</h1><p id="78d8" class="pw-post-body-paragraph ir is hu it b iu kp iw ix iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo hn dt translated">为了读取我们的数据源，我们的<strong class="it hv">legal relation</strong>类<strong class="it hv"> </strong>需要混合<strong class="it hv"> TableScan </strong>特征。<strong class="it hv"> TableScan </strong>有一个我们需要用以下签名实现的方法:</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="5805" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">方法<em class="jq"> buildScan </em>应该从我们的数据源返回所有行。在我们的特例中，每一行都是每个文件的选定内容。让我们看看我们的<em class="jq">构建扫描</em>的实现。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="d32b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这里我们使用了<em class="jq"> wholeTextFiles </em>方法<em class="jq"> </em>来读取整个文件(每个文件都是一个实体)，读取前两行(我们需要的唯一字段)并从每一行创建一行。结果是一个行集合，其中每一行都是仅使用我们关心的文件部分创建的。</p><p id="8fe6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这将足以修改我们的<em class="jq">应用程序</em>，使其打印出我们数据源的内容。<em class="jq">应用程序</em>现在看起来如下。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="10fe" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">即使我们将所需的格式读入数据框，也没有关于数据字段类型的信息。我们的模式定义支持不同的数据类型，但我们并不强制它们。</p><p id="03f9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们修改我们的<em class="jq"> buildScan </em>方法，以便它在创建每一行时推断类型信息。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="fe90" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这里，唯一的变化是我们将从文件中读取的每个值转换为正确的类型，这是从<em class="jq"> schema.fields </em>对象中推断出来的。在我们的特例中，我们只对<em class="jq">名字</em>是一个<em class="jq">字符串</em>和<em class="jq">年龄</em>是一个<em class="jq">整数</em>感兴趣，但是同样，在这一点上我们可以非常有创意。</p><p id="416f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在，我们最后的<strong class="it hv"> LegacyRelation </strong>类将如下所示。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="ba5a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在我们可以将我们的数据加载到一个<strong class="it hv"> DataFrame </strong>中，并注册它供SQL客户端使用，正如我们在上一篇文章中解释的那样。我们的<em class="jq"> app </em>和我们展示的一样简单。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="62a8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们已经展示了足够多的将自定义格式读入数据帧的内容，因此我们可以利用<em class="jq"> DataFrame API </em>的优势，但还有更多的事情可以做。</p><p id="929a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jq">数据源API </em>不仅提供读取数据的功能，还提供以自定义格式写入数据的功能。如果我们想将一个数据集从一种格式转换成另一种格式，这个功能非常强大。让我们看看如何将这些功能添加到我们现有的驱动程序中。</p><h1 id="3551" class="jr js hu bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dt translated">编写格式化程序</h1><p id="f0b5" class="pw-post-body-paragraph ir is hu it b iu kp iw ix iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo hn dt translated">假设我们想要保存我们的数据，以便可以从其他标准系统中读取。我们将加载我们的自定义数据源，并从它创建一个<strong class="it hv"> CSV </strong>样的输出。</p><p id="fa6f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了支持来自API的<em class="jq">保存调用</em>，我们的<strong class="it hv"> DefaultSource </strong>类<strong class="it hv"> </strong>必须与<strong class="it hv">CreatableRelationProvider</strong>特征混合。这个trait有一个方法叫做<em class="jq"> createRelation </em>我们<em class="jq"> </em>需要实现，我们来看看。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="9eb6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们基本上是将数据框保存为一个类似于<strong class="it hv"> CSV </strong>的文件，然后返回一个带有已知模式的关系。</p><p id="18f7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jq"> saveAsCsvFile </em>方法用我们格式化为<strong class="it hv"> <em class="jq"> CSV </em> </strong>，<strong class="it hv"> <em class="jq"> </em> </strong>的数据创建一个<strong class="it hv"> RDD【字符串】</strong>，然后<strong class="it hv"><em class="jq"/></strong>it<strong class="it hv"><em class="jq"/></strong>保存到给定的路径。为了简单起见，我们没有在输出文件中包含头文件，但是请记住，我们可以按照我们需要的格式输出数据。</p><p id="295f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们的<strong class="it hv"> DefaultSource </strong>类的完整代码如下。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="a1bd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了将我们的原始数据保存为类似<strong class="it hv"> CSV </strong>的格式，我们对我们的<em class="jq"> app </em>做了如下修改。</p><figure class="ku kv kw kx fq li"><div class="bz el l di"><div class="lj lk l"/></div></figure><p id="355b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">注意，每次我们读/写我们的数据时，我们需要指定我们的<strong class="it hv"> DefaultSource </strong>类所在的包名。</p><p id="aefd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们现在可以打包我们的库，并将其包含在任何需要使用我们描述的数据源的项目中。许多其他库正在被创建，以支持我们可以想象的所有可能的格式，现在您可以创建自己的库来为社区做出贡献，或者只是在您自己的项目中使用。</p><h1 id="bf25" class="jr js hu bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dt translated">结局</h1><p id="561e" class="pw-post-body-paragraph ir is hu it b iu kp iw ix iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo hn dt translated">我们已经看到了如何使用Spark <em class="jq">数据源API </em>将数据从定制格式加载到数据帧中。我们还回顾了过程中涉及的类，特别是Spark如何使用我们包中的<strong class="it hv"> DefaultSource </strong>来执行所需的操作。我们还实现了一个输出格式化程序，这样我们的数据帧可以被保存，就像我们希望的那样。</p><p id="697a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">使用<em class="jq">数据源API </em>我们可以做更多的事情，但是根据我的经验，找到正确的文档是相当困难的。我相信可以创建一个更好的文档，特别是那些在扩展API时非常有用的部分。</p><p id="c61d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">尽管我们的示例展示了如何扩展<em class="jq">数据源API </em>以支持简单的格式，但是可以修改它来读写更复杂的类型，比如二进制编码的实体。</p><p id="885a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">将我们自己的数据类型集成到Spark中的能力使它成为数据处理的顶级框架之一。</p><p id="2b7a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在Hadoop世界中，我们可以找到许多共享目标和功能的工具，但没有一个像Spark一样灵活和通用。这使得Spark在这个领域非常受欢迎。如果我们对能够在无限环境下工作的处理框架感兴趣，那么Apache Spark是一个不错的选择。</p></div><div class="ab cl ll lm hc ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="hn ho hp hq hr"><p id="8bfa" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你觉得这篇文章有用，请推荐它，这样其他人也能从中受益。</p><p id="e0af" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jq">阅读下一条:</em></p><p id="204c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae jp" rel="noopener" href="/@anicolaspp/apache-spark-as-a-distributed-sql-engine-4373e254e0f9#.ttfkjcemk"> <em class="jq"> Apache Spark作为分布式SQL引擎</em> </a></p><p id="f7c6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae jp" rel="noopener" href="/@anicolaspp/how-mapr-improves-our-productivity-and-simplify-our-design-2d777ab53120#.w22b0x8md"><em class="jq">MapR如何提高我们的生产力，简化我们的设计。</em>T3】</a></p><blockquote class="ls lt lu"><p id="64ab" class="ir is jq it b iu iv iw ix iy iz ja jb lv jd je jf lw jh ji jj lx jl jm jn jo hn dt translated"><a class="ae jp" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae jp" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae jp" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae jp" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="dca4" class="ir is jq it b iu iv iw ix iy iz ja jb lv jd je jf lw jh ji jj lx jl jm jn jo hn dt translated">要了解更多信息，请<a class="ae jp" href="https://goo.gl/4ofytp" rel="noopener ugc nofollow" target="_blank">阅读我们的“关于”页面</a>、<a class="ae jp" href="http://bit.ly/HackernoonFB" rel="noopener ugc nofollow" target="_blank">在脸书上给我们点赞/发消息</a>，或者简单地说，<a class="ae jp" href="https://goo.gl/k7XYbx" rel="noopener ugc nofollow" target="_blank"> tweet/DM @HackerNoon。</a></p><p id="708a" class="ir is jq it b iu iv iw ix iy iz ja jb lv jd je jf lw jh ji jj lx jl jm jn jo hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae jp" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae jp" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote></div></div>    
</body>
</html>