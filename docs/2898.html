<html>
<head>
<title>Learning AI if You Suck at Math — P5 — Deep Learning and Convolutional Neural Nets in Plain English!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如果你数学很差，就学习人工智能——P5——用简单的英语说，深度学习和卷积神经网络！</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/learning-ai-if-you-suck-at-math-p5-deep-learning-and-convolutional-neural-nets-in-plain-english-cda79679bbe3?source=collection_archive---------3-----------------------#2017-02-27">https://medium.com/hackernoon/learning-ai-if-you-suck-at-math-p5-deep-learning-and-convolutional-neural-nets-in-plain-english-cda79679bbe3?source=collection_archive---------3-----------------------#2017-02-27</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/4aa5ff99ad86ffabd0df23b9fcb0f276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ArZ_lJehUi9RicOWubMMmA.jpeg"/></div></div></figure><p id="3af5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你数学很差，欢迎来到学习人工智能的第五部分。如果您遗漏了零件<a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-8bdfb4b79037#.qv49ic2ok" rel="noopener ugc nofollow" target="_blank"> 1 </a>、<a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-part-two-practical-projects-47d7a1e4e21f#.p1x8tjxyx" rel="noopener ugc nofollow" target="_blank"> 2 </a>、<a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p3-building-an-ai-dream-machine-or-budget-friendly-special-d5a3023140ef#.wktve8ouw" rel="noopener ugc nofollow" target="_blank"> 3 </a>、<a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32#.kql2vj3yn" rel="noopener ugc nofollow" target="_blank"> 4 </a>、<a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p6-math-notation-made-easy-1277d76a1fe5#.fra2px108" rel="noopener ugc nofollow" target="_blank"> 6 </a>和<a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p7-the-magic-of-natural-language-processing-f3819a689386" rel="noopener ugc nofollow" target="_blank"> 7 </a>，请务必检查它们！</p><p id="5f75" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">今天，我们要编写自己的Python图像识别程序。</strong></p><p id="ba05" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">为此，我们将探索一种强大的深度学习架构，称为深度卷积神经网络(DCNN)。</strong></p><p id="6d00" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">Convnets是计算机视觉的主力。它们为从无人驾驶汽车到谷歌图像搜索的一切事物提供动力。在2017年TensorFlow峰会上，<a class="ae ka" href="https://www.youtube.com/watch?v=toK1OSLep3s" rel="noopener ugc nofollow" target="_blank">一名研究人员展示了他们如何使用convnet检测皮肤癌</a>以及一名皮肤科医生如何使用智能手机！</p><p id="fc28" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">那么为什么神经网络如此强大呢？一个关键原因是:</p><p id="138a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">他们做<em class="kb">自动模式识别</em>。</strong></p><p id="2271" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">那么什么是模式识别，为什么我们关心它是否是自动的呢？</p><p id="0b00" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">模式有多种形式，但让我们举两个重要的例子:</p><ul class=""><li id="b039" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">定义物理形态的特征</li><li id="ac3f" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">完成一项任务所需的步骤</li></ul><h1 id="ef46" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated">计算机视觉</h1><p id="c846" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">在图像处理中模式识别被称为<strong class="je hv"> </strong> <a class="ae ka" href="https://en.wikipedia.org/wiki/Feature_extraction" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> <em class="kb">特征提取</em> </strong> </a> <strong class="je hv">。</strong></p><p id="7e38" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当你看一张照片或现实世界中的一些东西时，你是在有选择地挑选出能让你理解它的关键特征。这是你无意识做的事情。</p><p id="b1c7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当你看到我的猫Dove的照片时，你会想到“猫”或“哇哦哇哦”,但你并不知道你是怎么做到的。你只管去做。</p><p id="01c9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你不知道你是如何做到的，因为它是自动发生的<em class="kb"/>和不知不觉发生的<em class="kb"/>。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lt"><img src="../Images/393a9489e13fd18675a2ed29d118886b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jT34jY1zYQ8DXXMzRTjGPw.jpeg"/></div></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">My beautiful cat Dove. Your built in neural network knows this is a cat.</figcaption></figure><p id="c4f2" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这对你来说似乎很简单，因为你每天都在做，但那是因为复杂性对你来说是隐藏的。</p><p id="c225" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你的大脑是一个黑匣子。你没有说明书。</p><p id="d685" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">然而，如果你真的停下来想一想，你刚才在几分之一秒内所做的事情包含了大量的步骤。表面上看起来很简单，但实际上非常复杂。</p><ul class=""><li id="5b69" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">你移动了你的眼睛。</li><li id="bb3d" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">你吸收光线，然后将光线加工成组成部分，将信号发送到你的大脑。</li><li id="8e80" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">然后你的大脑开始工作，施展它的魔法，将光转化为电化学信号。</li><li id="55a1" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">这些信号通过你的内置神经网络发出，激活它的不同部分，包括记忆、联想和感觉。</li><li id="f8f2" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">在最“基本”的层次上，你的大脑突出了低层次的模式(耳朵、胡须、尾巴)，它们组合成更高层次的模式(动物)。</li><li id="62db" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">最后，你做了一个分类，这意味着你把它变成了一个单词，这是一个现实生活中事物的象征性表示，在这个例子中是一只“猫”</li></ul><p id="e58b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">所有这一切都发生在眨眼之间。</p><p id="889a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你试着教一台计算机做那件事，你甚至会从哪里开始？</p><ul class=""><li id="79df" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">你能告诉它如何检测耳朵吗？</li><li id="434e" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">耳朵是什么？</li><li id="0901" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">你如何描述他们？</li><li id="0754" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">为什么猫耳和人耳或者蝙蝠耳(或者蝙蝠侠)不一样？</li><li id="af24" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">耳朵从各个角度看是什么样的？</li><li id="15c4" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">所有的猫耳朵都一样吗(不，看看苏格兰的褶皱)？</li></ul><p id="f061" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">问题不断出现。</p><p id="c979" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你不能就如何用C++或Python教会计算机所有这些步骤给出一个好的答案，不要难过，因为它难倒了计算机科学家50年！</p><p id="7446" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">你自然做的事情是深度学习神经网络的关键用途之一，它是一个“分类器”，在这种情况下是一个图像分类器。</strong></p><p id="21cc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">一开始，人工智能研究人员试图做我们刚刚经历的练习。他们试图手动定义所有步骤。例如，当谈到自然语言处理或NLP时，他们召集了最好的语言学家，并说“写下所有语言的‘规则’。”他们称这些早期的人工智能为“专家系统”</p><p id="4e68" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">语言学家坐下来，琢磨出一系列令人眼花缭乱的if、then、unless、except语句:</p><ul class=""><li id="575a" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">鸟会飞吗？</li></ul><p id="03f6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">是</p><p id="2a9b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">除非是:</p><ul class=""><li id="1608" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">死亡的</li><li id="dd5f" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">受伤的</li><li id="13fb" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">像企鹅一样不会飞的鸟</li><li id="1530" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">少了一只翅膀</li></ul><p id="0453" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这些规则和例外是无止境的。不幸的是，它们也非常脆弱，容易出现各种错误。创建它们很费时间，容易引起争论和偏见，很难弄清楚，等等。</p><p id="9e09" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">深度神经网络代表了一个真正的突破，因为你不必计算所有的步骤，你可以让机器<em class="kb">自动提取猫<em class="kb">的关键特征</em></em>。</strong></p><p id="5c49" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">“自动地”是必不可少的，因为我们绕过了试图找出我们做任何复杂动作所采取的成千上万个隐藏步骤这一不可能的问题。</p><p id="c785" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们可以让计算机自己解决这个问题！</p><h1 id="076a" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated">万物无尽的脚步</h1><p id="d595" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">让我们看看第二个例子:找出完成一项任务的步骤。</p><p id="a66d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">今天，我们手动完成这项工作，并为计算机定义步骤。这叫编程。假设您想要找到硬盘上的所有图像文件，并将它们移动到一个新文件夹中。</p><p id="6e2e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于大多数任务，程序员是神经网络。他是情报人员。他研究任务，将其分解成步骤，然后为计算机逐一定义每个步骤。他用一种被称为计算机编程语言的符号表示向计算机描述它。</p><p id="6d32" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这里有一个Python中的例子，来自栈交换上的<a class="ae ka" href="http://stackoverflow.com/questions/11903037/copy-all-jpg-file-in-a-directory-to-another-directory-in-python" rel="noopener ugc nofollow" target="_blank">“快乐跳跃者】 :</a></p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="0ebc" class="mh kr hu md b fv mi mj l mk ml">import glob<br/>import shutil<br/>import os</span><span id="2863" class="mh kr hu md b fv mm mj l mk ml">src_dir = “your/source/dir”<br/>dst_dir = “your/destination/dir”</span><span id="4be3" class="mh kr hu md b fv mm mj l mk ml">for jpgfile in glob.iglob(os.path.join(src_dir, “*.jpg”)):<br/>shutil.move(jpgfile, dst_dir) </span></pre><p id="19ff" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">Jolly Jumper想出了所有的步骤并翻译给电脑，比如:</p><ul class=""><li id="648d" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">我们需要知道源目录</li><li id="a650" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">此外，我们需要一个目的地</li><li id="92f4" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">我们需要一种方法来分类我们想要的文件类型，在这个例子中是一个“jpg”文件</li><li id="fd12" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">最后，我们进入目录，搜索任何jpg，并将它们从源目录移动到目标目录</li></ul><p id="b8ac" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这对于简单甚至中等复杂的问题都很有效。操作系统是世界上最复杂的软件之一，由几百万行代码组成。每一行都是对计算机如何完成任务(如在屏幕上画图、存储和更新信息)以及人们如何完成任务(复制文件、输入文本、发送电子邮件、查看照片、与他人聊天等)的明确说明。).</p><p id="a5d7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">但是当我们试图解决更具挑战性的问题时，我们会遇到手动定义问题步骤的能力极限。</p><p id="caef" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">比如你怎么定义开车？</p><p id="37e1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们采取数以亿计的微小步骤来完成这项令人麻木的复杂任务。我们必须:</p><ul class=""><li id="9ae1" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">待在队伍里</li><li id="0519" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">知道什么是线，并能够识别它</li><li id="85cb" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">从一个地方航行到另一个地方</li><li id="518c" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">识别障碍物，如墙壁、人、碎片</li><li id="9625" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">将物体分类为有帮助的(街道标志)或有威胁的(行人闯绿灯)</li><li id="8caf" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">评估我们周围的司机都在哪里</li><li id="3072" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">瞬间做出决定</li></ul><p id="105f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在机器学习中，这被称为<em class="kb">决策</em>问题。复杂决策问题的例子有:</p><ul class=""><li id="f6fe" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">机器人导航和感知</li><li id="7ed6" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">语言翻译系统</li><li id="199f" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">自动驾驶汽车</li><li id="c4cc" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">股票交易系统</li></ul><h1 id="8745" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak">神经网络的秘密内部生活</strong></h1><p id="eb4f" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">让我们看看深度学习如何通过自动特征提取来帮助我们解决现实世界的疯狂复杂性！</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div class="fe ff mn"><img src="../Images/26cdd24c97c1bbbf87f0f173b44c22c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*XAktSZg3tmE-VkqZzqmrcg.png"/></div></figure><p id="e317" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你读过V. Anton Spraul 写的《像程序员一样思考》这本书，你应该知道<strong class="je hv">编程是关于解决问题的</strong>。程序员<strong class="je hv">将一个问题分解成更小的问题，创建一个行动计划</strong>来解决它<strong class="je hv">，然后编写代码</strong>来实现它。</p><p id="a459" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">深度学习为我们解决了问题，但AI在这一点上仍然需要人类(感谢上帝)来设计和测试AI架构(至少目前是这样。)所以让我们把一个神经网络分解成它的各个部分，建立一个程序来识别我的鸽子的图片是一只猫。</p><h1 id="0751" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak">深度学习中的深度</strong></h1><p id="0fb1" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">深度学习是机器学习的子领域。它的名字来源于我们将一堆不同的<strong class="je hv">层</strong>堆叠在一起以学习越来越有意义的数据表示的想法。</p><p id="096c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">每一层都是<strong class="je hv">神经网络，</strong>由<strong class="je hv">人工神经元</strong>之间的链接组成。</p><p id="1dd7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在我们拥有强大的GPU来为我们计算之前，我们只能构建非常小的“玩具”神经网络。他们做不了太多。今天我们可以<strong class="je hv">将许多层</strong>堆叠在一起，因此有了<strong class="je hv">深度学习</strong>中的<strong class="je hv">深度</strong>。</p><p id="0791" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">神经网络的灵感来自于20世纪50年代对人脑的生物学研究。研究人员创建了一个神经元的数学表示，你可以在下面看到(<a class="ae ka" href="http://cs231n.github.io/neural-networks-1/" rel="noopener ugc nofollow" target="_blank">来自斯坦福</a>和维基共享资源的关于卷积神经网络的令人敬畏的开放课件):</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mo"><img src="../Images/922e6b1e2a8754f79f2ae24b1f1f7e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mz0a4EEsdJYsbvf5M_u-Sw.png"/></div></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Biological neuron</figcaption></figure><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div class="fe ff mp"><img src="../Images/fa398c15cec6c9f1759384b7b35d9342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*Yf6BWJq0kdHTumErO99bUQ.jpeg"/></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Math model of a neuron.</figcaption></figure><p id="f443" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">暂时忘掉所有更复杂的数学符号，因为你不需要它们。</p><p id="2ddc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">基础超级简单。由<strong class="je hv"> x0、</strong>表示的数据通过神经元之间的连接传播。连接的强度由其权重表示(<strong class="je hv"> w0x0，w1x1 </strong>等)。如果信号足够强，它通过其<strong class="je hv">激活功能</strong>激活神经元，使神经元<strong class="je hv">激活</strong></p><p id="cacf" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">以下是一个三层深度神经网络的示例:</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mq"><img src="../Images/9800c4a3e11a7da469b220c5017f549b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jUydtMleiUS-6uQzVuttKw.png"/></div></div></figure><p id="9d39" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">通过激活一些神经元而不是其他神经元，并通过加强神经元之间的连接，系统可以了解世界上什么是重要的，什么是不重要的。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mq"><img src="../Images/ba7e87e13779f4f5bdd01b55c0fcab07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3R4Z-JIOB_QV2XQCc_oapg.jpeg"/></div></div></figure><h1 id="f430" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak">构建和训练神经网络</strong></h1><p id="7ceb" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">让我们更深入地了解深度学习，并在学习过程中编写一些代码。<a class="ae ka" href="https://github.com/the-laughing-monkey/learning-ai-if-you-suck-at-math/tree/master/Deep%20Learning%20Examples" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">所有的代码在我的Github这里都有</strong> </a>。</p><p id="1d88" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">该系统的基本特征是:</p><ul class=""><li id="6a5e" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated"><strong class="je hv">训练</strong></li><li id="a91b" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated"><strong class="je hv">输入数据</strong></li><li id="8498" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated"><strong class="je hv">图层</strong></li><li id="5b2d" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated"><strong class="je hv">重量</strong></li><li id="5b59" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated"><strong class="je hv">目标</strong></li><li id="ff44" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated"><strong class="je hv">损失函数</strong></li><li id="cd14" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated"><strong class="je hv">优化器功能</strong></li><li id="363c" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated"><strong class="je hv">预测</strong></li></ul><h1 id="b936" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak">训练</strong></h1><p id="56d7" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">训练是我们如何教会神经网络我们想要它学习的东西。它遵循一个简单的五步流程:</p><ol class=""><li id="1639" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz mr ki kj kk dt translated">创建一个<strong class="je hv">训练数据集</strong>，我们将其命名为<strong class="je hv"> x </strong>，并加载其<strong class="je hv">标签作为目标y </strong></li><li id="5d51" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz mr ki kj kk dt translated"><strong class="je hv">通过网络前馈x数据</strong>，结果<strong class="je hv">为预测y’</strong></li><li id="3d12" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz mr ki kj kk dt translated">算出网络的<strong class="je hv">“损耗”，即预测值y’与正确目标值y </strong>之间的<strong class="je hv">差值</strong></li><li id="203c" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz mr ki kj kk dt translated">计算损失(l) 的<strong class="je hv">“梯度”,它告诉我们朝着或远离正确目标的速度有多快</strong></li><li id="0f87" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz mr ki kj kk dt translated"><strong class="je hv">在<strong class="je hv">与</strong>梯度相反的方向调整网络的权重</strong>并返回第二步再试一次</li></ol><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ms"><img src="../Images/af6b913df44e7b3039ad529f4b76de27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6SuGYTmD0Gg3R8hOgmfE2A.jpeg"/></div></div></figure><h1 id="2adb" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak">输入数据</strong></h1><p id="613b" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">在这种情况下，DCNN的输入数据是一组图像。图像越多越好。与人不同，计算机需要大量的例子来学习如何分类。人工智能研究人员正在研究用更少的数据学习的方法，但这仍然是一个前沿问题。</p><p id="a5dd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">一个著名的例子是<a class="ae ka" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> ImageNet </strong> </a>数据集。它由许多手工标记的图像组成。换句话说，他们众包人类使用他们内置的神经网络来查看所有图像，并为数据提供意义。人们上传了他们的照片，并贴上标签，比如“狗”，或者特定类型的狗，比如“小猎犬”。</p><p id="1b44" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">那些<strong class="je hv">标签代表网络的准确预测</strong>。网络越接近<strong class="je hv">匹配手工标记的数据(y) </strong>和它们的<strong class="je hv">预测(y’)</strong>，网络就越精确。</p><p id="4834" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">数据分为两部分，一个训练集和测试集</strong>。训练集是我们提供给神经网络的输入。它学习各种对象的关键特征，然后我们测试它是否能在测试图像集中的随机数据上准确地找到这些对象。</p><p id="d5e3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在我们的程序中，我们将使用由加拿大高级研究所开发的著名的<strong class="je hv"> </strong> <a class="ae ka" href="http://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> CIFAR-10数据集</strong> </a>。</p><p id="9caa" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">CIFAR-10有10类60000张32x32的彩色图像，每类6000张。我们得到50000幅训练图像和10000幅测试图像。</p><p id="c24c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当我第一次开始使用CIFAR时，我错误地认为这将是一个比使用ImageNet挑战的更大图像更容易的挑战。事实证明，CIFAR10更具挑战性，因为这些图像非常小，数量少得多，所以我们的神经网络很难锁定它们的可识别特征。</p><p id="93c4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">虽然一些最大和最差的DCNN架构，如<a class="ae ka" href="https://github.com/KaimingHe/deep-residual-networks" rel="noopener ugc nofollow" target="_blank"> ResNet </a>在ImageNet上可以达到97%的准确率，但根据我的经验，它在CIFAR 10上只能达到87%左右。CIFAR 10目前的技术水平是<a class="ae ka" href="https://github.com/titu1994/DenseNet" rel="noopener ugc nofollow" target="_blank"> DenseNet </a>，它可以达到大约95%的惊人的250层和1500万个参数！我在文章的底部链接了这些框架，以便进一步研究。但是在深入那些复杂的系统之前，最好从简单的开始。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div class="fe ff mt"><img src="../Images/f86679f667b4b785ad63e5d1b6f8d42b.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*ZCtQWsq9kPAU768IsM82Pg.jpeg"/></div></figure><p id="0e98" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">理论够了！让我们写代码。</p><p id="85d8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你对Python不太熟悉，我非常、非常、非常推荐Fabrizio Romano的<a class="ae ka" href="http://amzn.to/2ldE3fs" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">学习Python。这本书很好地解释了一切。我从来没有找到比这更好的Python书籍，我有一大堆没有教会我多少东西。</strong></a></p><p id="74d4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">我们DCNN的代码基于</strong><a class="ae ka" href="https://github.com/fchollet/keras/tree/master/examples" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">Github</strong></a><strong class="je hv">上的Keras示例代码。</strong></p><p id="93e1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">你可以在这里找到</strong> <a class="ae ka" href="https://github.com/the-laughing-monkey/learning-ai-if-you-suck-at-math/tree/master/Deep%20Learning%20Examples" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">我的修改</strong> </a> <strong class="je hv">。</strong></p><p id="5c7b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我已经调整了架构和参数，并添加了TensorBoard来帮助我们可视化网络。</p><p id="b984" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们初始化Python程序，导入数据集和构建DCNN所需的各种类。幸运的是，Keras已经知道如何自动获取这个数据集，所以我们没有太多的工作要做。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="ec25" class="mh kr hu md b fv mi mj l mk ml">from __future__ import print_function<br/>import numpy as np</span><span id="4588" class="mh kr hu md b fv mm mj l mk ml">from keras.datasets import cifar10<br/>from keras.callbacks import TensorBoard<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Activation, Flatten<br/>from keras.layers import Convolution2D, MaxPooling2D<br/>from keras.utils import np_utils<br/>from keras import backend as K</span></pre><p id="12b6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们的神经网络从随机配置开始。这是一个很好的起点，但是我们不应该期望它有一个非常聪明的开始。然而，也有可能一些随机的配置完全出于偶然给了我们惊人的结果，所以我们播种随机权重以确保我们不会因为纯粹的运气而得到最先进的结果！</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="37aa" class="mh kr hu md b fv mi mj l mk ml">np.random.seed(1337) # Very l33t</span></pre><h1 id="17e0" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak">层</strong></h1><p id="2129" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">现在我们将添加一些层。</p><p id="be67" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">大多数神经网络使用<strong class="je hv">全连接层</strong>。这意味着它们将每一个神经元与其他神经元连接起来。</p><p id="86ad" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">完全连接的层非常适合解决各种问题。不幸的是，它们不能很好地适应图像识别。</p><p id="61de" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">所以我们将使用<strong class="je hv">卷积层</strong>来构建我们的系统，这是独一无二的，因为<strong class="je hv">它们没有将所有的神经元连接在一起</strong>。</p><p id="9f09" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们来看看斯坦福大学计算机视觉课程对convnet缩放的看法:</p><blockquote class="mu mv mw"><p id="3779" class="jc jd kb je b jf jg jh ji jj jk jl jm mx jo jp jq my js jt ju mz jw jx jy jz hn dt translated">在CIFAR-10中，图像仅为32×32×3(32宽，32高，3个颜色通道)，因此常规神经网络的第一隐藏层中的单个全连接神经元将具有32*32*3 = 3072个权重。这个数量看起来还是可以管理的，但是很明显这个全连接结构不能扩展到更大的图像。例如，更大尺寸的图像，例如200×200×3，将导致神经元具有200×200×3 = 120，000个权重。此外，我们几乎肯定希望有几个这样的神经元，所以参数会很快增加！显然，这种完全连接是一种浪费，大量的参数会很快导致过度拟合。”</p></blockquote><p id="355b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">过度拟合</strong>是指你对网络训练得如此之好，以至于它在训练数据上表现出色，但当你向它展示它从未见过的图像时却表现糟糕。换句话说，它在现实世界中没有多大用处。</p><p id="bbac" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这就好像你一遍又一遍地玩同一盘棋，直到你完全记住为止。然后有人在真实的游戏中做出不同的举动，你不知道该怎么办。稍后我们将更多地了解过度拟合。</p><p id="525e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">以下是数据如何流经DCNN。它只查看一小部分数据，寻找模式。然后，它将这些观察建立成更高层次的理解。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff na"><img src="../Images/fd879a9021e2f173b6f22dcf0b99a3b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3rECTefgSkJJ6Sni5sxptA.png"/></div></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">A visual representation of a convolutional neural net from the mNeuron plugin created for MIT’s computer vision courses/teams.</figcaption></figure><p id="c663" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">注意前几层是简单的图案，如边缘、颜色和基本形状。</p><p id="3a76" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">随着信息在各层之间流动，系统会发现越来越复杂的图案，比如纹理，最终它会推断出各种对象类别。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nb"><img src="../Images/3181e676066fab103032425f11088edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mMoJS0rzLztM9hklSJC8ng.png"/></div></div></figure><p id="f3e3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这些想法是基于对猫视觉的实验，该实验表明不同的细胞只对特定种类的刺激做出反应，如边缘或特定的颜色。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nc"><img src="../Images/2e1d56bd9196fb0143edf8e01cf02555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3sThpKdW6V8iQxyYeoBjKA.jpeg"/></div></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek"><a class="ae ka" href="https://www.youtube.com/watch?v=PlhFWT7vAEw" rel="noopener ugc nofollow" target="_blank">Slides from the excellent Deep Learning open course at Oxford</a>.</figcaption></figure><p id="2ace" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">人类也是如此。我们的视觉细胞只对非常特殊的特征做出反应。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nd"><img src="../Images/0cc12d33ab85ff5d2c8f8b332044215e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h28Re9Ug6STaptCcdSUwCw.jpeg"/></div></div></figure><p id="e530" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这是一个典型的DCNN架构图:</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ne"><img src="../Images/3ca4813594c9fb7532f82d7b81d8abb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N4h1SgwbWNmtrRhszM9EJg.png"/></div></div></figure><p id="3f0d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你会注意到那里有第三种层，一个<strong class="je hv">池层</strong>。你可以在<a class="ae ka" href="https://www.youtube.com/watch?v=bEUX_56Lojc" rel="noopener ugc nofollow" target="_blank">牛津讲座</a>和<a class="ae ka" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">斯坦福讲座</a>中找到各种细节。然而，我将跳过许多细节，因为大多数人只是觉得它令人困惑。我知道当我第一次试着去理解它的时候我是这样做的。</p><p id="8434" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">以下是您需要了解的关于合并图层的信息。他们的目标很简单。他们做<strong class="je hv">子采样</strong>。换句话说，它们<strong class="je hv">缩小了输入图像</strong>，这减少了计算负荷和内存使用。由于需要处理的信息更少，我们可以更轻松地处理图像。</p><p id="919b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">它们还有助于减少第二种过度拟合，即网络专注于训练集中的异常，这些异常与挑选狗、鸟或猫没有任何关系。例如，在一组图像上可能有一些混乱的像素或一些镜头眩光。该网络可能会决定镜头眩光和狗在一起，当他们像小行星和婴儿摇铃一样密切相关时。</p><p id="9a88" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最后，大多数DCNNs添加几个<strong class="je hv">密集连接的</strong>，也称为<strong class="je hv">完全连接的层</strong>，以处理掉在早期层中检测到的所有特征地图并进行预测。</p><p id="287d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">因此，让我们给我们的convnet增加几层。</p><p id="80af" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">首先，我们添加一些变量，我们将拉进我们的层。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="093d" class="mh kr hu md b fv mi mj l mk ml"># Defines how many images we will process at once<br/>batch_size = 128</span><span id="a4e6" class="mh kr hu md b fv mm mj l mk ml"># Defines how many types of objects we can detect in this set.  Since CIFAR 10 only detects 10 kinds of objects, we set this to 10.<br/>nb_classes = 10</span><span id="8473" class="mh kr hu md b fv mm mj l mk ml"># The epoch defines how lone we train the system.  Longer is not always better.  After a period of time we reach the point of diminishing returns.  Adjust this as necessary.<br/>nb_epoch = 45</span><span id="387f" class="mh kr hu md b fv mm mj l mk ml"># Here we put in the image dimensions.  We know the images are 32 x 32.  They are already preprocessed for us to be nicely uniform to work with at this point.<br/>img_rows, img_cols = 32, 32</span><span id="192f" class="mh kr hu md b fv mm mj l mk ml"># Here we set the number of convolutional filters to use<br/>nb_filters = 32</span><span id="df31" class="mh kr hu md b fv mm mj l mk ml"># size of pooling area for max pooling<br/>pool_size = (2, 2)<br/># convolution kernel size<br/>kernel_size = (3, 3)</span></pre><p id="a1d8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">内核</strong>和<strong class="je hv">池大小</strong>定义卷积网络如何通过图像寻找特征。最小的内核大小是1x1，这意味着我们认为关键特征只有1像素宽。典型的内核大小一次检查3个像素以上的有用特征，然后将这些特征汇集到一个2x2的网格中。</p><p id="0f0f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">2x2网格从图像中提取特征，并像交易卡一样将它们堆叠起来。这将它们从图像上的特定点断开，并允许系统在任何地方寻找直线或漩涡，而不仅仅是在最初发现它们的点。</p><p id="6d24" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">大多数教程将此描述为处理“<a class="ae ka" href="http://stats.stackexchange.com/questions/208936/what-is-translation-invariance-in-computer-vision-and-convolutional-netral-netwo" rel="noopener ugc nofollow" target="_blank">平移不变性</a>”</p><p id="4613" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这到底是什么意思？好问题。</p><p id="7689" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">再看一下这张图片:</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nb"><img src="../Images/3181e676066fab103032425f11088edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mMoJS0rzLztM9hklSJC8ng.png"/></div></div></figure><p id="c6ca" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果不像你在第1层或第2层看到的那样将这些特征拉出来，系统可能会决定猫鼻子的圆圈只在它找到它的图像的中心位置才是重要的。</p><p id="7e98" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们看看这是如何与我的鸽子工作。如果系统最初在她的眼睛里发现了一个圆圈，那么它可能会错误地认为圆圈在图像中的位置与检测猫有关。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nf"><img src="../Images/4476cc51be335d58333c5216a0d9d7a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I3X7isryYS0M12qdliY8ag.jpeg"/></div></div></figure><p id="1f5b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">相反，正如我们在下面看到的，系统应该在它们可能漫游的任何地方寻找圆圈。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nf"><img src="../Images/3afdf684c6fbcc33aca93114173710b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AarVv_DnjzvyFnvRK8Uz5w.jpeg"/></div></div></figure><p id="e32d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在添加图层之前，我们需要加载和处理数据。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="f589" class="mh kr hu md b fv mi mj l mk ml"># This splits the data into training and test sets and loads the data.  Cifar10 is a standard test data set for Keras so it can download it automatically.  It's about 186MB expanded.</span><span id="7f50" class="mh kr hu md b fv mm mj l mk ml">(X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><span id="f84a" class="mh kr hu md b fv mm mj l mk ml"># Unfortunately, TensorFlow and Theano want their tenor parameters in a different order, so we check for the backend from the json initialization file and set them accordingly.</span><span id="9766" class="mh kr hu md b fv mm mj l mk ml">if K.image_dim_ordering() == 'th':<br/>    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)<br/>    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)<br/>    input_shape = (1, img_rows, img_cols)<br/>else:<br/>    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)<br/>    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)<br/>    input_shape = (img_rows, img_cols, 3)</span><span id="0806" class="mh kr hu md b fv mm mj l mk ml">X_train = X_train.astype('float32')<br/>X_test = X_test.astype('float32')<br/>X_train /= 255<br/>X_test /= 255<br/>print('X_train shape:', X_train.shape)<br/>print(X_train.shape[0], 'train samples')<br/>print(X_test.shape[0], 'test samples')</span><span id="c7bd" class="mh kr hu md b fv mm mj l mk ml"># convert class vectors to binary class matrices</span><span id="51f7" class="mh kr hu md b fv mm mj l mk ml">Y_train = np_utils.to_categorical(y_train, nb_classes)<br/>Y_test = np_utils.to_categorical(y_test, nb_classes)</span></pre><p id="7004" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">好了，现在我们终于可以为程序添加一些层了:</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="2464" class="mh kr hu md b fv mi mj l mk ml">model = Sequential()</span><span id="094b" class="mh kr hu md b fv mm mj l mk ml">model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],<br/>                        border_mode='valid',<br/>                        input_shape=input_shape))<br/>model.add(Activation('relu'))<br/>model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=pool_size))<br/>model.add(Dropout(0.25))</span></pre><p id="9b83" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这些层的堆叠方式如下:</p><ul class=""><li id="d3d0" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">盘旋</li><li id="509b" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">激活</li><li id="5422" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">盘旋</li><li id="df40" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">激活</li><li id="01f9" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">联营</li><li id="b5fe" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">拒绝传统社会的人</li></ul><p id="ffe9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">除了其中两种类型<strong class="je hv">脱落</strong>和<strong class="je hv">激活</strong>之外，我们已经讨论了大多数这些层类型。</p><p id="288a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">辍学是最容易理解的。基本上，它是随机杀死多少模型的一个百分比。这与网飞使用<a class="ae ka" href="http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html" rel="noopener ugc nofollow" target="_blank">混沌猴</a>的方式相似。他们有脚本可以关闭网络中的随机服务器，以确保网络能够以其内置的弹性和冗余生存。这里也是如此。我们想确保网络不太依赖任何一种功能。</p><p id="b2f8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">激活层是决定神经元是“激发”还是“被激活”的一种方式。此时有几十个激活功能。RELU是最成功的，因为它的计算效率。这里是<a class="ae ka" href="https://keras.io/activations/" rel="noopener ugc nofollow" target="_blank">Keras中所有不同类型激活功能的列表</a>。</p><p id="4712" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们还将添加第二个卷积层堆栈，以镜像第一个。如果我们为了效率重写这个程序，我们会创建一个模型生成器，并做一个for循环来创建我们想要的任何堆栈。但是在这种情况下，为了方便起见，我们将从上面剪切并粘贴图层，违反了Python的禅宗规则。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="4af8" class="mh kr hu md b fv mi mj l mk ml">model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))<br/>model.add(Activation('relu'))<br/>model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=pool_size))<br/>model.add(Dropout(0.25))</span></pre><p id="fc89" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最后，我们添加了密集的层，一些更多的脱落层，我们展平了所有的要素地图。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="147e" class="mh kr hu md b fv mi mj l mk ml">model.add(Flatten())<br/>model.add(Dense(256))<br/>model.add(Activation('relu'))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(nb_classes))<br/>model.add(Activation('softmax'))</span></pre><p id="66bd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们在最后一层使用一种叫做softmax的不同类型的激活，因为它定义了类的概率分布。</p><h1 id="9823" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak">重量</strong></h1><p id="5caa" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">我们之前简要讨论了重量，但现在我们将深入研究它们。</p><p id="becd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">权重是各神经元之间连接的强度</strong>。</p><p id="f453" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们自己也有类似的想法。在你的大脑中，有一系列<strong class="je hv">生物神经元</strong>。它们通过电/化学信号与其他神经元相连。</p><p id="6b2c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">但是这些联系不是一成不变的。随着时间的推移，一些联系变得更强，一些变得更弱。</p><p id="817a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">两个生物神经元之间流动的电化学信号越多，这些联系就越强。本质上，当你有新的经历时，你的大脑会不断地自我重组。它通过加强一些神经元之间的连接，对你的记忆、感觉和关于这些经历的想法进行编码。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ng"><img src="../Images/1414a5870389f9538619bd8247c09436.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LXZzdoZGTyA63OW0z7edGg.jpeg"/></div></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Source U.S. National Institute of Health — Wikimedia Commons.</figcaption></figure><p id="5ab5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">基于计算机的神经网络受到生物网络的启发。我们简称它们为<strong class="je hv">人工神经网络</strong>或<strong class="je hv">安</strong> s。通常当我们说“神经网络”时，我们真正指的是ANN。人工神经网络的功能与生物大脑并不完全相同，所以不要错误地认为人工神经网络是某种模拟大脑。不是的。例如，在一个生物神经网络(BNN)中，每个神经元都<em class="kb">而不是</em>连接到其他每个神经元，而在人工神经网络中，一层中的每个神经元通常都连接到下一层中的每个神经元。</p><p id="b500" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">下图是一个BNN，显示了不同神经元之间的连接。请注意，它们是<em class="kb">而不是</em>链接在一起的。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mq"><img src="../Images/d92c9e1b0851db35009b3f793d3dbf86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KbG5-_CcuzALE32qbBG_YQ.png"/></div></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Source: <a class="ae ka" href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0057831" rel="noopener ugc nofollow" target="_blank">Wikimedia Commons</a>: Soon-Beom HongAndrew ZaleskyLuca CocchiAlex FornitoEun-Jung ChoiHo-Hyun KimJeong-Eun SuhChang-Dai KimJae-Won KimSoon-Hyung Yi</figcaption></figure><p id="4a4a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">虽然有许多不同之处，但在BNNs和ann之间也有很强的相似之处。</p><p id="2a46" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">就像你大脑中的神经元形成更强或更弱的连接一样，我们人工神经网络中的权重定义了神经元之间连接的强度。每个神经元对世界都有一点了解。将它们连接在一起可以让他们在一起时对世界有更全面的看法。那些联系更紧密的人被认为对我们试图解决的问题更重要。</p><p id="25b3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们来看几个<a class="ae ka" href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.45414&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">神经网络游乐场的截图，TensorFlow </strong> </a>的可视化工具，帮助更好地理解这一点。</p><p id="d6a2" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">第一个网络显示了一个简单的六层系统。网络试图做的是<strong class="je hv">将最右边的图片中的蓝色圆点和橙色圆点清晰地分开</strong>。它在寻找能以高精度区分它们的最佳模式。</p><p id="4fc3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我还没有开始训练这里的系统。因此，我们可以看到神经元之间的权重基本相等。细虚线表示弱连接，粗线表示强连接。网络以随机权重作为起点进行初始化。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nh"><img src="../Images/ed23bac5e8198cba6138eee93e4c2134.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8w8KRINjTkIvWAZexHzZaA.jpeg"/></div></div></figure><p id="2ada" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在，让我们来看看训练后的网络。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ni"><img src="../Images/c1221c08df0949e22f5831ac3b6859a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zDadr-0UuBv-gGear4ueAQ.jpeg"/></div></div></figure><p id="6970" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">首先注意最右边的图片。现在，在蓝点周围的中间有一个漂亮的蓝点，图片的其余部分是橙色的。如你所见，它做得很好，精确度很高。这种情况发生了80多个“时代”或训练回合。</p><p id="57e3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">还要注意，许多权重在不同神经元之间有强烈的蓝色虚线</strong>。重量增加了，现在这个系统已经训练好了，准备好面对世界了！</p><h1 id="4dac" class="kq kr hu bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated">训练我们的神经网络并优化它</h1><p id="3998" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt translated">现在让模型处理一些数字。为此，我们编译它并设置它的<strong class="je hv">优化器</strong>函数。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="3467" class="mh kr hu md b fv mi mj l mk ml">model.compile(loss='categorical_crossentropy',<br/>              optimizer='adam',<br/>              metrics=['accuracy'])</span></pre><p id="b523" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我花了很长时间才理解优化器的功能，因为我发现大多数解释都忽略了“什么”背后的“为什么”</p><p id="f5a3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">换句话说，我为什么需要一个优化器？</p><p id="dfb7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">记住，一个网络有<strong class="je hv">目标预测y </strong>，当它经过多次训练后，它会做出新的<strong class="je hv">预测y’</strong>。系统根据测试数据集中的随机样本测试这些预测，并确定系统的<strong class="je hv">验证准确性</strong>。一个系统可以在训练数据上达到99%的准确性，而在测试图像上只能达到50%或70%，因此游戏的真正名称是验证准确性，而不是准确性。</p><p id="ef12" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">优化器计算误差函数相对于模型权重的梯度(在数学术语中也称为偏导数</strong>)。</p><p id="9377" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">那是什么意思？想象一下分布在3D丘陵地形上的权重(如下图所示)，这被称为“误差地形”景观的“坐标”代表特定的权重配置(如地图上的坐标)，而景观的“高度”对应于不同权重配置的总误差/成本。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nj"><img src="../Images/c1c8258ecc0322c3f86d978923b910bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YTDwPXrnfbPndXxNw77O-w.png"/></div></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Error landscape</figcaption></figure><p id="f6c5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">优化器</strong>有一个重要的功能。它计算出<strong class="je hv">如何调整权重以尽量减小误差</strong>。它是通过从微积分书上取一页来做到这一点的。</p><p id="18e8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">什么是微积分？如果你翻开任何一本数学教科书，你都会发现一些超级无用的解释，比如这都是关于计算导数或微分的。但是这到底是什么意思呢？</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div class="fe ff nk"><img src="../Images/c3ee4f883e3176795c8aef634e74e700.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*WCsum9lcn6MPfkewWIHPog.jpeg"/></div></figure><p id="aeff" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">直到看了<a class="ae ka" href="http://amzn.to/2lOCeJT" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">Calculus Better Explained，作者Kalid Azad </strong> </a>才明白。</p><p id="4e0b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这是没人愿意解释的。</p><p id="6fbf" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">微积分做两件事:</strong></p><ul class=""><li id="209f" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">将事物分解成更小的块，也就是将一个圆分解成环。</li><li id="eb18" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">计算出变化率。</li></ul><p id="cd37" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">换句话说，如果我把一个圆切成环:</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div class="fe ff nl"><img src="../Images/c2a9155e0ef304abd77dbcb40abaeff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*IZ7PhVFiz_nOJ1tCxfMIHg.png"/></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Courtesy of the awesome <a class="ae ka" href="https://betterexplained.com/calculus/" rel="noopener ugc nofollow" target="_blank">Calculus Explained website</a>.</figcaption></figure><p id="b7d7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我可以展开这些环来做一些简单的数学计算:</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div class="fe ff nm"><img src="../Images/8e20f950a6e630b05799d33dc4f350dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*kmqnNplLKSTZglJ6qcigAg.png"/></div></figure><p id="3fe3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">嘭！</p><p id="883a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在我们的例子中，我们运行了一系列测试，调整了网络的权重，但是我们真的有更好的解决问题的方法吗？优化器告诉我们！</p><p id="70d6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你可以在这里或者在<a class="ae ka" href="http://cs231n.github.io/optimization-1/" rel="noopener ugc nofollow" target="_blank">斯坦福课程</a>中读到<strong class="je hv">梯度下降</strong>和<a class="ae ka" href="http://sebastianruder.com/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank">的大量细节，但是你可能会像我一样发现它们在细节上很长，而在为什么的关键问题上很轻。</a></p><p id="08aa" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">本质上，你要做的是尽量减少错误。这有点像在雾中开车。在这篇文章的早期版本中，我把梯度下降描述为一种寻找最优解的方法。但实际上，根本没有办法知道我们是否有一个“最优”的解决方案。如果我们知道那是什么，我们会直接去做。相反，我们试图找到一个“更好”的解决方案。这有点像进化。我们找到了足够适合生存的东西，但这并不意味着我们创造了爱因斯坦！</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nn"><img src="../Images/56baabe6035c1991a8d729e46abbb067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dU9pqAQk4ZeGjKo8tebzIw.jpeg"/></div></div></figure><p id="9396" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">想象一下你小时候玩马可波罗时的梯度下降</strong>。</p><p id="1308" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你闭上眼睛，你所有的朋友都在泳池里散开。你喊出“马可”，所有的孩子都必须回答“波罗”你用你的耳朵来判断你是越来越近还是越来越远。如果你在更远的地方，你会调整并尝试一条不同的道路。如果你靠近一点，你会一直朝那个方向走。在这里，我们要弄清楚如何最好地调整网络的权重，以帮助他们更好地了解世界。</p><p id="86cf" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们选择了本文中描述的“adam”优化器<a class="ae ka" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank">。我发现通过强力改变我的程序，似乎能产生最好的结果。这就是数据科学的艺术。没有一种算法可以统治所有这些问题。如果我改变网络的架构，我可能会发现不同的优化器工作得更好。</a></p><p id="c786" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">以下是Keras 中各种优化器的列表。</p><p id="a160" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">接下来，我们设置TensorBoard，这样我们就可以直观地了解网络的运行情况。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="918f" class="mh kr hu md b fv mi mj l mk ml"># Set up TensorBoard<br/>tb = TensorBoard(log_dir='./logs')</span></pre><p id="3179" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们所做的只是创建一个日志目录。现在，我们将训练模型，并将TensorBoard指向原木。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="6adf" class="mh kr hu md b fv mi mj l mk ml">model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_test, Y_test), callbacks=[tb])</span><span id="0358" class="mh kr hu md b fv mm mj l mk ml">score = model.evaluate(X_test, Y_test, verbose=0)</span><span id="edef" class="mh kr hu md b fv mm mj l mk ml">print('Test score:', score[0])<br/>print("Accuracy: %.2f%%" % (score[1]*100))</span></pre><p id="586d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">好吧，让我们把这个坏小子点燃，看看效果如何！</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="3d8e" class="mh kr hu md b fv mi mj l mk ml">50000/50000 [==============================] - 3s - loss: 0.4894 - acc: 0.8253 - val_loss: 0.6288 - val_acc: 0.7908<br/>Epoch 89/100<br/>50000/50000 [==============================] - 3s - loss: 0.4834 - acc: 0.8269 - val_loss: 0.6286 - val_acc: 0.7911<br/>Epoch 90/100<br/>50000/50000 [==============================] - 3s - loss: 0.4908 - acc: 0.8224 - val_loss: 0.6169 - val_acc: 0.7951<br/>Epoch 91/100<br/>50000/50000 [==============================] - 4s - loss: 0.4817 - acc: 0.8238 - val_loss: 0.6052 - val_acc: 0.7952<br/>Epoch 92/100<br/>50000/50000 [==============================] - 4s - loss: 0.4863 - acc: 0.8228 - val_loss: 0.6151 - val_acc: 0.7930<br/>Epoch 93/100<br/>50000/50000 [==============================] - 3s - loss: 0.4837 - acc: 0.8255 - val_loss: 0.6209 - val_acc: 0.7964<br/>Epoch 94/100<br/>50000/50000 [==============================] - 4s - loss: 0.4874 - acc: 0.8260 - val_loss: 0.6086 - val_acc: 0.7967<br/>Epoch 95/100<br/>50000/50000 [==============================] - 3s - loss: 0.4849 - acc: 0.8248 - val_loss: 0.6206 - val_acc: 0.7919<br/>Epoch 96/100<br/>50000/50000 [==============================] - 4s - loss: 0.4812 - acc: 0.8256 - val_loss: 0.6088 - val_acc: 0.7994<br/>Epoch 97/100<br/>50000/50000 [==============================] - 3s - loss: 0.4885 - acc: 0.8246 - val_loss: 0.6119 - val_acc: 0.7929<br/>Epoch 98/100<br/>50000/50000 [==============================] - 3s - loss: 0.4773 - acc: 0.8282 - val_loss: 0.6243 - val_acc: 0.7918<br/>Epoch 99/100<br/>50000/50000 [==============================] - 3s - loss: 0.4811 - acc: 0.8271 - val_loss: 0.6201 - val_acc: 0.7975<br/>Epoch 100/100<br/>50000/50000 [==============================] - 3s - loss: 0.4752 - acc: 0.8299 - val_loss: 0.6140 - val_acc: 0.7935<br/>Test score: 0.613968349266<br/>Accuracy: 79.35%</span></pre><p id="bd9b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们在100个纪元后达到了79%的准确率。对于几行代码来说还不错。现在你可能认为79%没那么好，但请记住，在2011年，这比Imagenet上的最先进水平要好，而且花了十年才达到这一水平！我们只用Keras Github的一些示例代码和一些调整就做到了这一点。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff no"><img src="../Images/aeeb8612503cc77a6936c2b9ef6e991a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LF6NWh79JPp6lRJa4JyusQ.jpeg"/></div></div></figure><p id="ae7e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你会注意到2012年是新想法开始出现的时候。</p><p id="bf8f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">人工智能研究人员Alex Krizhevsky，Ilya Sutskever和Geoffrey Hinton开发的AlexNet是第一个橙色点。它标志着当前深度学习复兴的开始。到第二年，每个人都在使用深度学习。到2014年，获奖的架构比人类水平的图像识别更好。</p><p id="7743" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">即便如此，这些架构通常与某些类型的问题紧密相关。当今最流行的几个架构，像<a class="ae ka" href="https://github.com/raghakot/keras-resnet" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">【ResNet】</strong></a>和<strong class="je hv">谷歌的</strong> <a class="ae ka" href="https://github.com/tensorflow/models/tree/master/inception" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">盗梦空间V3</strong></a><strong class="je hv">do</strong><a class="ae ka" href="http://oduerr.github.io/blog/2016/04/06/Deep-Learning_for_lazybones" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">在微小的CIFAR10镜像</strong> </a>上只有88%。它们在更大的CIFAR100设备上表现得更差。</p><p id="3b3b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">目前的艺术状态是<strong class="je hv"> DenseNet </strong>，它在2016年赢得了去年的ImageNet大赛。它啃过CIFAR10，<strong class="je hv">达到了惊人的94.81%的准确率</strong>拥有令人疯狂的深度250层和1530万个连接！跑起来绝对是个怪物。在一台Nvidia 1080GTX上，如果你用40 x 12型号运行它，达到你在下面的图表中看到的93%的准确率，它将需要一个月才能运行。哎哟！</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff np"><img src="../Images/1a29b77d11a8f2168acd01a2fbba50ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYmTbgX6nwRe-zZedtdwpA.jpeg"/></div></div></figure><p id="db19" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">也就是说，我鼓励你深入研究这些模型，看看你能从中学到什么。</p><p id="ed26" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我做了一些实验，并通过蛮力实验成功地拼凑了一个奇怪的架构，仅使用Keras层中的构建，没有自定义层，就达到了81.40%的准确率。 <a class="ae ka" href="https://github.com/the-laughing-monkey/learning-ai-if-you-suck-at-math/blob/master/Deep%20Learning%20Examples/keras-example-simple-convnet-15c6.py" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">你可以在Github这里找到</strong> </a> <strong class="je hv">。</strong></p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="5b4c" class="mh kr hu md b fv mi mj l mk ml"> Epoch 70/75<br/> 50000/50000 [==============================] - 10s - loss: 0.3503 - acc: 0.8761 - val_loss: 0.6229 - val_acc: 0.8070<br/> Epoch 71/75<br/> 50000/50000 [==============================] - 10s - loss: 0.3602 - acc: 0.8740 - val_loss: 0.6039 - val_acc: 0.8085<br/> Epoch 72/75<br/> 50000/50000 [==============================] - 10s - loss: 0.3543 - acc: 0.8753 - val_loss: 0.5986 - val_acc: 0.8094<br/> Epoch 73/75<br/> 50000/50000 [==============================] - 10s - loss: 0.3461 - acc: 0.8780 - val_loss: 0.6052 - val_acc: 0.8147<br/> Epoch 74/75<br/> 50000/50000 [==============================] - 10s - loss: 0.3418 - acc: 0.8775 - val_loss: 0.6457 - val_acc: 0.8019<br/> Epoch 75/75<br/> 50000/50000 [==============================] - 10s - loss: 0.3440 - acc: 0.8776 - val_loss: 0.5992 - val_acc: 0.8140<br/> Test score: 0.599217191744<br/> Accuracy: 81.40%</span></pre><p id="0ccd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们可以加载TensorBoard来可视化我们的表现。</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="d4d2" class="mh kr hu md b fv mi mj l mk ml">tensorboard --logdir=./logs</span></pre><p id="ba24" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在打开浏览器，转到以下URL:</p><pre class="lu lv lw lx fq mc md me mf aw mg dt"><span id="c63f" class="mh kr hu md b fv mi mj l mk ml">127.0.1.1:6006</span></pre><p id="ad6e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这是一段时间以来的培训截图。</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nq"><img src="../Images/1591cf21bb2933d91f56de4d648f94a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7_zbkcxImFfXjxgt7yvew.jpeg"/></div></div></figure><p id="ffb1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你可以看到我们很快开始超过收益递减点，大约在35个时期和79%。剩下的时间花在将它提高到81.40%上，并且可能在超过75个时期时过度拟合。</p><p id="78b5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">那么你会如何改进这个模型呢？</p><p id="6256" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">以下是一些策略:</p><ul class=""><li id="5262" class="kc kd hu je b jf jg jj jk jn ke jr kf jv kg jz kh ki kj kk dt translated">实现您自己的自定义层</li><li id="81ae" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">做图像增强，比如翻转图像，增强图像，扭曲图像，克隆图像等等</li><li id="c748" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">深入一点</li><li id="f72e" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">更改图层上的设置</li><li id="7cf1" class="kc kd hu je b jf kl jj km jn kn jr ko jv kp jz kh ki kj kk dt translated">通读获奖的架构论文，并堆积出你自己的具有相似特征的模型</li></ul><p id="4f9a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">因此，你已经达到了真正的数据科学艺术，即使用你的大脑来理解数据，并手工制作一个模型来更好地理解它。也许你会深入研究CIFAR10，并注意到提高这些图像的对比度真的会使图像突出。干吧！</p><p id="41a7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">不要害怕在Photoshop中加载东西，并开始摆弄过滤器，看看图像是否变得更清晰。弄清楚是否可以用Keras图像处理函数做同样的事情。</p><p id="7ae7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">深度学习远非灵丹妙药。做正确的事需要耐心和奉献。</p><p id="01b7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">它可以做令人难以置信的事情，但你可能会发现自己粘在你的工作站上，看着数字滴答几个小时，直到凌晨2点，毫无进展。</p><p id="be73" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">但随后你有了突破！</strong></p><p id="c3c8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这有点像神经网络经历的反复试验。尝试一些东西，更接近答案。试试别的，离远点。</p><p id="1f4e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我现在正在探索<a class="ae ka" href="http://nn.cs.utexas.edu/?neat" rel="noopener ugc nofollow" target="_blank">如何使用遗传算法来自动进化神经网络</a>。在这方面已经做了很多工作，但是还不够！</p><p id="1d06" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最终，我们将达到这样一个点，即通过引入一些库和一些预先训练的权重文件，许多架构都已成熟并易于实现，但这是企业it几年后的事情。</p><p id="209d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这个领域仍在快速发展，每天都有新的想法出现。好消息是，你正处于这波浪潮的早期。所以，放松一下，开始玩你自己的模型吧。</p><p id="00ee" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">学习。实验。学习。</p><p id="31c7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">做那件事，你不会出错的。</p><p id="ad5d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-8bdfb4b79037#.ng7ggn5d9" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">学习人工智能如果你数学很差——第一部分</strong></a><strong class="je hv"/>——这篇文章将指导你阅读一些必要的书籍，如果你从来都不是数学迷，但作为一个成年人你正在学习它。</p><p id="dc8b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-part-two-practical-projects-47d7a1e4e21f#.yo1o1ar5h" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">学习人工智能如果你数学很差——第二部分</strong></a><strong class="je hv">——实际项目</strong>——这篇文章指导你如何开始你的第一个项目。</p><p id="cd85" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p3-building-an-ai-dream-machine-or-budget-friendly-special-d5a3023140ef#.6frka033t" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">数学不好就学人工智能——第三部分</strong></a><strong class="je hv">——打造人工智能梦想机器</strong>——本文指导你获得一个强大的深度学习机器设置，并安装了所有最新最棒的框架。</p><p id="91d6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32#.2jpelkuhd" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">数学烂就学AI——第四部分——张量图解(带猫！)</strong> </a> —这个回答了一个古老的谜团:张量到底是个什么鬼？</p><p id="84f7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p5-deep-learning-and-convolutional-neural-nets-in-plain-english-cda79679bbe3#.xjah79lsd" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">学AI如果你数学很烂——第5部分——深度学习和卷积神经网络用简单的英语说</strong></a>——在这里我们创建了我们的第一个Python程序，并探索神经网络的内部工作原理！</p><p id="311a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p6-math-notation-made-easy-1277d76a1fe5" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">学人工智能如果你数学很烂——第六部分——数学符号变得简单</strong></a>——还在努力理解那些有趣的小符号吗？让我们现在就改变这一切！</p><p id="f9b3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://hackernoon.com/learning-ai-if-you-suck-at-math-p7-the-magic-of-natural-language-processing-f3819a689386" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">学AI如果你数学很烂——第七部分——自然语言处理的魔力</strong></a>——了解谷歌和Siri如何理解你喃喃自语。</p><p id="b2bc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt">############################################</p><p id="15b7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你喜欢我的作品，请让我有幸参观我的作品，因为这是我们一起改变未来的方式。帮我脱离母体，我会加倍回报你的慷慨，把我所有的时间和精力放在写作、研究和为你和世界提供令人惊奇的内容上。</p><p id="15dc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt">###########################################</p><p id="31e5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你喜欢这个教程，我希望你能鼓掌推荐给其他人。之后，请随时将文章通过电子邮件发送给朋友！非常感谢。</p><p id="17a1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt">###########################################</p><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div class="fe ff nr"><img src="../Images/524258472f427960c76fe5e46c7f374a.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*5GOTOJ42ui30Cu210u737g.png"/></div></figure><p id="57c7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">简单介绍一下我:我是一名作家、工程师和连续创业者。在过去的二十年中，我涉及了从Linux到虚拟化和容器的广泛技术。</p><p id="0184" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你可以看看我的最新小说， <a class="ae ka" href="http://amzn.to/2gAg249" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> <em class="kb">这是一部史诗般的中国科幻内战传奇</em> </strong> </a> <em class="kb">在这部小说中，中国摆脱了共产主义的枷锁，成为世界上第一个直接民主国家，运行着一个高度先进的、人工智能的去中心化应用平台，没有领导人。</em></p><h2 id="8be5" class="mh kr hu bd ks ns nt nu kw nv nw nx la jn ny nz le jr oa ob li jv oc od lm oe dt translated"><a class="ae ka" href="http://meuploads.com/join-my-readers-group/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> <em class="of">加入我的读者群就可以免费获得我的第一部小说《蝎子游戏》</em> </strong> </a> <strong class="ak"> <em class="of">。</em> </strong> <em class="of">读者们称之为</em> <strong class="ak"> <em class="of">【第一次神经癌的严重竞争】</em></strong><em class="of"/><strong class="ak"><em class="of">黑色侦探遇上约翰尼助记术。</em></strong><em class="of"/></h2><h2 id="1184" class="mh kr hu bd ks ns nt nu kw nv nw nx la jn ny nz le jr oa ob li jv oc od lm oe dt translated">最后，你可以<a class="ae ka" href="https://www.facebook.com/groups/1736763229929363/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">加入我的私人脸书小组，纳米机器人后人类刺客</strong> </a> <strong class="ak">，在这里我们讨论所有的科技、科幻、幻想等等。</strong></h2><p id="a076" class="pw-post-body-paragraph jc jd hu je b jf lo jh ji jj lp jl jm jn lq jp jq jr lr jt ju jv ls jx jy jz hn dt">############################################</p><p id="23c7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我偶尔会从我文章中的链接赚钱，但我只推荐我拥有、使用和喜欢的东西。在这里查看我的<a class="ae ka" href="http://meuploads.com/disclosure/" rel="noopener ugc nofollow" target="_blank">完整保单</a>。</p><p id="70ca" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt">############################################</p><p id="2a64" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">感谢阅读！</p><div class="lu lv lw lx fq ab cb"><figure class="og iv oh oi oj ok ol paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="og iv oh oi oj ok ol paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="og iv oh oi oj ok ol paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="mu mv mw"><p id="072c" class="jc jd kb je b jf jg jh ji jj jk jl jm mx jo jp jq my js jt ju mz jw jx jy jz hn dt translated"><a class="ae ka" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae ka" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae ka" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae ka" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="jc jd kb je b jf jg jh ji jj jk jl jm mx jo jp jq my js jt ju mz jw jx jy jz hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae ka" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae ka" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="lu lv lw lx fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff om"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></div></figure></div></div>    
</body>
</html>