<html>
<head>
<title>Training an Architectural Classifier — IV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练建筑分类器— IV</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/training-an-architectural-classifier-iv-4f76bc6844bc?source=collection_archive---------29-----------------------#2017-10-11">https://medium.com/hackernoon/training-an-architectural-classifier-iv-4f76bc6844bc?source=collection_archive---------29-----------------------#2017-10-11</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="b676" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">卷积神经网络</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/8fb4288b08f1fe0273d8ea90bf448ad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rbGHwiIKi7RS6XzU_bFjjQ.png"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">The basic architecture of a convolutional network. source[<a class="ae jz" href="https://www.clarifai.com/technology" rel="noopener ugc nofollow" target="_blank">4</a>]</figcaption></figure><p id="d072" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><em class="kw">这是5篇文章系列的第4部分:</em></p><ol class=""><li id="a045" class="kx ky hu kc b kd ke kg kh kj kz kn la kr lb kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-5f1b4f512368"> <em class="kw">训练一个架构分类器:动机</em> </a></li><li id="4d9f" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-ii-bf29eca3cfa6"> <em class="kw">训练一个架构分类器:Softmax回归</em> </a></li><li id="8d2c" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iii-84dd5f3cf51c"> <em class="kw">训练一个架构分类器:深度神经网络</em> </a></li><li id="b116" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iv-4f76bc6844bc"> <em class="kw">训练一个架构分类器:卷积网络</em> </a></li><li id="6317" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-v-fe82e83e94ec"> <em class="kw">训练一个架构分类器:迁移学习</em> </a></li></ol><p id="7efa" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt ll translated">在之前的文章中，我探索了深度神经网络来解决我们的厨房分类问题。虽然他们改进了简单的逻辑回归模型，但他们表现出非常强的过度拟合，即使在剔除正则化的情况下也是如此。我假设这至少部分是由于维度的诅咒；我们有少量非常高维的数据，这降低了网络找到泛化能力良好的权重的概率。</p><p id="d6f7" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">解决这个问题的一个办法是降低数据的维度，但我们希望以一种智能的方式来实现这一点。如果我们简单地缩小图像尺寸，我们很可能会丢掉重要的信息。相反，我们将转向一种叫做卷积的深度学习架构，首先挑选出最重要的细节，然后在将其传递给分类层之前去掉其余的。</p><h2 id="5d2d" class="lu lv hu bd lw lx ly lz ma mb mc md me kj mf mg mh kn mi mj mk kr ml mm mn mo dt translated">卷积架构</h2><p id="4462" class="pw-post-body-paragraph ka kb hu kc b kd mp iv kf kg mq iy ki kj mr kl km kn ms kp kq kr mt kt ku kv hn dt translated">卷积实际上在概念上很容易理解。卷积将采用一个非常小的图像(通常小于5px乘以5px ),称为滤波器，并在输入图像上滑动该滤波器。空间关系得到了维护，因为我们没有像以前那样将输入扁平化。为了形象化这一点，考虑下面的动画:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mu"><img src="../Images/0e7de8a67e0c197106c87d417e45b499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*ZCjPUFrB6eHPRi4eyP6aaA.gif"/></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">Convolution being applied. source[<a class="ae jz" href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution" rel="noopener ugc nofollow" target="_blank">1</a>]</figcaption></figure><p id="9558" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">黄色滤镜在绿色输入图像上一次滑动1个像素，将它们的值(红色)组合成粉红色输出“卷积特征”。对于一个给定的卷积层，我们可以用许多不同的过滤器来完成，产生多个输出图像。那么这在实际图像上是什么样的呢？这是一个使用滤镜生成边缘的动画:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mv"><img src="../Images/6696be14fd8e2a392c954e1f0a4755dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*Y0tvNnH7sXHw2zP7TrCKgA.gif"/></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">Convolution producing two feature maps. source[<a class="ae jz" href="http://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/" rel="noopener ugc nofollow" target="_blank">2</a>]</figcaption></figure><p id="b4ad" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">您可以看到，根据使用的过滤器，从输入图像中“发现”了不同的特征。在早期阶段，应用在大图像上的小过滤器会发现非常小的尺度特征，比如边缘。如果我们在这些之上堆积更多的回旋，就可以发现越来越复杂和大规模的特征；从边缘，到角落，到眼睛，到脸，到人。</p><h2 id="ec37" class="lu lv hu bd lw lx ly lz ma mb mc md me kj mf mg mh kn mi mj mk kr ml mm mn mo dt translated">空间池</h2><p id="b451" class="pw-post-body-paragraph ka kb hu kc b kd mp iv kf kg mq iy ki kj mr kl km kn ms kp kq kr mt kt ku kv hn dt translated">卷积的第二个重要步骤是减少这些特征图的维数，去掉不太重要的信息。这通常是通过一个称为空间池的函数来完成的。空间池的概念是定义一些空间窗口，如2px乘2px，并将该窗口中的值组合成一个值。2px乘2px池会将特征地图的大小减半。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mw"><img src="../Images/43c9d1def28f9c877534635172a57cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GksqN5XY8HPpIddm5wzm7A.jpeg"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">Max Pooling reducing an image by half. source[<a class="ae jz" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">3</a>]</figcaption></figure><p id="9d4a" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">上面显示的是max pooling，我们从窗口中取出最大的数值，丢弃其余的。这是最常见的池形式，也是我将在笔记本中使用的形式。</p><h2 id="c770" class="lu lv hu bd lw lx ly lz ma mb mc md me kj mf mg mh kn mi mj mk kr ml mm mn mo dt translated">《恋恋笔记本》</h2><p id="3d7a" class="pw-post-body-paragraph ka kb hu kc b kd mp iv kf kg mq iy ki kj mr kl km kn ms kp kq kr mt kt ku kv hn dt translated">出于两个原因，本笔记本中的一些代码结构看起来会有些不同:</p><ol class=""><li id="97a6" class="kx ky hu kc b kd ke kg kh kj kz kn la kr lb kv lc ld le lf dt translated">在这个实验中，慢速训练让我通过队列跑步者输入数据，在这篇文章底部的旁注中可以读到更多。</li><li id="b3c9" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated">由于架构定义变得非常冗长，我开始使用Tensorflow的Slim模块。</li></ol><p id="f59c" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">TensorFlow Slim只是一个用于定义层和变量的更简洁的语法。例如，TensorFlow中的全连接图层:</p><pre class="jk jl jm jn fq mx my mz na aw nb dt"><span id="2692" class="lu lv hu my b fv nc nd l ne nf">W_one = tf.get_variable('weights_1', [85 * 85 * 3, 1000], initializer=xavier())<br/>b_one = tf.get_variable('bias_1', [1000], initializer=zeros())<br/>logits_one = tf.add(tf.matmul(inputs, W1), b1)<br/>layer_one = tf.nn.relu(logits1)</span></pre><p id="0b40" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">在TensorFlow Slim中变得更小:</p><pre class="jk jl jm jn fq mx my mz na aw nb dt"><span id="2b38" class="lu lv hu my b fv nc nd l ne nf">layer_one = slim.fully_connected(inputs, 1000)</span></pre><p id="c1b5" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">记住这些概念，下面是将卷积网络应用于厨房分类问题的实验笔记本:</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="ng nh l"/></div></figure><p id="8773" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">更加成功！验证准确率现在已经高达70%左右，接近77%。随着更多的架构实验，低80应该是可以实现的。像往常一样，下面是tensorboard总结:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff ni"><img src="../Images/01daa75ec3ac53bf8f7fd484906d50e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UoTySTQJXTlZ0zvkQ4VPMg.png"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">tensorboard summary for training. Blue: training accuracy, Purple: validation accuracy.</figcaption></figure><p id="316f" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">在最后一本笔记本中，我将尝试一些稍微不同的东西，一种被称为<em class="kw">迁移学习的技术。</em>快来看看！</p><p id="8920" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-v-fe82e83e94ec">接下来:转移学习</a></p><p id="4f6b" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><em class="kw">顺便说一句，我在上次培训中注意到GPU没有得到充分利用。以下是nvidia-smi工具在训练时的输出:</em></p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nj"><img src="../Images/9f760ac4f080c101cc8becc0a8d08e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cbqdcjZcee3XM4pOhHvlqw.png"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">nvidia-smi output on starved GPU</figcaption></figure><p id="4c7c" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><em class="kw">您可以看到，尽管培训时间很长，但我们的利用率只有9%左右，而且这一数字波动很大。这表明GPU急需数据。训练示例不能足够快地从CPU内存中移出并移到GPU上，以跟上GPU通过计算燃烧的速度。因此，当GPU等待数据输入时，我们看到了低利用率。其原因和解决方案确实值得他们自己写一篇文章，但简单来说:TensorFlow的feed_dict输入系统实际上是为了在小数据集上进行测试和玩具示例。合适的饲养数据生产方式是使用</em> <a class="ae jz" href="https://www.tensorflow.org/programmers_guide/threading_and_queues" rel="noopener ugc nofollow" target="_blank"> <em class="kw">队列跑者</em> </a> <em class="kw">。运行者将利用多线程从磁盘或内存中读取数据，并保持GPU运行良好。缺点是它增加了一些代码复杂性。我不会详细描述它们的实现，但希望你能跟上笔记本上发生的事情。</em></p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="nk nh l"/></div></figure></div></div>    
</body>
</html>