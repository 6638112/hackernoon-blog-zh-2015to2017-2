<html>
<head>
<title>Training an Architectural Classifier — V</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练架构分类器— V</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/training-an-architectural-classifier-v-fe82e83e94ec?source=collection_archive---------22-----------------------#2017-10-16">https://medium.com/hackernoon/training-an-architectural-classifier-v-fe82e83e94ec?source=collection_archive---------22-----------------------#2017-10-16</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="8a67" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">迁移学习</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/7c5015e1f21ab5245cbc6bf9c513c54c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FsiN9x7UpByRq7voZnb7eg.jpeg"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">Transferring knowlege gained by one model, into another. source[<a class="ae jz" href="https://commons.wikimedia.org/wiki/File:Knowledge-sharing.jpg" rel="noopener ugc nofollow" target="_blank">1</a>]</figcaption></figure><p id="374d" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><em class="kw">这是5篇文章系列的第5部分:</em></p><ol class=""><li id="a045" class="kx ky hu kc b kd ke kg kh kj kz kn la kr lb kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-5f1b4f512368"> <em class="kw">训练一个架构分类器:动机</em> </a></li><li id="4d9f" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-ii-bf29eca3cfa6"> <em class="kw">训练一个架构分类器:Softmax回归</em> </a></li><li id="8d2c" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iii-84dd5f3cf51c"> <em class="kw">训练一个架构分类器:深度神经网络</em> </a></li><li id="b116" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iv-4f76bc6844bc"> <em class="kw">训练一个架构分类器:卷积网络</em> </a></li><li id="6317" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated"><a class="ae jz" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-v-fe82e83e94ec"> <em class="kw">训练一个架构分类器:迁移学习</em> </a></li></ol><p id="f818" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">在本系列的最后一篇文章中，我将尝试使用一种叫做<em class="kw">迁移学习</em>的技术来提高我们之前使用卷积网络的模型的准确性。</p><h2 id="2c38" class="ll lm hu bd ln lo lp lq lr ls lt lu lv kj lw lx ly kn lz ma mb kr mc md me mf dt translated">迁移学习</h2><p id="76bb" class="pw-post-body-paragraph ka kb hu kc b kd mg iv kf kg mh iy ki kj mi kl km kn mj kp kq kr mk kt ku kv hn dt translated">简而言之，迁移学习背后的想法是采用一个已经为不同的任务训练过的模型，并将其作为你的任务的起点。</p><p id="eef7" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">一个模型基本上有两个组成部分:</p><ol class=""><li id="3566" class="kx ky hu kc b kd ke kg kh kj kz kn la kr lb kv lc ld le lf dt translated">它执行的数学运算(它的体系结构)。</li><li id="75da" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated">通过训练获得的体重。</li></ol><p id="b6d5" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt ml translated">人们通常会选择一个已知的公共架构，该架构在与他们的问题领域相关的基准测试中表现良好。图像识别的一个基准是ILSVRC(通常简称为ImageNet)。ImageNet涵盖了超过1000个类别的非常广泛的训练数据集。这使得在it上表现良好的模型非常适合迁移学习，因为它们往往能够很好地概括。因此，如果您选择一个在ImageNet上得到验证的架构，它很可能对您的问题也有很高的准确性。</p><p id="e34c" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt ml translated">如果您从ImageNet获得该架构的副本，并且该架构的所有训练权重都是从ImageNet获得的，那么您可以从比随机初始化更准确的位置开始自己的训练。这意味着训练时间将比你从头开始训练要短得多。</p><p id="b29f" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">唯一要做的工作是为您的特定任务和输出类重新训练模型，或者它的一部分。</p><h2 id="3638" class="ll lm hu bd ln lo lp lq lr ls lt lu lv kj lw lx ly kn lz ma mb kr mc md me mf dt translated">履行</h2><p id="6dcf" class="pw-post-body-paragraph ka kb hu kc b kd mg iv kf kg mh iy ki kj mi kl km kn mj kp kq kr mk kt ku kv hn dt translated">在几乎所有的深层架构中，最后一层将是一个分类器，其神经元数量等于它可以预测的类别数量。要调整一个<a class="ae jz" href="https://hackernoon.com/tagged/network" rel="noopener ugc nofollow" target="_blank">网络</a>来传输<a class="ae jz" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank">学习</a>，只需切断最后一层，用你自己的、适合你任务的层来替换它(和它的权重)。</p><p id="df78" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">一旦你既有建筑又有重量，你也有一些选择可以做。如果您自己的数据集足够大，并且您有足够的计算资源在您完全选择的架构上运行训练，您可以简单地使用预训练的权重作为初始值，并继续正常训练模型。如果你缺少这两者中的任何一个，那么值得探索冻结网络早期层的权重(至少在卷积网络中这些更一般化)，并且只允许后面的层或者甚至只是输出层经历梯度下降。这可以显著降低计算成本，因为您不必通过整个网络反向传播误差，并且通常会产生非常好的精度。</p><p id="7858" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">绝对最快的方法是将数据集中的每个影像向前传播到要保留的最后一个图层，然后保存从该图层生成的激活值(有时称为“瓶颈”值)。这些值成为您的新的预处理“图像”，您可以在其上训练一个非常简单的分类器。这样，前向推进步骤的计算成本仅对每个图像收取一次，而不是在每个训练时期收取一次。</p><p id="dfbc" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">您还可以简单地在您喜欢的地方分割预训练的网络，然后在其上连接新的输出层。</p><h2 id="afc1" class="ll lm hu bd ln lo lp lq lr ls lt lu lv kj lw lx ly kn lz ma mb kr mc md me mf dt translated">克拉斯</h2><p id="ec34" class="pw-post-body-paragraph ka kb hu kc b kd mg iv kf kg mh iy ki kj mi kl km kn mj kp kq kr mk kt ku kv hn dt translated">特别是一个深度学习框架，<a class="ae jz" href="https://keras.io" rel="noopener ugc nofollow" target="_blank"> Keras </a>，让这变得非常简单，这也是我将在下面的笔记本中使用的。您还会注意到Keras在无数其他方面使生活变得更加容易，从数据加载到图像增强，到架构定义和培训；这是一个非常棒的图书馆。</p><p id="d13f" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">为了在Keras中完成迁移学习，</p><ol class=""><li id="8dbe" class="kx ky hu kc b kd ke kg kh kj kz kn la kr lb kv lc ld le lf dt translated">我们将从它的库中导入一个模型(我将使用VGG16)。</li><li id="f465" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated">砍掉分类层和倒数第二个全连接层(您实际上可以将其指定为导入选项)。</li><li id="682b" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated">通过网络向前运行所有图像示例，将来自最后卷积的激活值存储为一组新的“图像”特征。</li><li id="f26e" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated">建立一个简单的2层全连接模型，具有2个神经元的softmax输出。</li><li id="98c1" class="kx ky hu kc b kd lg kg lh kj li kn lj kr lk kv lc ld le lf dt translated">使用预先计算的VGG特征作为分类器的输入进行训练。</li></ol><p id="b895" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">只有我们创建的最后2层将被训练，但是它们被馈送的特征将经历ImageNet训练的VGG16网络的全部提取能力。代码见笔记本:</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mu mv l"/></div></figure><p id="851a" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">我们最终获得了91.9 <strong class="kc hv"> % </strong>的准确率，只需要很少的调整或训练时间，这比我们最初使用softmax回归获得的57%的准确率有了巨大的提高，随着更多的训练、数据和实验，准确率只会继续提高。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mw mv l"/></div></figure></div></div>    
</body>
</html>