# 强化学习第 0 部分

> 原文：<https://medium.com/hackernoon/reinforcement-learning-part-0-8c2c3efe0ad6>

> [你可以在 Twitter @bhutanisanyam1](http://twitter.com/bhutanisanyam1) 上找到我，在 [Linkedin 上联系我](https://www.linkedin.com/in/sanyambhutani/)

本系列将采用深入研究代码的形式，并附带解释和演练。

接下来将会有一系列的帖子，以最初级的吸引人的方式带你浏览一些概念。

# **那么强化学习到底是什么？**

在这个系列中，你会得到一个完整的数学上和程序上合理的答案，但是这里有一个有趣的答案。

想象一下，你在一家面包店，你的主管告诉你要烤一个美味的蛋糕。

![](img/46a7fb225f8159861d2db7ce6158bc71.png)

你的上司是一个相当严格的人，他让你去发现最好的食谱。然而，由于主管讨厌你，每次你烤了一个糟糕的蛋糕，她都会痛打你一顿(这可能不是最好的工作场所)。

现在，你是个聪明的孩子！你开始做一个实验。你记录你的表现和每一次尝试的味道。

你的最终目标是给你的主管留下深刻印象(最大化你的奖励)。你开始是一个没有经验的人。你在面包店(你的环境)周围玩耍，不断尝试，直到你最终打动你的主管(奖励)

你开始加盐，烧掉一些东西，每次这样做都会被痛打一顿(接受惩罚)，因为你很聪明，你会确保自己不会再这样做(跟踪以前的动作)。

最后，一旦你烤出了最好的蛋糕，并实现了你的最高目标，你就终于得到了“训练”。

这就是 RL 的工作原理。

*   有一个代理人:你。
*   在一个环境中:面包店。
*   谁的目标是最大化回报:接受主管的评估。
*   代理不断从[环境](https://hackernoon.com/tagged/environment)中获得[反馈](https://hackernoon.com/tagged/feedback):主管。
*   一个正反馈代表正确的一步，一个负反馈代表错误的一步。
*   代理有一个记忆，它以前的行动，在此基础上学习。
*   代理人保持互动，直到回报最大化。

> 订阅我的[时事通讯](http://tinyletter.com/sanyambhutani/)获取深度学习和计算机视觉的每周精选列表