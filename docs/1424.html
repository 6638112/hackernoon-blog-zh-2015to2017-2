<html>
<head>
<title>How to crawl the web politely with Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用Scrapy有礼貌地抓取网页</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/how-to-crawl-the-web-politely-with-scrapy-15fbe489573d?source=collection_archive---------1-----------------------#2016-10-26">https://medium.com/hackernoon/how-to-crawl-the-web-politely-with-scrapy-15fbe489573d?source=collection_archive---------1-----------------------#2016-10-26</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="4b1f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">网络爬行的第一条规则是你不能损害网站。网络爬行的第二条规则是你做<strong class="it hv">而不是</strong>损害网站。我们是网络数据民主化的支持者，但不是以网站所有者为代价。</p><p id="fcc7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在本帖中，我们为想要礼貌周到的网络爬虫的<a class="ae jp" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank"> Scrapy </a>用户(Scrapy是一个100%开源的网络爬虫框架)分享一些小技巧。</p><p id="ff18" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">不管你叫它们蜘蛛、爬虫还是机器人，让我们一起创造一个Baymaxs、WALL-Es和R2-D2s的世界，而不是一个HAL 9000s、T-1000和威震天的世界末日荒原。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff jq"><img src="../Images/6514b6bcae7d1b39f7bdaf55c00435cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*YSO3AbxfWQ6Bc8McB5-dGA.png"/></div><figcaption class="jy jz fg fe ff ka kb bd b be z ek">Embrace the lovable bots</figcaption></figure><h1 id="c209" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">是什么让爬虫变得有礼貌？</h1><blockquote class="la lb lc"><p id="6701" class="ir is ld it b iu iv iw ix iy iz ja jb le jd je jf lf jh ji jj lg jl jm jn jo hn dt translated">一个有礼貌的爬虫尊重机器人。txt <br/>一个有礼貌的爬虫从不降低网站的性能<br/>一个有礼貌的爬虫用联系信息识别它的创建者<br/>一个有礼貌的爬虫不是系统管理员的眼中钉</p></blockquote><h1 id="7722" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">robots.txt</h1><p id="1637" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">始终确保您的爬虫遵循网站的robots.txt文件中定义的规则。这个文件通常可以在一个网站(www.example.com/robots.txt)的根目录下找到，它描述了根据<a class="ae jp" href="https://support.google.com/webmasters/answer/6062608?hl=en" rel="noopener ugc nofollow" target="_blank">机器人排除标准</a>爬虫应该或不应该爬行的内容。一些网站甚至使用爬虫的用户代理为不同的网络爬虫指定单独的规则:</p><pre class="jr js jt ju fq lm ln lo lp aw lq dt"><span id="1949" class="lr kd hu ln b fv ls lt l lu lv">User-agent: Some_Annoying_Bot<br/>Disallow: /</span><span id="09ee" class="lr kd hu ln b fv lw lt l lu lv">User-Agent: *<br/>Disallow: /*.json<br/>Disallow: /api<br/>Disallow: /post<br/>Disallow: /submit<br/>Allow: /</span></pre><h1 id="6211" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">爬行延迟</h1><p id="079d" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">拥有一个有礼貌的爬虫的关键任务是确保你的爬虫不会太猛烈地攻击一个网站。遵循robots.txt Crawl-Delay指令，遵守爬网程序在请求之间应该等待的延迟。</p><p id="73d1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当一个网站的请求数量超过web服务器的处理能力时，它可能会变得没有响应。不要成为让网站管理员头疼的人。</p><h1 id="b89d" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">用户代理</h1><p id="a962" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">然而，如果你忽略了上面的基本规则(或者你的爬虫已经获得了侵略性的感知)，需要有一种方法让网站所有者联系你。为此，您可以在请求的用户代理标题中包含您的公司名称和电子邮件地址或网站。比如谷歌的爬虫用户代理就是“Googlebot”。</p><h1 id="445a" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">如何礼貌地使用Scrapy</h1><p id="735c" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">Scrapy 有点像擎天柱:友好、快速，无论如何都能完成任务。然而，就像擎天柱和他的汽车人同伴一样，Scrapy偶尔也需要被控制。因此，这是确保Scrapy尽可能礼貌的本质。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><a href="https://scrapy.org/"><div class="fe ff lx"><img src="../Images/44571c27d509bfba2875f37072f09688.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*FsyqhfN3evDrckB5IH_h8w.png"/></div></a></figure><h1 id="d39a" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">Robots.txt</h1><p id="a0e9" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">默认情况下，使用Scrapy 1.1+创建的爬虫已经尊重robots.txt。如果您的爬网程序是使用以前版本的Scrapy生成的，您可以通过将它添加到项目的设置中来启用此功能。</p><pre class="jr js jt ju fq lm ln lo lp aw lq dt"><span id="4b9d" class="lr kd hu ln b fv ls lt l lu lv">ROBOTSTXT_OBEY = True</span></pre><p id="e091" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">然后，每当您的爬虫程序试图从不允许的URL下载页面时，您将会看到这样的消息:</p><pre class="jr js jt ju fq lm ln lo lp aw lq dt"><span id="8c55" class="lr kd hu ln b fv ls lt l lu lv">2016-08-19 16:12:56 [scrapy] DEBUG: Forbidden by robots.txt: &lt;GET http://website.com/login&gt;</span></pre><h1 id="eae6" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">识别您的爬虫</h1><p id="6cd1" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">如果系统管理员对您的爬虫有任何问题，为他们提供一种容易联系您的方式是很重要的。如果你不这样做，他们将不得不挖掘他们的日志，寻找违规的IP。</p><p id="eeef" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">善待你生活中友好的系统管理员，并通过Scrapy USER_AGENT设置识别你的爬虫。分享您的爬虫名称、公司名称和联系电子邮件:</p><pre class="jr js jt ju fq lm ln lo lp aw lq dt"><span id="829d" class="lr kd hu ln b fv ls lt l lu lv">USER_AGENT = 'MyCompany-MyCrawler (bot@mycompany.com)'</span></pre><h1 id="940d" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">引入延迟</h1><p id="0c5b" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">刺痒蜘蛛速度惊人。它们可以处理许多并发请求，并充分利用您的带宽和计算能力。然而，权力越大，责任越大。</p><p id="772d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了避免过于频繁地访问web服务器，您需要在您的项目中(或者在您的蜘蛛中)使用<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/settings.html?highlight=download_delay#download-delay" rel="noopener ugc nofollow" target="_blank"> DOWNLOAD_DELAY </a>设置。Scrapy将在对同一域的连续请求之间引入一个范围从0.5 * DOWNLOAD_DELAY到1.5 * DOWNLOAD_DELAY秒的随机延迟。如果你想坚持你定义的确切的下载延迟，你必须禁用<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/settings.html?highlight=download_delay#randomize-download-delay" rel="noopener ugc nofollow" target="_blank">随机化下载延迟</a>。</p><p id="1fcb" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">默认情况下，DOWNLOAD_DELAY设置为0。要在爬网程序的请求之间引入5秒钟的延迟，请将其添加到您的设置中，py:</p><pre class="jr js jt ju fq lm ln lo lp aw lq dt"><span id="6324" class="lr kd hu ln b fv ls lt l lu lv">DOWNLOAD_DELAY = 5.0</span></pre><p id="be82" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果您有一个爬行多个站点的多蜘蛛项目，您可以使用download_delay(是的，是小写)蜘蛛属性为每个蜘蛛定义不同的延迟:</p><pre class="jr js jt ju fq lm ln lo lp aw lq dt"><span id="676b" class="lr kd hu ln b fv ls lt l lu lv">class MySpider(scrapy.Spider):<br/>    name = 'myspider'<br/>    download_delay = 5.0<br/>    ...</span></pre><h1 id="ef64" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">每个域的并发请求</h1><p id="2c65" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">另一个让你的蜘蛛更有礼貌的设置是每个域并发请求的数量。默认情况下，Scrapy将同时向任何给定的域发送最多8个请求，但是您可以通过更新<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/settings.html#concurrent-requests-per-domain" rel="noopener ugc nofollow" target="_blank">CONCURRENT _ REQUESTS _ PER _ DOMAIN</a>设置来更改该值。</p><p id="56a8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">注意，<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/settings.html?highlight=download_delay#concurrent-requests" rel="noopener ugc nofollow" target="_blank"> CONCURRENT_REQUESTS </a>设置定义了Scrapy的下载器将为所有蜘蛛执行的最大并发请求量。当你同时抓取多个域时，调整这个设置更多的是关于你自己的服务器性能/带宽，而不是你的目标。</p><h1 id="2058" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">自动油门拯救世界</h1><p id="bf9b" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">网站可以处理的请求数量差异很大。为你正在浏览的每个网站手动调整这个就像看着油漆变干一样有趣。为了拯救你的理智，Scrapy提供了一个名为<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/autothrottle.html" rel="noopener ugc nofollow" target="_blank"> AutoThrottle </a>的扩展。</p><p id="ae78" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">自动油门根据当前web服务器负载自动调整请求之间的延迟。它首先计算一个请求的等待时间。然后，它将调整同一域的请求之间的延迟，使得不超过<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/autothrottle.html#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY" rel="noopener ugc nofollow" target="_blank">个AUTOTHROTTLE _ TARGET _ CONCURRENCY</a>个请求同时处于活动状态。它还确保请求在给定的时间跨度内均匀分布。</p><p id="ad9f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">要启用自动油门，只需将其包含在项目的设置中。</p><pre class="jr js jt ju fq lm ln lo lp aw lq dt"><span id="f050" class="lr kd hu ln b fv ls lt l lu lv">AUTOTHROTTLE_ENABLED = True</span></pre><p id="66cb" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae jp" href="https://scrapinghub.com/scrapy-cloud/" rel="noopener ugc nofollow" target="_blank"> Scrapy Cloud </a>用户不必担心启用它，因为它已经默认启用。</p><p id="716f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有一个<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/autothrottle.html#settings" rel="noopener ugc nofollow" target="_blank">大范围的设置</a>来帮助你调整油门机制，所以玩得开心点！</p><h1 id="7d4e" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">使用HTTP缓存进行开发</h1><p id="a014" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">开发网络爬虫是一个迭代的过程。然而，运行爬虫来检查它是否工作意味着每次测试都要多次访问服务器。为了帮助你避免这种不礼貌的活动，Scrapy提供了一个名为<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpcache" rel="noopener ugc nofollow" target="_blank"> HttpCacheMiddleware </a>的内置中间件。您可以通过将它包含在项目的设置中来启用它，py:</p><pre class="jr js jt ju fq lm ln lo lp aw lq dt"><span id="c044" class="lr kd hu ln b fv ls lt l lu lv">HTTPCACHE_ENABLED = True</span></pre><p id="9d39" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一旦启用，它将缓存蜘蛛发出的每个请求以及相关的响应。所以下一次你运行你的蜘蛛时，它不会向服务器请求已经完成的请求。这是一个双赢的局面:你的测试会运行得更快，网站也会节省资源。</p><h1 id="94bb" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">不要抓取，使用API</h1><p id="2c4d" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">许多网站提供HTTP APIs，以便第三方可以使用他们的数据，而不必抓取他们的网页。在构建web scraper之前，检查目标网站是否已经提供了您可以使用的HTTP API。如果有，就用API。同样，这是一个双赢的局面:你避免了钻研页面的HTML，你的爬虫变得更加健壮，因为它不需要依赖于网站的布局。</p><h1 id="1ea4" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">Zyte滥用报告表</h1><p id="8d37" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">嘿，使用我们<a class="ae jp" href="https://www.zyte.com/scrapy-cloud/" rel="noopener ugc nofollow" target="_blank"> Scrapy Cloud </a>平台的人们！我们相信你会负责任地爬行，但为了支持网站管理员，我们提供了一个<a class="ae jp" href="https://www.zyte.com/contact-us/" rel="noopener ugc nofollow" target="_blank">滥用报告表</a>，他们可以报告在我们平台上运行的爬虫的任何不当行为。我们会友好地传递消息，以便您可以修改您的抓取，避免破坏一个系统管理员的一天。如果你的爬虫正在变成天网和践踏人类法律的<a class="ae jp" href="https://www.zyte.com/terms-policies/terms-of-service/" rel="noopener ugc nofollow" target="_blank"/>，我们保留停止它们爬行活动的权利，从而避免机器人的末日。</p><h1 id="cd84" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">包裹</h1><p id="9729" class="pw-post-body-paragraph ir is hu it b iu lh iw ix iy li ja jb jc lj je jf jg lk ji jj jk ll jm jn jo hn dt translated">让我们都尽自己的一份力量来保持系统管理员、网站所有者和开发者之间的和平，确保我们的网络爬行项目尽可能地无创。请记住，我们需要团结起来，以推迟我们的机器人霸主的崛起，所以让我们保持我们的爬虫，蜘蛛和机器人礼貌。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff ly"><img src="../Images/e5ed7edd63b1fed535c7cff0ce5519fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*kgoZTFROt7PpugiqcGHWLQ.jpeg"/></div></figure><p id="c026" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所有网站所有者，帮助爬虫，确保你的网站有HTTP API。</p></div><div class="ab cl lz ma hc mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="hn ho hp hq hr"><p id="1c01" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae jp" href="https://www.zyte.com/scrapy-cloud/" rel="noopener ugc nofollow" target="_blank">刺痒云永远免费</a>是刺痒果冻的花生酱。希望你学到了一些既能加快抓取速度又能防止滥用投诉的技巧。</p></div><div class="ab cl lz ma hc mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="hn ho hp hq hr"><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/7c7fe2e670081a58430f9315be2e77ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*eB6mGeLhPSP3hXrcrtRuqQ.jpeg"/></div></figure><p id="7090" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这篇帖子是Zyte(前身为Scrapinghub)的开发者巴尔迪尔·斯图姆(<a class="ae jp" href="https://twitter.com/stummjr" rel="noopener ugc nofollow" target="_blank">@ stumjr</a>)写的。</p><p id="7927" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">请用心“推荐”，让别人更好地了解如何礼貌地使用Scrapy。</p><p id="220a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae jp" href="https://www.zyte.com/data-extraction/" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv">了解更多关于网络抓取和网络数据能为你做什么</strong> </a> <strong class="it hv">。</strong></p><p id="2a93" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最初发表在Zyte博客上。</p><div class="jr js jt ju fq ab cb"><figure class="mh jv mi mj mk ml mm paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="mh jv mi mj mk ml mm paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="mh jv mi mj mk ml mm paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="la lb lc"><p id="f922" class="ir is ld it b iu iv iw ix iy iz ja jb le jd je jf lf jh ji jj lg jl jm jn jo hn dt translated"><a class="ae jp" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是T21家庭的一员。我们现在<a class="ae jp" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae jp" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="ir is ld it b iu iv iw ix iy iz ja jb le jd je jf lf jh ji jj lg jl jm jn jo hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae jp" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae jp" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="jr js jt ju fq jv fe ff paragraph-image"><a href="https://goo.gl/Ahtev1"><div class="fe ff mn"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></a></figure></div></div>    
</body>
</html>