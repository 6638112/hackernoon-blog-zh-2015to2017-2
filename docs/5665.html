<html>
<head>
<title>Where’s Waldo : Terminator Edition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">沃尔多:终结者版在哪里</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/wheres-waldo-terminator-edition-8b3bd0805741?source=collection_archive---------3-----------------------#2017-08-09">https://medium.com/hackernoon/wheres-waldo-terminator-edition-8b3bd0805741?source=collection_archive---------3-----------------------#2017-08-09</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/0e93fc2be6f44ec013c9be057a994a86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVwu29o-uUukoz3b4qjTcA.png"/></div></div></figure><h1 id="fef5" class="jc jd hu bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">使用语义分割寻找瓦尔多&amp;提拉米苏</h1><p id="c693" class="pw-post-body-paragraph ka kb hu kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx hn dt translated"><em class="ky">这篇文章的灵感来自与</em><a class="ae kz" href="https://twitter.com/jeremyphoward" rel="noopener ugc nofollow" target="_blank"><em class="ky">@ Jeremy Howard</em></a><em class="ky">和</em><a class="ae kz" href="https://twitter.com/math_rachel" rel="noopener ugc nofollow" target="_blank"><em class="ky">@ math _ Rachel</em></a><em class="ky">【s</em><a class="ae kz" href="http://fast.ai" rel="noopener ugc nofollow" target="_blank"><em class="ky">fast . ai</em></a><em class="ky">实习时学习的材料，特别是他们的课程</em> <a class="ae kz" href="http://course.fast.ai/part2.html" rel="noopener ugc nofollow" target="_blank"> <em class="ky">第14课《程序员的前沿深度学习</em> </a> <em class="ky">，在USF的</em>如果你想看我这个项目的端到端代码，请查看我的资源库 <a class="ae kz" href="https://github.com/bckenstler/TheresWaldo" rel="noopener ugc nofollow" target="_blank"> <em class="ky">有瓦尔多</em> </a> <em class="ky">。</em></p><p id="c63f" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">到目前为止，业外人士可能都知道最近关于“脸书艾事件”的报道被大大夸大了(假新闻！).这是一种保守的说法；报道的故事是可怕的记者对一篇令人兴奋的研究论文的严重歪曲。</p><p id="2c1e" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">不，天网还没有意识到。然而，人工智能继续快速发展。特别是，自从深度学习的复兴以来，计算机视觉领域已经取得了长足的进步；卷积神经网络使得像图像分类和物体检测这样的任务变得微不足道。尽管电子人仍然是科幻小说中的东西，但他们的操作部件已经不是了(见自动驾驶汽车)。所以在某种程度上，我们<em class="ky">今天确实</em>有能力帮助一个终结者获得它的目标。</p><p id="b82c" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">今天，目标是沃尔多。是的，每个人都喜欢的戴眼镜的流浪者和闭塞大师已经让自己陷入了困境；我们将看看如何使用语义分割和被称为<a class="ae kz" href="https://arxiv.org/abs/1611.09326" rel="noopener ugc nofollow" target="_blank"> <strong class="kc hv">【提拉米苏】</strong> </a>的全卷积DenseNet来找到他。</p></div><div class="ab cl lf lg hc lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hn ho hp hq hr"><p id="d4e2" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">对于那些不熟悉的人来说,《瓦尔多在哪里》(或《沃利》)是一系列儿童书籍，挑战读者在密集的插图中找到同名人物和他的伙伴。</p><p id="3b01" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">这里有一个例子:</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lm"><img src="../Images/645e28285b9ec36fdee82d6d89c77937.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7v_75ZGg1CTmWAw1rEgMHQ.jpeg"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Holy shark-repellant Batman!!!</figcaption></figure><p id="e9f4" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">这是一个更荒谬的困难挑战，但代表了它们是多么的耗时和令人生畏。</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div class="fe ff lv"><img src="../Images/801839ce815d0bf2e0169376e9a2a0cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*YdLI6hd-KoDZizEsyiqjNQ.jpeg"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Olson’s optimal search path, determined using a genetic algorithm.</figcaption></figure><p id="b6e0" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">在谷歌上快速搜索一下，就能找到一些机器/深度学习解决方案来解决这个问题。最值得注意的是，宾夕法尼亚大学高级数据科学家兰迪·奥尔森的<a class="ae kz" href="https://www.wired.com/2015/02/created-perfect-wheres-waldo-strategy-machine-learning/" rel="noopener ugc nofollow" target="_blank">最佳瓦尔多在哪里策略</a>确定了在所有68张瓦尔多图像中找到瓦尔多的最佳搜索路径。</p><p id="723b" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">奥尔森的方法实际上并没有找到瓦尔多，它告诉<strong class="kc hv">你</strong>找到他的最好方法是知道他在所有64张图像中的位置。这是一个不同任务的伟大解决方案，一个利用瓦尔多位置的先验知识<em class="ky"/>的解决方案。其他方法只是在图像中找到Waldo，给出他在该图像中的样子。</p><p id="1a3a" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我们的目标是像人类一样找到瓦尔多。给定一张新的图像和对瓦尔多是什么的概念理解，模型应该定位瓦尔多，即使它以前从未在那张照片中见过他。</p></div><div class="ab cl lf lg hc lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hn ho hp hq hr"><p id="3a74" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我把这个任务当作一个语义分割问题来处理。语义分割的目标是检测图像中的对象；它通过对每个像素进行分类来做到这一点。</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div class="fe ff lw"><img src="../Images/55d2bfc23e8ef327a2bf0713c0334d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*Ac0k9LYOmUuBnuSf6WccGg.jpeg"/></div></figure><p id="4313" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">这张来自<a class="ae kz" href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/" rel="noopener ugc nofollow" target="_blank"> Camvid数据集</a>的街道图像是这种工作方式的标准示例。图像中的每个像素都被标记为属于某类物体，无论是树、建筑物、汽车还是人。</p><p id="6495" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">接下来的任务是建立一个模型来预测每个像素的类别。为了检测Waldo，我们的图像只有两类:Waldo和not-Waldo。</p><p id="18fd" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">第一步是创建这些标签图像。我从瓦伦蒂诺·康斯坦蒂努的<a class="ae kz" href="https://github.com/vc1492a/Hey-Waldo" rel="noopener ugc nofollow" target="_blank">系列</a>中选取了18张沃尔多在哪里的图片，并使用<a class="ae kz" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"><strong class="kc hv">labelImg</strong></a><strong class="kc hv">创建了边框。</strong></p><div class="lx ly fm fo lz ma"><a href="https://flic.kr/s/aHsm27sQSz" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab ej"><div class="mc ab md cl cj me"><h2 class="bd hv fv z el mf eo ep mg er et ht dt translated">训练图像</h2><div class="mh l"><h3 class="bd b fv z el mf eo ep mg er et ek translated">沃尔多训练图像在哪里</h3></div><div class="mi l"><p class="bd b gc z el mf eo ep mg er et ek translated">flic.kr</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ja ma"/></div></div></a></div><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mp"><img src="../Images/d07a17e080d1fd222492186452393014.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eXRBqn6DcaejlJbVnJM0Ug.png"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Zoomed in for clarity.</figcaption></figure><p id="52e9" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">左边的这个边界框代表了另外17个:它们都正好围绕在瓦尔多的头部，并且自然地包含了一些周围的背景。传统上，对于语义分割，我们只想标记描述Waldo的像素。不幸的是，我不熟悉任何简单的逐个像素标记的方法，我也不认为有必要这样做。</p><p id="4599" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">一旦我设置了这些框，我就构建了代表非瓦尔多和瓦尔多的二进制标签图像。一般来说，这些看起来像这样:</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div class="fe ff mq"><img src="../Images/97c90a63fbe92ada6a3108f5b00aa03f.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*tiTGJ3f3s0BE3r2myMP_5A.png"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Example label image, zoomed in. Purple — no Waldo, Yellow — Waldo</figcaption></figure><p id="68db" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">太好了！现在我有了输入和目标，这是训练我们模型的基本要素。但在此之前，我们需要解决几个问题:</p><ul class=""><li id="4740" class="mr ms hu kc b kd la kh lb kl mt kp mu kt mv kx mw mx my mz dt translated">即使有适当的数据扩充(这在该领域中是有限的)，18个图像也根本不足以充分训练神经网络。</li><li id="102d" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">这些图像太大了，即使在Titan X上也无法加载到内存中。</li><li id="277f" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">更糟糕的是，下采样使得这些精细的图像完全无法理解。</li></ul><p id="5822" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我通过从最初的18张在线图片中动态抽取224 x 224的子图片来解决这些问题:</p><ul class=""><li id="944e" class="mr ms hu kc b kd la kh lb kl mt kp mu kt mv kx mw mx my mz dt translated">图像尺寸为2800 x 1760，随机水平反射，这为我们提供了大约。1.42亿幅独特的样本图像。</li><li id="6a9b" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">这个图像大小在资源方面是完全可以管理的。</li><li id="4fce" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">瓦尔多的头部通常为60 x 60像素。大小为224 x 224的样本很容易大到足以包含做出准确预测所需的局部信息。</li></ul><p id="5a83" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">第二点至关重要。提拉米苏是完全卷积的:它只利用本地信息。这意味着我们可以通过对精心管理的样本图像进行训练，来为完整的高分辨率图像(我们的主要目标)训练一个网络。当然，样本图像会有不存在于整个图像中的边缘，但是这种影响可以忽略不计。</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div class="fe ff nf"><img src="../Images/b18152cdf4602182a7c536615f7ffcdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*5kjh_G-9RlI5goyyJItRjw.png"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Four samples furthest from center of a “Waldo Image”, all completely contain Waldo.</figcaption></figure><p id="5e4a" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">关于小心管理采样:大量可能的样本图像和小批量(Titan X上大约6张)意味着我必须确保每批中有适当数量的包含Waldo的图像。</p><p id="c3ec" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">为了做到这一点，我为每幅原作分离出18幅“沃尔多图像”。这些图像的构造使得每个随机的224 x 224样本包含一个完整的Waldo。</p><p id="733b" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我还确保当从完整的图像中取样时，我省略了任何包含Waldo的部分或其他图像。这有助于确保完整的图像采样产生否定结果，并避免迫使网络从无用/不完整的肯定结果中学习(例如，从仅包含Waldo的帽子尖端的图像中学习是没有用的)。</p></div><div class="ab cl lf lg hc lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hn ho hp hq hr"><p id="09e0" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">现在我们已经理解了我使用的数据生成过程，让我们来谈谈模型。</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div class="fe ff ng"><img src="../Images/67554947103bb39d7a7fc7d1adc52acb.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*U-M5vI0j0raRI9-74WGRpg.png"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek"><strong class="bd nh">1. </strong><a class="ae kz" href="https://arxiv.org/pdf/1611.09326.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1611.09326.pdf</a></figcaption></figure><p id="74e8" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">如果你不熟悉被称为提拉米苏的全卷积DenseNet，我强烈推荐阅读Jégou et。al的原创论文<a class="ae kz" href="https://arxiv.org/abs/1611.09326" rel="noopener ugc nofollow" target="_blank">一百层提拉米苏:用于语义分割的全卷积DenseNets】。</a></p><p id="4e25" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">对于实际的用法和指导，我也强烈推荐看一看杰瑞米·霍华德的<a class="ae kz" href="https://github.com/fastai/courses/blob/master/deeplearning2/tiramisu-keras.ipynb" rel="noopener ugc nofollow" target="_blank">实现</a>，作为<a class="ae kz" href="http://fast.ai" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>课程<a class="ae kz" href="http://course.fast.ai/part2.html" rel="noopener ugc nofollow" target="_blank">程序员前沿深度学习第二部分</a> ( <strong class="kc hv">完全披露:</strong>作为我在<a class="ae kz" href="http://fast.ai" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>实习工作的一部分，我用完整的描述注释了这个实现和其他实现。</p><p id="cb94" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">如果您对这个领域相当熟悉，那么原始论文中的图表应该足以解释这个架构的本质。本质上，提拉米苏是语义分割中常用的<a class="ae kz" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> <strong class="kc hv"> U-Net </strong> </a>架构与<a class="ae kz" href="https://arxiv.org/abs/1608.06993" rel="noopener ugc nofollow" target="_blank"> <strong class="kc hv"> DenseNet </strong> </a>中发现的前向层连接的优势的结合。</p></div><div class="ab cl lf lg hc lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hn ho hp hq hr"><p id="67bd" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我使用RMSProp和分类交叉熵损失来训练这个网络。显然，包含Waldo的像素是稀疏的。我可以用两种方法来减轻这种阶级不平衡的影响:</p><ul class=""><li id="7f9a" class="mr ms hu kc b kd la kh lb kl mt kp mu kt mv kx mw mx my mz dt translated">通过控制生成器是否产生正/负图像，我能够在训练批次中以2:1的比例对正图像进行上采样。</li><li id="67c1" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">我用负类损失频率的倒数来衡量它。</li></ul><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ni"><img src="../Images/1e79af3c94c4cc8c956afda5a30f2361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*piMUbzjIbjYdksPVH45rAA.png"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Loss vs Iterations</figcaption></figure><p id="8209" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">经过大约一个半小时的训练，我取得了一些可喜的成绩。</p><p id="188b" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">似乎这个模型很快就对大多数分类做出了决定。当然有很多噪音，这与在线数据生成是一致的。</p><p id="ff83" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我怀疑，如果我想出一种简单的方法，在不替换 <strong class="kc hv">的情况下，从1.42亿张可能的图像<strong class="kc hv">中进行采样，收敛会更加顺畅。</strong>我没有，所以模型不断看到全新的图像，尤其是从完整图像中取样的底片。</strong></p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nj"><img src="../Images/9fce5c6c740194a1d7e65321b540068f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ie7m4RSMbA7Xxr24-TPboA.jpeg"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">It’s learning…</figcaption></figure><p id="eb64" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">从质量上讲，我们得到了非常令人鼓舞的结果！</p><p id="9d85" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">在训练的早期阶段，很明显模型已经开始学习Waldo在哪里，同时有效地筛选出背景。</p><p id="2ced" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">这是个好消息！以前的几个模型无法处理阶级不平衡，最终以零敏感度告终。在这个早期阶段看到这些结果说服了我继续通宵训练这个模型。</p></div><div class="ab cl lf lg hc lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hn ho hp hq hr"><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nk"><img src="../Images/34cf0f7a7646425e407e58d9812a4960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ukHqdaa9Ql1OmDGoJBH7dg.png"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Difficulty with negative space.</figcaption></figure><p id="21c8" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">经过一夜的训练，我注意到尽管这个模型已经变得非常敏感，但它在处理负面信息时仍然有些困难。鉴于底片的采样空间很大，我估计这是因为模型没有看到足够多的完整图像。</p><p id="015b" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">在平衡了正负批处理比率并训练了另外2000次迭代之后，我终于取得了一些显著的结果。我能够通过从预测中创建一个透明遮罩并将它们覆盖在原始图像上来可视化我的模型的性能。</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nl"><img src="../Images/b43c0249c11aa80ff34304cfd76db38e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qatx7nmzGVBdYFInhnMp0g.png"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Prediction as transparency mask over original.</figcaption></figure><p id="b5d8" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">是的，左上角的那个小点就是瓦尔多(讽刺的是，他正是奥尔森建议你开始搜索的地方)。我想强调的是，这不是一张<strong class="kc hv">四舍五入的二元</strong>透明贴图，这些是<strong class="kc hv">原始预测值</strong>。我们可以看到这个模型对它的预测有多么有信心。特写:</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nm"><img src="../Images/9255f5323d54f2503af73fda85856961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1MYq_XJCHR0QGUFkGS_SzQ.png"/></div></div></figure><p id="e06c" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我对这种表现非常满意，这在整个训练集中是一致的。自己看吧！</p><div class="lx ly fm fo lz ma"><a href="https://flic.kr/s/aHsm6dP8sz" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab ej"><div class="mc ab md cl cj me"><h2 class="bd hv fv z el mf eo ep mg er et ht dt translated">训练预测</h2><div class="mh l"><h3 class="bd b fv z el mf eo ep mg er et ek translated">训练集上的Waldo预测</h3></div><div class="mi l"><p class="bd b gc z el mf eo ep mg er et ek translated">flic.kr</p></div></div><div class="mj l"><div class="nn l ml mm mn mj mo ja ma"/></div></div></a></div><p id="f41f" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">快速浏览一下训练预测将会告诉您一些事情。</p><ul class=""><li id="b448" class="mr ms hu kc b kd la kh lb kl mt kp mu kt mv kx mw mx my mz dt translated">该模型已经学会在所有图像中找到瓦尔多</li><li id="1bbf" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">这个模型对它的预测非常有信心。</li><li id="fb70" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">该模型有时也会定位其他人物，特别是<strong class="kc hv">文达</strong></li></ul><p id="b8b0" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">文达是瓦尔多的女性对手:</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div class="fe ff no"><img src="../Images/f2891aa568dbe0e7da1c3748bcaca577.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*hO9C4LgTUQkyT8bbaeao5w.png"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Wenda</figcaption></figure><p id="0019" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">在训练集中的大多数解析中，她看起来非常相似，如果不完全像Waldo的话。对于电视网来说，这是一个完全合理的错误。由于Wenda是一个阴性样本，她的图像不太可能经常被采样；当模特看到她时，她会以为是沃尔多。如果我们在训练中增加她的出现，我相信模特会学着忽略她。</p><p id="17b6" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">当然，真正的任务是看电视网是否已经学会<strong class="kc hv">概括</strong>瓦尔多的概念，并能够在一张新的照片中找到他，这是<strong class="kc hv">以前从未见过的</strong>:</p><div class="lx ly fm fo lz ma"><a href="https://flic.kr/s/aHsm2umwRy" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab ej"><div class="mc ab md cl cj me"><h2 class="bd hv fv z el mf eo ep mg er et ht dt translated">测试图像</h2><div class="mh l"><h3 class="bd b fv z el mf eo ep mg er et ek translated">看不见的沃尔多测试图像在哪里</h3></div><div class="mi l"><p class="bd b gc z el mf eo ep mg er et ek translated">flic.kr</p></div></div><div class="mj l"><div class="np l ml mm mn mj mo ja ma"/></div></div></a></div><p id="165d" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">示例:</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nq"><img src="../Images/9b2343d86d43b972752b2dbbf0797f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8UsxczpS3-N-Yg9S7hP-Zw.jpeg"/></div></div></figure><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nl"><img src="../Images/3f9bcd069d88aebce32d2787d1ea1657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g54pByCU8N5LKmuPmW0b-g.png"/></div></div></figure><p id="10c1" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">哇！太好了！！！我已经永远解决了沃尔多。</p><p id="14be" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">好吧，<strong class="kc hv">不算真的</strong>。我测试的8张图片中有2张没有阳性结果。</p><p id="3d0d" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">然而，剩下的6个人准确而自信地找到了沃尔多、文达或两者。此外，所有图像在负空间中都没有噪声；有假阳性，但没有不确定的“云”。</p><div class="lx ly fm fo lz ma"><a href="https://flic.kr/s/aHsm2dE6cw" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab ej"><div class="mc ab md cl cj me"><h2 class="bd hv fv z el mf eo ep mg er et ht dt translated">测试图像预测</h2><div class="mh l"><h3 class="bd b fv z el mf eo ep mg er et ek translated">对测试图像的预测</h3></div><div class="mi l"><p class="bd b gc z el mf eo ep mg er et ek translated">flic.kr</p></div></div><div class="mj l"><div class="nr l ml mm mn mj mo ja ma"/></div></div></a></div><p id="a20b" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">因此，尽管这个模型并不完美，但它足以证明这个任务<strong class="kc hv">是可以用这个方法</strong>解决的，更重要的是，它是<strong class="kc hv">可推广的</strong>。</p><p id="9926" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我毫不怀疑:</p><ul class=""><li id="2efb" class="mr ms hu kc b kd la kh lb kl mt kp mu kt mv kx mw mx my mz dt translated">完整的数据集</li><li id="2c92" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">正确验证</li><li id="6569" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">智能批量采样</li><li id="fb30" class="mr ms hu kc b kd na kh nb kl nc kp nd kt ne kx mw mx my mz dt translated">广泛的超参数调整</li></ul><p id="6ca7" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">还有很多空闲时间，有人可以训练一个防弹的沃尔多模型在哪里。</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ns"><img src="../Images/203ed3ad2d94f3d80d4e4e7eb9a71443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4w9fBmwOa5vPQG9ngfVOkQ.png"/></div></div></figure></div><div class="ab cl lf lg hc lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hn ho hp hq hr"><p id="6d15" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">最后一点。</p><p id="b1ec" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">在对224 x 224个样本进行训练时，对于我如何准确地为整个图像产生这些预测，可能会有一些困惑。当然，理论上，像提拉米苏这样的完全卷积网络可以处理全尺寸图像。不幸的是，在实践中，原始图像太大，无法加载到内存中，对其进行下采样会破坏分类所需的细节。</p><p id="478d" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">我的解决方案是将每张图片的尺寸调整到可以被224整除的下一个最大尺寸，然后将它分割成单独的面板，每个面板为224 x 224。然后，我对这些面板中的每一个进行预测，并将它们重新组合在一起，作为最终的输出。</p><figure class="ln lo lp lq fq iv fe ff paragraph-image"><div class="fe ff nt"><img src="../Images/224b9f51a3e1375baac71ba6e12ad550.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*-Ipf0t4Bp8FNxKtnUo_hbQ.png"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Waldo at panel border</figcaption></figure><p id="1f5e" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">总的来说，与对整个图像的理论预测相比，这样做的危害是可以忽略的，因为这些子面板足够大，可以包含预测所需的信息。</p><p id="a9bb" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">唯一有问题的时候是当镶板真的分开沃尔多的时候。我肯定有办法避免这种情况，但我发现这种方法已经足够好了。</p><p id="a9d3" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">说到方法，你可能想知道为什么我没有在这个任务中使用包围盒回归。同样，这些图像太大，下采样会破坏信息。不仅它们太大，而且盒子可能相对太小。</p><p id="42b8" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated"><em class="ky">可能真正起作用的是分割成面板，将面板整体分类为包含或不包含Waldo，然后在包含Waldo的面板上回归边界框。但那是一个比这个更复杂的方法。</em></p></div><div class="ab cl lf lg hc lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hn ho hp hq hr"><p id="be78" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">就是这样！我希望你喜欢这一点，如果你想更深入地了解我的端到端过程，包括代码，请查看我的这个项目库，<a class="ae kz" href="https://github.com/bckenstler/TheresWaldo" rel="noopener ugc nofollow" target="_blank">有瓦尔多</a>。</p><p id="283d" class="pw-post-body-paragraph ka kb hu kc b kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt le kv kw kx hn dt translated">如果你是深度学习的新手，或者希望获得高级架构和应用的最新信息，我强烈推荐<a class="ae kz" href="http://fast.ai" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>的深度学习<a class="ae kz" href="http://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> Part 1 </a>和<a class="ae kz" href="http://course.fast.ai/part2.html" rel="noopener ugc nofollow" target="_blank"> Part 2 </a>。</p></div></div>    
</body>
</html>