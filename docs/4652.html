<html>
<head>
<title>The Unreasonable Ineffectiveness of Deep Learning in NLU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习在NLU毫无道理的无效</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/the-unreasonable-ineffectiveness-of-deep-learning-in-nlu-e4b4ce3a0da0?source=collection_archive---------0-----------------------#2017-06-13">https://medium.com/hackernoon/the-unreasonable-ineffectiveness-of-deep-learning-in-nlu-e4b4ce3a0da0?source=collection_archive---------0-----------------------#2017-06-13</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="7843" class="pw-subtitle-paragraph is ht hu bd b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj ek translated">在真实世界的数据上，深度学习的表现可能很肤浅</h2></div><p id="4dd1" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">我经常被抛给一个更好的自然语言理解的<a class="ae kg" href="https://hackernoon.com/tagged/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>解决方案(<a class="ae kg" href="https://hackernoon.com/tagged/nlu" rel="noopener ugc nofollow" target="_blank"> NLU </a>)。这个计划看起来很谨慎。毕竟<a class="ae kg" href="https://trends.google.com/trends/explore?date=all&amp;q=deep%20learning,genetic%20algorithms,fuzzy%20logic" rel="noopener ugc nofollow" target="_blank">深度学习是AI </a>中的颠覆性新生力量。一个更好的NLU人工智能吸引了许多有用的进步，从<a class="ae kg" href="https://chatbotsmagazine.com/what-bots-may-come-a35b2bb9bd58" rel="noopener ugc nofollow" target="_blank">更智能的聊天机器人</a>和<a class="ae kg" href="https://www.recode.net/2015/11/3/11620286/facebooks-virtual-assistant-m-is-super-smart-its-also-probably-a-human" rel="noopener ugc nofollow" target="_blank">虚拟助手</a>到<a class="ae kg" href="http://fortune.com/2017/04/21/bill-oreilly-auto-parts-stock/" rel="noopener ugc nofollow" target="_blank">新闻分类</a>，最终有望实现更好的语言理解。</p><h2 id="da59" class="kh ki hu bd kj kk kl km kn ko kp kq kr jt ks kt ku jx kv kw kx kb ky kz la lb dt translated">实践状况</h2><p id="2bcd" class="pw-post-body-paragraph jk jl hu jm b jn lc iw jp jq ld iz js jt le jv jw jx lf jz ka kb lg kd ke kf hn dt translated">让我们假设这个高级深度学习(DL)“产品”叫做<code class="eh lh li lj lk b">"(dot)AI”</code>。他们的推介资料总会有一个类似这样的条形图，声称<code class="eh lh li lj lk b">(Dot)AI </code>的新DL主题分类器/标记器比最先进的方法更好。</p><figure class="lm ln lo lp fq lq fe ff paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="fe ff ll"><img src="../Images/a5c5b0cc3a421502420ffd8d79b9fab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*unP1qDkUPSSUsa2-530zEg.png"/></div></div><figcaption class="lx ly fg fe ff lz ma bd b be z ek">In many industries, it is expected that production grade ML classifiers have more than 90% accuracy for quality assurance and a decent user experience. This is expected tolerance level for news categorization or conversational bots</figcaption></figure><p id="31c9" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">该图表提出了一个有趣的命题，尽管性能仅略高于最先进水平。在任何产品中，<strong class="jm hv">什么构成“足够好”取决于该行业特定的误差容限</strong>。例如，模型的最佳准确度分数对于视频推荐器或图像转录可能是合理的，但是超出了新闻分类的容许极限。</p><blockquote class="mb mc md"><p id="10ca" class="jk jl me jm b jn jo iw jp jq jr iz js mf ju jv jw mg jy jz ka mh kc kd ke kf hn dt translated"><em class="hu">你不必怀疑这个问题:</em>在自然语言文本分类领域，DL技术是否明显优于浅层方法，例如<a class="ae kg" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a>或基于单词包(BoW)的方法？</p></blockquote><p id="e594" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">这个假设通常是自信的肯定——DL抹杀了NLU肤浅的方法。<strong class="jm hv"> <em class="me">但是呢？最近有三种趋势支撑着这种错觉:</em></strong></p><ol class=""><li id="b521" class="mi mj hu jm b jn jo jq jr jt mk jx ml kb mm kf mn mo mp mq dt translated">在行业人工智能会议中，<strong class="jm hv">深度学习演讲压倒性地涉及图像/音频/视频数据</strong>，几乎没有关于生产级自然语言任务的演讲。为什么？</li><li id="cc34" class="mi mj hu jm b jn mr jq ms jt mt jx mu kb mv kf mn mo mp mq dt translated">媒体和其他人不断地将深度学习宣传为<em class="me">银弹</em>、<strong class="jm hv">而没有仔细阅读论文中的实际结果</strong>。对于试图评估DL在其领域中的效用的从业者来说，这可能会导致混乱。</li><li id="3553" class="mi mj hu jm b jn mr jq ms jt mt jx mu kb mv kf mn mo mp mq dt translated">在一些人为的基准测试中，许多结果只挤压了几个百分点的性能，而健壮性和适用性更重要。</li></ol><p id="2bb2" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">虽然DL已经席卷了计算世界，但它对某些基本NLU任务的影响仍然不确定，性能也不总是优越的。为了理解为什么，让我首先描述一下<em class="me">NLU的任务</em>，然后是<em class="me">试图解决这个问题的最先进的模型</em>以及<em class="me">DL表现不佳的原因。</em></p><h1 id="0e79" class="mw ki hu bd kj mx my mz kn na nb nc kr jb nd jc ku je ne jf kx jh nf ji la ng dt translated">NLU的一项基本任务</h1><p id="73e2" class="pw-post-body-paragraph jk jl hu jm b jn lc iw jp jq ld iz js jt le jv jw jx lf jz ka kb lg kd ke kf hn dt translated">自然语言理解的一个关键任务是理解句子的主题。主题可以是一个标签(如<code class="eh lh li lj lk b">politics</code>、<code class="eh lh li lj lk b">music</code>、<code class="eh lh li lj lk b">gaming </code>、<code class="eh lh li lj lk b">immigration</code>或<code class="eh lh li lj lk b">adventure-sports</code>)，但通常它<em class="me">不仅仅是<a class="ae kg" href="https://github.com/karpathy/paper-notes/blob/master/wikireading.md" rel="noopener ugc nofollow" target="_blank">一个基于命名实体的任务</a>，如一个人的名字或提取位置。</em></p><figure class="lm ln lo lp fq lq fe ff paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="fe ff nh"><img src="../Images/381a3579fea182289187bf4a39527b02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jr2VTmUJbQw_njTZRlDygA.png"/></div></div><figcaption class="lx ly fg fe ff lz ma bd b be z ek">A topic tagger will attempt to tag the first WFTV article to “<code class="eh lh li lj lk b">sports</code>”, while the second WFTV article to “<code class="eh lh li lj lk b">animals</code>” although both mentions `Tiger`. This can get complicated quickly due to things like <a class="ae kg" href="https://en.wikipedia.org/wiki/Word-sense_disambiguation" rel="noopener ugc nofollow" target="_blank">word sense disambiguation</a>, as is shown in the <a class="ae kg" href="https://www.theatlantic.com/technology/archive/2011/03/does-anne-hathaway-news-drive-berkshire-hathaways-stock/72661/" rel="noopener ugc nofollow" target="_blank">example on the right</a>.</figcaption></figure><p id="6fd5" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">这种类型的软件被称为主题标签。它们的效用不能被夸大。主题是<strong class="jm hv">提取意图</strong>和<strong class="jm hv">制定自动回复的关键。考虑一下聊天机器人——机器人公司面临的最常见的问题是缺乏任何自动捕捉用户信息的方法。从bot消息中估计用户意图的唯一方法是通过人眼观察或任何匹配预建正则表达式脚本的方法。这两种方法都是次优的，不能覆盖更大的主题空间。</strong></p><p id="e5d5" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">事实上，在各种语义分辨率下的主题标记是一种针对NLU的<strong class="jm hv">网关解决方案方法</strong>，原因有二:(1)将文本分类为主题是大多数更高级NLU任务的先驱，例如情感检测、话语分析、情节记忆，甚至是问题回答(<a class="ae kg" href="http://uclmr.github.io/ai4exams/data.html" rel="noopener ugc nofollow" target="_blank">典型的NLU任务</a> ) (2)此外，NLP管道非常容易出现错误传播，即主题分类中的错误会危及未来的分析，例如<a class="ae kg" rel="noopener" href="/@aditinair/episodic-memory-modeling-for-conversational-agents-7c82e25b06b4">情节记忆建模</a>或话语甚至是情感分析。因此，找到合适的主题对NLU来说至关重要。</p><figure class="lm ln lo lp fq lq"><div class="bz el l di"><div class="ni nj l"/></div><figcaption class="lx ly fg fe ff lz ma bd b be z ek"><em class="ir">What good is sentiment of a piece of news unless we know what exactly this sentiment is about? Incorrect topic tagging can adversely affect sentiment utility.</em></figcaption></figure><p id="ac13" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">理解主题是采取有意义行动的第一步。在现实中，主题分类是一个困难的问题，它有时被人工智能社区低估和忽视。</p><h1 id="f68d" class="mw ki hu bd kj mx my mz kn na nb nc kr jb nd jc ku je ne jf kx jh nf ji la ng dt translated">技术发展水平</h1><p id="43ed" class="pw-post-body-paragraph jk jl hu jm b jn lc iw jp jq ld iz js jt le jv jw jx lf jz ka kb lg kd ke kf hn dt translated">多年来，有几种技术试图解决主题分类问题。有<a class="ae kg" href="https://en.wikipedia.org/wiki/Latent_semantic_analysis" rel="noopener ugc nofollow" target="_blank"> LSA </a>、<a class="ae kg" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank"> LDA </a>和其他像<a class="ae kg" href="https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis" rel="noopener ugc nofollow" target="_blank"> PLSI </a>、<a class="ae kg" href="https://en.wikipedia.org/wiki/Explicit_semantic_analysis" rel="noopener ugc nofollow" target="_blank">显式语义分析</a>等等。其中一半不是<em class="me">非生产级</em>就是<em class="me">不能很好地适应杂乱的真实世界数据</em>。另一半具有<em class="me">差的可解释性</em>或者需要<em class="me">大量的后处理</em>无论它输出什么。</p><p id="8831" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><strong class="jm hv"> <em class="me">新世界模型:</em> </strong> <em class="me"> </em>如今，两种主要的解决方案压倒性地出现在主题分类性能比较中。(1)首先是来自2016年的非常深度C<a class="ae kg" href="https://arxiv.org/abs/1606.01781" rel="noopener ugc nofollow" target="_blank">on voluntive Neural Net</a>[<code class="eh lh li lj lk b">DCNN</code>]模型，该模型提出使用非常深度的神经网络架构——一种“<em class="me">计算机视觉中的最先进技术”</em>。(2)其次是<code class="eh lh li lj lk b"><a class="ae kg" href="https://arxiv.org/abs/1607.01759" rel="noopener ugc nofollow" target="_blank">FastText</a></code>方法(也是2016)。它的性能几乎和<code class="eh lh li lj lk b">DCNN</code>一样好，但是在训练和评估上比<code class="eh lh li lj lk b">DCNN</code>快几个数量级。一些人称FastText为NLP的特斯拉——不管这是什么意思。</p><p id="4388" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">这两种方法各有千秋。最大的区别在于<code class="eh lh li lj lk b">FastText</code> <strong class="jm hv">是一个浅层网络</strong>而<strong class="jm hv"> </strong> <code class="eh lh li lj lk b">DCNN</code> <strong class="jm hv">是29层深层神经网络。</strong> <code class="eh lh li lj lk b">FastText</code>不落于花里胡哨的深度神经网络的“刻板印象”。相反，它使用单词嵌入来解决标签预测任务。</p><figure class="lm ln lo lp fq lq fe ff paragraph-image"><div class="fe ff nk"><img src="../Images/e5542b35e546101e9aa120ce410f300a.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*FuRMCm1JPMFC1CGvsccESg.gif"/></div><figcaption class="lx ly fg fe ff lz ma bd b be z ek">FastText extends the basic <a class="ae kg" href="https://en.wikipedia.org/wiki/Word_embedding" rel="noopener ugc nofollow" target="_blank">word embedding</a> idea to predict a topic label, instead of predicting the middle/missing word (which recall is the original <a class="ae kg" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank">Word2Vec</a> task). This visualizes Word2Vec word embeddings [<a class="ae kg" href="http://www.anthonygarvan.com/wordgalaxy/" rel="noopener ugc nofollow" target="_blank">link</a>]</figcaption></figure><p id="7832" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><strong class="jm hv"> <em class="me">旧世界模型:</em> </strong> <em class="me"> </em>支持旧模型/幼稚模型的是基于单词的n-gram/bag模型和TFIDF，它们在大规模实现中仍然有价值。</p><p id="4d64" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><strong class="jm hv"> <em class="me">基准数据</em> </strong> <em class="me"> : </em>当前技术水平检查的最后一个组成部分是测试这些模型的数据集。基准数据集是再现性和比较分析的关键。在主题分类任务中，三个流行的数据集是:<code class="eh lh li lj lk b"><a class="ae kg" href="http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html" rel="noopener ugc nofollow" target="_blank">AG news</a></code>、<code class="eh lh li lj lk b">Sogou news </code>和<code class="eh lh li lj lk b">Yahoo! answers</code>。它们在语料大小和数据中出现的主题(类)数量上有所不同。</p><figure class="lm ln lo lp fq lq fe ff paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="fe ff nl"><img src="../Images/327f3c31f6da6b59d690aa58c3c843dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CtX-gtoQGoQdQoB8ojg9A.png"/></div></div><figcaption class="lx ly fg fe ff lz ma bd b be z ek">The three datasets marked in red rectangles are specifically used for topic classification. Shown with arrow is one instance in the dataset. Task is to predict the label by analyzing the sample.</figcaption></figure><h1 id="f1b9" class="mw ki hu bd kj mx my mz kn na nb nc kr jb nd jc ku je ne jf kx jh nf ji la ng dt translated">深度(学习)影响？</h1><p id="25f0" class="pw-post-body-paragraph jk jl hu jm b jn lc iw jp jq ld iz js jt le jv jw jx lf jz ka kb lg kd ke kf hn dt translated">首先，让我们看看来自<code class="eh lh li lj lk b">DCNN</code> DL论文的结果，并将其与简单模型进行比较。下面的数字表示在主题分类数据集上运行模型的特定配置时的错误率。</p><figure class="lm ln lo lp fq lq fe ff paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="fe ff nm"><img src="../Images/eecd85b2c6bfd86ed359a5830fee9e57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GSSP75ivQAzywq_ce0WRdA.png"/></div></div><figcaption class="lx ly fg fe ff lz ma bd b be z ek">This is Table 4 from <a class="ae kg" href="https://arxiv.org/abs/1606.01781" rel="noopener ugc nofollow" target="_blank">[DCNN] paper</a>. Topic classification datasets (mentioned above) are marked with rectangles. The corresponding comparable error values are marked with red ellipses.</figcaption></figure><p id="baf1" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><em class="me">四</em>这里主要观察:</p><ol class=""><li id="79f1" class="mi mj hu jm b jn jo jq jr jt mk jx ml kb mm kf mn mo mp mq dt translated">在2 /3主题分类数据集(<code class="eh lh li lj lk b">AG</code> + <code class="eh lh li lj lk b">Sogou</code>)中，<strong class="jm hv">朴素/浅层方法的表现优于深度学习</strong>。</li><li id="2c2b" class="mi mj hu jm b jn mr jq ms jt mt jx mu kb mv kf mn mo mp mq dt translated">在第三个数据集(<code class="eh lh li lj lk b">Yah. Ans</code>)中，<strong class="jm hv"> DL仅减少了</strong> <code class="eh lh li lj lk b"><strong class="jm hv">~1.63</strong></code>的误差。</li><li id="53f9" class="mi mj hu jm b jn mr jq ms jt mt jx mu kb mv kf mn mo mp mq dt translated">( <code class="eh lh li lj lk b"><strong class="jm hv">Yah. Ans</strong></code> <strong class="jm hv">)数据集上的最佳模型的<strong class="jm hv">精度仍然在</strong> <code class="eh lh li lj lk b"><strong class="jm hv">~73</strong></code>，这不是微不足道的，并且显著低于大多数高质量生产系统的容许水平。</strong></li></ol><blockquote class="mb mc md"><p id="c595" class="jk jl me jm b jn jo iw jp jq jr iz js mf ju jv jw mg jy jz ka mh kc kd ke kf hn dt translated">需要注意的重要一点是:所有3个数据集的主题空间都小于<code class="eh lh li lj lk b">11</code>，这在某种程度上仍然是合成的。在真实世界的自然语言数据(新闻流或会话消息)中，主题空间很容易超过20或25个不同的主题(或意图)。这很关键，因为下一点提示<strong class="jm hv">主题空间基数</strong>会对准确性产生巨大影响。</p></blockquote><p id="28fe" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">4.<strong class="jm hv">准确率下降:</strong>注意当话题空间从4增长到10 ( <code class="eh lh li lj lk b">AG</code> vs. <code class="eh lh li lj lk b">Yah.Ans</code>)，<em class="me">误差暴涨到</em> <code class="eh lh li lj lk b"><em class="me">28.26</em></code> <em class="me">从</em> <code class="eh lh li lj lk b"><em class="me">7.64</em></code> <em class="me">同一个模型。</em>虽然这可能是由虚假因素引起的，如不平衡的数据集，但很有可能是由于 <a class="ae kg" href="https://blog.acolyer.org/2017/05/11/understanding-deep-learning-requires-re-thinking-generalization/" rel="noopener ugc nofollow" target="_blank"> <em class="me">概括</em> </a> <em class="me">更大的主题空间所涉及的复杂性，错误 <em class="me">增加了四倍。</em></em></p><p id="ac62" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">最后，让我们看看<code class="eh lh li lj lk b">FastText</code>在这些数据集上的表现，并将其与<code class="eh lh li lj lk b">DCNN</code> DL和朴素方法进行比较:</p><figure class="lm ln lo lp fq lq fe ff paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="fe ff nn"><img src="../Images/5e14012b4f3da52760f2e6bca843994a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DCL7u5SSfAMVz6J0dnibQQ.png"/></div></div><figcaption class="lx ly fg fe ff lz ma bd b be z ek">This is Table 1 from <a class="ae kg" href="https://arxiv.org/abs/1607.01759" rel="noopener ugc nofollow" target="_blank">FastText paper</a> showing accuracy values on the three topic classification datasets, comparing FastText with naive methods.</figcaption></figure><p id="14b0" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><em class="me">三个</em>T37】进一步观察与<code class="eh lh li lj lk b">FastText’s</code>比较结果:</p><p id="1d56" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">5.再次，在2/3数据集上<code class="eh lh li lj lk b">FastText</code> <strong class="jm hv">比深度学习</strong>模型表现更好。<strong class="jm hv"> </strong>在<code class="eh lh li lj lk b">Yah. Ans</code>数据集中，<code class="eh lh li lj lk b">FastText</code>仅次于<code class="eh lh li lj lk b">~1.1</code>。</p><p id="33af" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">6.<strong class="jm hv"> </strong> <code class="eh lh li lj lk b">DCNN</code> <strong class="jm hv">深度学习方法在前两个数据集(<code class="eh lh li lj lk b">AG</code>和<code class="eh lh li lj lk b">Sogou</code>)中的表现实际上比朴素模型</strong>差。</p><p id="09f2" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">7.同样，在2/3数据集上，<strong class="jm hv">朴素模型的性能与</strong> <code class="eh lh li lj lk b">FastText</code>相当或更好</p><p id="4665" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">除了这些(惊人的)结果，回想一下，非DL模型通常比训练和<em class="me">快几个数量级，更容易理解。</em></p><h1 id="99f7" class="mw ki hu bd kj mx my mz kn na nb nc kr jb nd jc ku je ne jf kx jh nf ji la ng dt translated">为什么这个U<em class="ir">n合理</em>？</h1><p id="e052" class="pw-post-body-paragraph jk jl hu jm b jn lc iw jp jq ld iz js jt le jv jw jx lf jz ka kb lg kd ke kf hn dt translated">好吧，看起来当谈到主题分类器时——旧世界的模型(天真/浅薄)还没有准备好放弃他们的宝座！深度学习的这种<strong class="jm hv">无效有些出乎意料。这是违反直觉的，考虑到新世界DL模型是由一家拥有大量数据的公司生产的，性能应该明显更好。</strong></p><p id="ec0a" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">然而，我们观察到在准确性上差别很小。当将文本分类到主题中时，朴素的/旧的模型比DL模型更好或可与之相比。</p><figure class="lm ln lo lp fq lq fe ff paragraph-image"><div class="fe ff no"><img src="../Images/8abae1470d466b0ec0d1cd1c2da6f4be.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*7xS1rwu4FLERErNrnVxVXA.png"/></div><figcaption class="lx ly fg fe ff lz ma bd b be z ek">From “<a class="ae kg" href="https://www.slideshare.net/ExtractConf/andrew-ng-chief-scientist-at-baidu" rel="noopener ugc nofollow" target="_blank">What Data Scientists should know about Deep Learning</a>”, performance beats older algorithms with sufficient data.</figcaption></figure><p id="ce3a" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">深度学习在对语言进行分类方面可能有很深的问题，但这里的目标不是贬低它，也不是与深度学习阴谋有任何关系。我认为它的影响是明显和有希望的。在计算机视觉和<a class="ae kg" rel="noopener" href="/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a">语音识别</a>和<a class="ae kg" href="https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/" rel="noopener ugc nofollow" target="_blank">玩游戏</a>方面，DNN带我们去了从未去过的地方。</p><p id="8b4d" class="pw-post-body-paragraph jk jl hu jm b jn jo iw jp jq jr iz js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">但现实是，当使用深度学习进行文本分类等基本的自然语言任务时，你的里程数可能会有所不同。为什么图像/视频/音频与语言数据之间会有这样的性能差距？也许这与“理解”前者所需的生物信号处理模式和“理解”后者所需的文化背景模式有关？无论如何，关于学习本身的复杂性，我们还有很多东西要学，尤其是不同形式的多媒体。</p><div class="lm ln lo lp fq ab cb"><figure class="np lq nq nr ns nt nu paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="np lq nq nr ns nt nu paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="np lq nq nr ns nt nu paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="mb mc md"><p id="f922" class="jk jl me jm b jn jo iw jp jq jr iz js mf ju jv jw mg jy jz ka mh kc kd ke kf hn dt translated"><a class="ae kg" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae kg" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae kg" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae kg" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="jk jl me jm b jn jo iw jp jq jr iz js mf ju jv jw mg jy jz ka mh kc kd ke kf hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae kg" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae kg" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="lm ln lo lp fq lq fe ff paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="fe ff nv"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></div></figure><figure class="lm ln lo lp fq lq"><div class="bz el l di"><div class="nw nj l"/></div></figure></div></div>    
</body>
</html>