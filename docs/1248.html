<html>
<head>
<title>SuperIntelligence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超级智能</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/singularity-and-society-5a8679133888?source=collection_archive---------3-----------------------#2016-10-01">https://medium.com/hackernoon/singularity-and-society-5a8679133888?source=collection_archive---------3-----------------------#2016-10-01</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><figure class="ht hu fm fo hv hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff hs"><img src="../Images/00ef472aa1cc1615f246bf089a2d3a95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aTPZqenuBsa9OQBzS_G9jw.jpeg"/></div></div></figure><figure class="id ie if ig fq hw"><div class="bz el l di"><div class="ih ii l"/></div></figure><div class=""/><p id="9382" class="pw-post-body-paragraph ji jj il jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">从广义上来说，人工智能是一种旨在通过计算机算法复制人类和其他生物进化动物的认知能力的努力。在从简单的计算器到人类水平的人工智能(AI)以及更高水平的道路上，许多伦理和社会问题将会出现，并可能阻碍人工智能的发展。其中最令人担忧的可能是人工智能及其潜在的更优秀的继任者将对人类构成的生存威胁。我们与未来人工智能的关系可能类似于我们与猿和马的关系，我们瞧不起前者，认为后者不如我们，并利用后者为我们造福和娱乐。我们作为一个物种的命运可能有一天取决于我们的人工智能统治者，他们可能已经进化或设计成对我们友好或恶意。尽管如此，正如许多人工智能的支持者和反对者可能同意的那样，在我们拥有优于人类的人工智能之前，我们还有很长的路要走。在此之前，我们的关注应该是双重的；第一，如何确保由此产生的超级智能代理或实体不会对我们造成伤害，第二，如何防止一面倒的赢家通吃的情况，即人工智能的所有收益都流向最先答对的少数人。在这篇文章中，将探索通往超级智能的道路，但除此之外，人工智能的当前状态和超级智能之间的中间阶段也将得到公平的审查。</p><h1 id="23e6" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated"><strong class="ak">简介</strong></h1><p id="8a8e" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">在创造人类水平的通用人工智能的努力取得成果之前，一大堆狭隘和极端专业化的人工智能可能会扰乱我们的生活方式，并可能以不可挽回的方式改变社会结构，这是我们无法预见的。具体来说，利用狭义人工智能的企业可能会获得不平衡和极不成比例的收益，同时实际上从当前的经济体系中消除了人类劳动力的作用。(Hughes，2004)同样，政府围绕人工智能的活动，以及它们的物理体现，如机器人或自动驾驶汽车，也应该受到关注。对他们来说，威胁变成了全球安全与和平。想象一下，美国政府机构设法制造出自主程度不明的终极战争机器。这个人工智能驱动的机器可以被引导去消灭敌人的军队或设施，但是它自己却想出了完成这样一个可怕任务的方法。这种假设的场景应该使单一的威胁变得清晰，拥有次人类水平人工智能力量的不道德的人类组织可能比在疯狂科学家的实验室中出生的超级智能人工智能更早地结束我们的世界！</p><h1 id="3e90" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">奇异</h1><p id="d8f7" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">计算机硬件和软件的发展速度远远超过任何其他人造技术或工具。这可能是由于它们的可扩展特性，改进通过几代人的积累而产生更好、更快和更有效的计算机。然而，计算机信息处理能力的指数增长并没有导致使用计算机的人类工作者的生产率的指数增长。简而言之，我们没有能力或利用计算机的全部潜力。我们拥有经过数百万年进化的生物大脑，迄今为止，与任何人工智能相比，它更加智能，也更加灵活。另一方面，机器似乎以更快的速度变得更好。他们还没有自己的目标和意图。他们需要人类来设计他们的电路和软件。但是这里要问的问题是<em class="lk">我们能跟上机器改进的速度吗？</em>或者，我们是否有一天需要创造出能够制造更好机器的机器。如果目前的趋势继续下去，在人工智能机器获得设计和制造更好机器的能力后，将会出现智能爆炸。一些人称这种情况为<em class="lk">奇点。</em>(查尔莫斯，2010年)</p><h1 id="07b8" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">最后的发明</h1><p id="3af0" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">古德是第一个正式评估机器存在的可能性以及由此产生的后果的人，这些机器在所有智力方面都远比人类聪明(古德，1965)。这个想法是，如果有一天我们真的创造出这样一台<em class="lk">超智能</em>机器，这种机器或人工智能的能力之一将是创造出更多的智能机器本身。这种机器可以创造人工智能来探索各种可能的维度和各种人类从未想到过的智能。这将导致所谓的情报爆炸事件。智人将被远远抛在后面，不用说，此后很可能毫无用处。因此，发明这种超级智能的人工智能萌芽机器将是我们需要做的最后一项发明。</p><figure class="id ie if ig fq hw"><div class="bz el l di"><div class="ll ii l"/></div><figcaption class="lm ln fg fe ff lo lp bd b be z ek">Humans Need Not Apply</figcaption></figure><h1 id="f9bd" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">奇点会发生吗？</h1><p id="2908" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">也许这个问题最关键的方面在于我们的动机，作为人类社会的集体，来创造更有能力的机器。我们创造了计算机来帮助我们更快更有效地完成任务。同样，我们创造了智能机器，使它们能够独立完成任务，比我们自己或在计算机等工具的帮助下更好。仅经济压力就将推动人工智能发展的步伐，以实现更高效、更具成本效益的流程、工厂、运营、交易等。在许多行业，传统上由数百名工人在数周内完成的工作量现在可以委托给一个工业机器人，只需几分之一的成本和几个小时的时间。机器人、智能软件程序、虚拟助手，不管我们怎么称呼它们，也不管它们的形状和形式，对于我们生活的工业和数字化世界来说都是必不可少的。到目前为止，智能机器的好处一直超过其风险和成本。如果这种上升趋势继续下去，除了一场足以毁灭整个人类的全球性灾难性事件之外，没有什么能够阻止我们创造更好的机器。</p><h1 id="17b6" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">超智能技术上可行吗？</h1><p id="84b4" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">人类水平的智力显然是可以达到的，尽管不是通过设计。事实上，直接设计已经被证明是一种不太可能的方法来设计非常复杂的系统，如我们的大脑或未来的人工智能。如果有合适的环境，我们可以在虚拟的模拟世界中创造合适的环境，让人工智能自己进化。但是，要比生物进化的速度快得多，并且要有一些高级别的监督，以避免资源和时间的浪费。如果我们认为人类大脑只不过是有组织的物质，那么就没有明显的理由不能在硅或其他人工智能宿主中复制这样的结构或系统。我们也不太可能接近智力的顶峰。正如历史上一些杰出的人所看到的那样，与普通人相比，我们的认知能力的某些方面有可能以一种异常优越的方式得到发展。智能人造或自我进化的机器只会受到它们可用资源数量的限制。有了正确的架构和条件，超级智能机器可以达到如此高的智能水平，以至于我们在它们看来就像蚂蚁一样。</p><h1 id="88cb" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">消除的方法</h1><p id="22f3" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">在本文的第二部分，我们将看看灾难性人工智能接管场景的一些基本要素。这里的假设是，人类水平的人工智能的发展是人类力所能及的。此后，后续各代AI的出现，我们将称之为AI+和ai++<a class="ae kg" href="#_ftn1" rel="noopener ugc nofollow">【1】</a>，主要是时间和外部条件的问题。从某种意义上说，计算机硬件和软件现有状态的任何改进速度都足以最终使我们走向人工智能。因此，对于人工智能来说，要超越人类集体所能实现的极限，只需要在超级计算机上部署相同人工智能程序的许多实例，并看着它们在几天或几周内取得比整个人类几千年来所取得的进步更多的进步。通过自动化，人工智能将渗透到我们日常生活的方方面面，而不仅仅是认知要求高的任务。一个有力的例子是自动驾驶或无人驾驶汽车取代了数百万司机。一旦一家公司做对了，设计出完美的自动驾驶汽车(或至少比人类司机更好的汽车)，他们将能够部署数百万或数十亿辆不用马拉的马车(确切地说是没有人)，并永远收获成果。人工智能带来的巨大好处以及自动化带来的巨大可扩展性，让人们无法不去追求它。换句话说，AI的到来是不可避免的。</p><h1 id="4207" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">主持人</h1><p id="1eae" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">人工智能的强大力量应该被极其小心地处理，它的动机和目标最好与我们的一致，否则我们将会被人工智能的龙卷风卷去。只有人工智能的智能和智力能力才能对地球人构成任何严重威胁，除非加上宽松的操作框架和物理基础设施来影响现实世界。显然，一个孤立封装的人工智能对我们没有任何用处。我们必须能够与它互动，以获得人工智能的好处。任何参与经济和法律交易的实体都必须是自然人或法人。虽然最终将人分配给人工智能代理并非完全不可能，但更有可能的是，利用人工智能技术的组织将如此依赖它，以至于实际上它们被人工智能控制。这些组织最终可能会变成他们自己奴隶的傀儡。全栈或端到端公司特别适合人工智能收购。这些组织通过控制从制造和产品开发到客户体验的整个价值链来实现更高的效率。监管者看不到它们，它们通常拥有强大的游说和营销力量，为了自身利益改变监管和社会认知。这种巨型公司的惯性使得政府很难控制它们，从而为超级智能机器的最终劫持创造了完美的条件。</p><h1 id="bb84" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">僵尸网络</h1><p id="c2ec" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">末日的另一个主要因素是人工智能与现实世界的物理接触和连接。物联网运动是这种担忧的最终体现。在这个世界上，从交通灯和自动驾驶汽车到核弹头，一切都与互联网或某种形式的网络相连，任何强大到超过安全警卫的邪恶实体都可能造成不可挽回的损害。在某种程度上，我们正在为自己的毁灭创造完美的条件。</p><h1 id="ddda" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">社会经济单一性</h1><p id="5f01" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">让我们看看我们的世界正走向何方；一个严重依赖自动化和人工智能来满足对更便宜的商品和更具成本效益的服务的不断增长的需求的社会；由于普遍失业而士气低落的人口；极富的少数人和贫穷挣扎的大多数人之间的巨大鸿沟；腐败的政治机构为那些拥有财富和权力的人服务。所有这些情况最终导致了一个反乌托邦的未来，在那里，地球已经变得像一个虚弱的宿主身体，成熟到可以被寄生虫接管，等待一个恶意的人工智能来结束我们所知道的地球上的生命。</p><figure class="id ie if ig fq hw"><div class="bz el l di"><div class="ll ii l"/></div><figcaption class="lm ln fg fe ff lo lp bd b be z ek">Future of AI and Universal Basic Income (UBI)</figcaption></figure><h1 id="21a8" class="kh ki il bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le dt translated">过渡到后奇点社会</h1><p id="ec18" class="pw-post-body-paragraph ji jj il jk b jl lf jn jo jp lg jr js jt lh jv jw jx li jz ka kb lj kd ke kf hn dt translated">人工智能可能是我们所有问题的最终解决方案。事实上，在人工智能发明之后，可能没有人需要与痛苦和不幸作斗争。人类可以在与人工智能的共生关系中继续生活，最终甚至可以通过思维上传或智能放大大脑植入与人工智能结合。这些都不会在一夜之间发生。眼前的重要任务是让社会准备好优雅地过渡到智能生命形式进化的下一个阶段。为了在奇点生存，我们需要仔细考虑所有选项的风险和收益。通往繁荣的后奇点社会的道路不仅依赖于技术进步。所有的利益相关者应该合作并保持团结来对抗人工智能世界末日的威胁。这可以通过形成行业范围的人工智能道德联盟<a class="ae kg" href="#_ftn2" rel="noopener ugc nofollow">【2】</a>、提高公众对人工智能和自动化的益处和危害的认识、谨慎和前瞻性的监管，以及最重要的财富分配和价值创造的公平体系来实现。不管我们愿不愿意面对，通过自动化和人工智能的应用，大量的工作将被彻底消灭。数百万乃至数十亿全球劳动力将没有机会或能力适应新创造的工作岗位的要求。他们不是暂时失业，而是自动化和AI时代事实上无法就业的劳动力。帮助这些脆弱的社会成员是社会的集体责任，从某种意义上说，他们是为世界的持续进步和集体繁荣而牺牲的。在不久的将来，全民基本收入可以解决我们面临的失业危机。将向一个国家的所有公民支付一笔固定金额，根据每个地区的生活水平进行调整，让那些有需要的人能够应对他们缺乏可持续收入和快速变化的就业市场的问题。围绕UBI的话题有许多问题，从它对长期失业后个人尊严感的影响，到纳税人的大量额外成本和政府为所有公民提供宜居收入的负担。在这里讨论这些问题超出了本文的范围。人工智能可能会毁掉工作，但同时也可能为纳税人和政府节省大量资金。例如，预计仅在美国，自动驾驶汽车每年将显著减少事故数量，并减少约三万亿美元的运输成本(Frazzoli，2014年)。这些节省下来的成本可以用来资助UBI，或者，如果管理不当，可以造就几个亿万富翁，我们这个时代的第一批亿万富翁！</p></div><div class="ab cl lq lr hc ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hn ho hp hq hr"><p id="a0b6" class="pw-post-body-paragraph ji jj il jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><a class="ae kg" href="#_ftnref1" rel="noopener ugc nofollow">【1】</a>AI+被定义为比最聪明的人类更聪明的实体。AI++在智力谱上遥遥领先于最聪明的人类，人类对于AI++来说就像老鼠一样。</p><p id="33d1" class="pw-post-body-paragraph ji jj il jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><a class="ae kg" href="#_ftnref2" rel="noopener ugc nofollow">【2】</a>例如，新成立的<em class="lk">人工智能造福人类和社会合作伙伴</em>，<a class="ae kg" href="http://www.partnershiponai.org/" rel="noopener ugc nofollow" target="_blank">http://www.partnershiponai.org/</a></p><figure class="id ie if ig fq hw"><div class="bz el l di"><div class="lx ii l"/></div></figure></div></div>    
</body>
</html>