<html>
<head>
<title>How to scrape websites based on Viewstates using Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Scrapy抓取基于视图状态的网站</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/how-to-scrape-websites-based-on-viewstates-using-scrapy-39feb9445755?source=collection_archive---------5-----------------------#2016-12-14">https://medium.com/hackernoon/how-to-scrape-websites-based-on-viewstates-using-scrapy-39feb9445755?source=collection_archive---------5-----------------------#2016-12-14</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="5d5c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你发现自己正在浏览一个需要通过表单提交数据的ASP.Net页面，这篇文章可能会派上用场。Scrapy 是我在本教程中使用的工具，它是一个<a class="ae jp" href="https://scrapy.org/community/" rel="noopener ugc nofollow" target="_blank">开源</a>网络爬行框架。</p><h1 id="d0ba" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">处理ASP.Net页面、回发和视图状态</h1><p id="4fbd" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">使用ASP.Net技术建立的网站通常是网页抓取开发者的噩梦，主要是由于他们处理表单的方式。</p><p id="6d72" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这些类型的网站通常在请求和响应中发送状态数据，以便跟踪客户端的UI状态。想想那些你注册的网站，当你在HTML表单中填写数据的时候，要浏览很多页面。ASP.Net网站通常会将您在之前页面中填写的数据存储在一个名为“__VIEWSTATE”的隐藏字段中，该字段包含一个巨大的字符串，如下所示:</p><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="fe ff kt"><img src="../Images/74eb9f21acc3e29935ab818cc0b7cd3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kE5srwkKg3jnbDvR."/></div></div></figure><p id="3d21" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="lf">我不是在开玩笑，这是巨大的！(有时几十kB)</em></p><p id="6ea9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这是代表客户端UI状态的Base64编码字符串，包含表单中的值。这种设置在web应用程序中特别常见，在web应用程序中，表单中的用户操作会触发POST请求返回到服务器，以获取其他字段的数据。</p><p id="ddd2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">__VIEWSTATE字段随浏览器向服务器发出的每个POST请求一起传递。然后，服务器从这些数据中解码并加载客户端的UI状态，执行一些处理，根据新值计算新视图状态的值，并将新视图状态呈现为隐藏字段。</p><p id="56e4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果__VIEWSTATE没有发送回服务器，您可能会看到一个空白表单，因为服务器完全丢失了客户端的UI状态。因此，为了抓取像这样的表单产生的页面，您必须确保您的爬行器正在发送其请求的状态数据，否则页面将不会加载它期望加载的内容。</p><p id="81f2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这里有一个具体的例子，这样你可以直接看到如何处理这些类型的情况。</p><h1 id="9810" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">基于视图状态抓取网站</h1><p id="0833" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">今天的刮痧豚鼠是<a class="ae jp" href="http://quotes.toscrape.com/search.aspx" rel="noopener ugc nofollow" target="_blank">quotes.toscrape.com/search.aspx</a>。该网站列出名人名言，其搜索页面允许您按作者和标签过滤名言:</p><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div class="fe ff lg"><img src="../Images/332592a528e6617a8faa1351d813c175.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/0*-9yV6Y3yPxTOQfTh."/></div></figure><p id="ecde" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在<strong class="it hv"> Author </strong>字段中的一个变化向服务器发出一个POST请求，用与所选作者相关的标签填充<strong class="it hv">标签</strong>选择框。点击<strong class="it hv">搜索</strong>会显示符合所选作者标签的任何引文:</p><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="fe ff lh"><img src="../Images/5d7443ef0d4971059351d00a1b021f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/0*2UfMcW2wbB3xGj0z."/></div></div></figure><p id="e63f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了收集这些引用，我们的蜘蛛必须模拟选择作者、标签和提交表单的用户交互。使用可以通过浏览器开发工具访问的<a class="ae jp" href="https://developer.chrome.com/devtools" rel="noopener ugc nofollow" target="_blank">网络面板</a>仔细查看这个流程的每个步骤。首先，访问quotes.toscrape.com/search.aspx的<a class="ae jp" href="http://quotes.toscrape.com/search.aspx" rel="noopener ugc nofollow" target="_blank"/>，然后通过按F12或Ctrl+Shift+I(如果你使用Chrome)并点击网络选项卡来加载工具。</p><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="fe ff kt"><img src="../Images/98507463e22f4764dd8f2b79dfc4d6f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JNM36Gam6nU02KtW."/></div></div></figure><p id="5d9b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">从列表中选择一个作者，您将看到已经发出了对“/filter.aspx”的请求。单击资源名称(filter.aspx)会将您带到请求详细信息，您可以看到浏览器发送了您选择的作者以及来自服务器的原始响应中的__VIEWSTATE数据。</p><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="fe ff kt"><img src="../Images/c251e942dc636ab3100733a76a706d3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*d5k_GNHiiI29NRVh."/></div></div></figure><p id="a3b8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">选择一个标签，然后单击搜索。您将看到您的浏览器发送了表单中选择的值以及一个__VIEWSTATE值，该值不同于前一个值。这是因为当您选择作者时，服务器在视图状态中包含了一些新信息。</p><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="fe ff kt"><img src="../Images/79567aacaed42b8d85f6c5b5e2728666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8XFnvizXggK3OFAG."/></div></div></figure><p id="221f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在你只需要建立一个蜘蛛，它做的事情和你的浏览器完全一样。</p><h1 id="d9e7" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">打造你的蜘蛛</h1><p id="3232" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">以下是您的蜘蛛应该遵循的步骤:</p><ol class=""><li id="e60a" class="li lj hu it b iu iv iy iz jc lk jg ll jk lm jo ln lo lp lq dt translated">去叫quotes.toscrape.com/search.aspx</li></ol><p id="f6ea" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">2.对于在表单作者列表中找到的每个<strong class="it hv">作者</strong>:</p><ul class=""><li id="2b9d" class="li lj hu it b iu iv iy iz jc lk jg ll jk lm jo lr lo lp lq dt translated">创建一个POST请求到/filter.aspx，传递所选的<strong class="it hv">作者</strong>和__VIEWSTATE值</li></ul><p id="3ea2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">3.对于在结果页面中找到的每个<strong class="it hv">标签</strong>:</p><ul class=""><li id="ff34" class="li lj hu it b iu iv iy iz jc lk jg ll jk lm jo lr lo lp lq dt translated">向/filter.aspx发出POST请求，传递选定的<strong class="it hv">作者</strong>，选定的<strong class="it hv">标签</strong>和视图状态</li></ul><p id="cc1f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">4.刮掉生成的页面</p><h1 id="42ef" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">编码蜘蛛</h1><p id="45ab" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">这是我开发的蜘蛛，按照刚才描述的步骤从网站上抓取报价:</p><pre class="ku kv kw kx fq ls lt lu lv aw lw dt"><span id="0854" class="lx jr hu lt b fv ly lz l ma mb"><strong class="lt hv">import</strong> scrapy</span><span id="6d84" class="lx jr hu lt b fv mc lz l ma mb"><strong class="lt hv">class</strong> SpidyQuotesViewStateSpider(scrapy.Spider):<br/>    name = 'spidyquotes-viewstate'<br/>    start_urls = ['http://quotes.toscrape.com/search.aspx']<br/>    download_delay = 1.5</span><span id="0917" class="lx jr hu lt b fv mc lz l ma mb">    <strong class="lt hv">def</strong> parse(self, response):<br/>        <strong class="lt hv">for</strong> author <strong class="lt hv">in</strong> response.css('select#author &gt; option ::attr(value)').extract():<br/>            <strong class="lt hv">yield</strong> scrapy.FormRequest(<br/>                'http://quotes.toscrape.com/filter.aspx',<br/>                formdata={<br/>                    'author': author,<br/>                    '__VIEWSTATE': response.css('input#__VIEWSTATE::attr(value)').extract_first()<br/>                },<br/>                callback=self.parse_tags<br/>            )</span><span id="1e75" class="lx jr hu lt b fv mc lz l ma mb">    <strong class="lt hv">def</strong> parse_tags(self, response):<br/>        <strong class="lt hv">for</strong> tag <strong class="lt hv">in</strong> response.css('select#tag &gt; option ::attr(value)').extract():<br/>            <strong class="lt hv">yield</strong> scrapy.FormRequest(<br/>                'http://quotes.toscrape.com/filter.aspx',<br/>                formdata={<br/>                    'author': response.css(<br/>                        'select#author &gt; option[selected] ::attr(value)'<br/>                    ).extract_first(),<br/>                    'tag': tag,<br/>                    '__VIEWSTATE': response.css('input#__VIEWSTATE::attr(value)').extract_first()<br/>                },<br/>                callback=self.parse_results,<br/>            )</span><span id="e9eb" class="lx jr hu lt b fv mc lz l ma mb">    <strong class="lt hv">def</strong> parse_results(self, response):<br/>        <strong class="lt hv">for</strong> quote <strong class="lt hv">in</strong> response.css("div.quote"):<br/>            <strong class="lt hv">yield</strong> {<br/>                'quote': response.css('span.content ::text').extract_first(),<br/>                'author': response.css('span.author ::text').extract_first(),<br/>                'tag': response.css('span.tag ::text').extract_first(),<br/>            }</span></pre><p id="ea7a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">步骤1 </strong>由Scrapy完成，它读取start_urls并向/search.aspx生成GET请求。</p><p id="ca36" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">parse()方法负责<strong class="it hv">步骤2 </strong>。它遍历在第一个选择框中找到的<strong class="it hv">作者</strong>，并为每个<strong class="it hv">作者</strong>创建一个<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/request-response.html#formrequest-objects" rel="noopener ugc nofollow" target="_blank">form request</a>to/filter . aspx，模拟用户是否点击了列表中的每个元素。值得注意的是，parse()方法从接收到的表单中读取__VIEWSTATE字段，并将其传递回服务器，以便服务器可以跟踪我们在页面流中的位置。</p><p id="e5d5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">步骤3 </strong>由parse_tags()方法处理。它非常类似于parse()方法，因为它提取列出的<strong class="it hv">标签</strong>，并创建POST请求，传递每个<strong class="it hv">标签</strong>，在前面的步骤中选择的<strong class="it hv">作者</strong>，以及从服务器接收的__VIEWSTATE。</p><p id="bbda" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最后，在<strong class="it hv">步骤4 </strong>中，parse_results()方法解析页面显示的报价列表，并从中生成条目。</p><h1 id="95bf" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">使用FormRequest.from_response()简化您的蜘蛛</h1><p id="5312" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">您可能已经注意到，在向服务器发送POST请求之前，我们的蜘蛛会提取从服务器收到的表单中预先填充的值，并将这些值包含在它将要创建的请求中。</p><p id="9c54" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">因为<a class="ae jp" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank"> Scrapy </a>提供了<a class="ae jp" href="http://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.FormRequest.from_response" rel="noopener ugc nofollow" target="_blank">form request . from _ response()</a>方法，所以我们不需要手工编写代码。这个方法读取响应对象并创建一个<code class="eh md me mf lt b">FormRequest</code>，它自动包含表单中所有预填充的值，以及隐藏的值。这就是我们蜘蛛的parse_tags()方法的样子:</p><pre class="ku kv kw kx fq ls lt lu lv aw lw dt"><span id="16eb" class="lx jr hu lt b fv ly lz l ma mb"><strong class="lt hv">def</strong> parse_tags(self, response):<br/>    <strong class="lt hv">for</strong> tag <strong class="lt hv">in</strong> response.css('select#tag &gt; option ::attr(value)').extract():<br/>        <strong class="lt hv">yield</strong> scrapy.FormRequest.from_response(<br/>            response,<br/>            formdata={'tag': tag},<br/>            callback=self.parse_results,<br/>        )</span></pre><p id="e781" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">因此，每当您处理包含一些隐藏字段和预填充值的表单时，使用<code class="eh md me mf lt b">from_response</code>方法，因为您的代码看起来会干净得多。</p><h1 id="32c1" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">包裹</h1><p id="1acd" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">你可以在这里阅读更多关于视图状态的信息。我总是在寻找新的网络抓取技巧，所以如果你在抓取网络时遇到任何障碍，请在下面的评论中告诉我，或者随时联系<a class="ae jp" href="https://twitter.com/scrapinghub" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或<a class="ae jp" href="https://www.facebook.com/ScrapingHub/" rel="noopener ugc nofollow" target="_blank">脸书</a>。</p><p id="239d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">作为一个提醒，<a class="ae jp" href="https://scrapinghub.com/platform/" rel="noopener ugc nofollow" target="_blank"> Scrapy Cloud </a>是一个永远免费的网络抓取平台，可以让你扩展和管理你的爬虫。如果您想部署您在本教程中构建的蜘蛛，请尝试Scrapy Cloud。</p></div><div class="ab cl mg mh hc mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="hn ho hp hq hr"><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div class="fe ff mn"><img src="../Images/7c7fe2e670081a58430f9315be2e77ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*eB6mGeLhPSP3hXrcrtRuqQ.jpeg"/></div></figure><p id="7090" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这篇帖子是Zyte(前身为Scrapinghub)的开发者巴尔迪尔·斯图姆(<a class="ae jp" href="https://twitter.com/stummjr" rel="noopener ugc nofollow" target="_blank">@ stumjr</a>)写的。</p><p id="7927" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">请用心“推荐”，让别人可以学到更多的网页抓取技巧。</p><p id="220a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae jp" href="https://scrapinghub.com/data-services/" rel="noopener ugc nofollow" target="_blank"><strong class="it hv"/></a><strong class="it hv">了解更多关于网络抓取和网络数据能为你做什么。</strong></p><div class="ku kv kw kx fq ab cb"><figure class="mo ky mp mq mr ms mt paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="mo ky mp mq mr ms mt paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="mo ky mp mq mr ms mt paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="mu mv mw"><p id="f922" class="ir is lf it b iu iv iw ix iy iz ja jb mx jd je jf my jh ji jj mz jl jm jn jo hn dt translated"><a class="ae jp" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae jp" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae jp" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae jp" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="ir is lf it b iu iv iw ix iy iz ja jb mx jd je jf my jh ji jj mz jl jm jn jo hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae jp" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae jp" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="fe ff na"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></div></figure></div></div>    
</body>
</html>