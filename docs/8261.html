<html>
<head>
<title>IMDB Sentiment Analysis using a pre-trained Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用预训练模型的IMDB情感分析</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/imdb-sentiment-analysis-using-a-pre-trained-model-80c3d8343d48?source=collection_archive---------7-----------------------#2017-11-26">https://medium.com/hackernoon/imdb-sentiment-analysis-using-a-pre-trained-model-80c3d8343d48?source=collection_archive---------7-----------------------#2017-11-26</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><blockquote class="ir is it"><p id="d2c0" class="iu iv iw ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hn dt translated">本文首发<a class="ae jt" href="http://sanyambhutani.com/IMDB-Sentiment-Analysis-using-pretrained-Model/" rel="noopener ugc nofollow" target="_blank">此处</a></p></blockquote><p id="70e7" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">我们必须承认，在NLP中使用预训练模型的概念是相当新的。</p><p id="f590" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">在这篇文章中，我分享了一个在<a class="ae jt" href="https://hackernoon.com/tagged/fastai" rel="noopener ugc nofollow" target="_blank"> FastAI </a>课程第二版(将于明年公开发布)中教授的方法:在<a class="ae jt" href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank">大型电影观看数据集</a>上训练一个语言模型，该数据集包含来自<a class="ae jt" href="https://hackernoon.com/tagged/imdb" rel="noopener ugc nofollow" target="_blank"> IMDB </a>的50，000条评论，从而为我们提供了大量数据来测试和训练我们的模型，然后使用相同的模型对IMDB评论进行情感分析。</p><h1 id="b473" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated"><strong class="ak">语言建模</strong></h1><p id="2560" class="pw-post-body-paragraph iu iv hu ix b iy kv ja jb jc kw je jf ju kx ji jj jv ky jm jn jw kz jq jr js hn dt translated">创建一个模型，用于预测/产生一种语言或简单地基于当前单词集预测语言中的下一个单词。</p><h1 id="afde" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated"><strong class="ak">情感分析</strong></h1><p id="e2bc" class="pw-post-body-paragraph iu iv hu ix b iy kv ja jb jc kw je jf ju kx ji jj jv ky jm jn jw kz jq jr js hn dt translated">分析一组给定的单词来预测段落中的情感。</p><h1 id="1d21" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated">IMDB大型电影数据集</h1><ul class=""><li id="9ea7" class="la lb hu ix b iy kv jc kw ju lc jv ld jw le js lf lg lh li dt translated">该数据集有50，000条评论</li><li id="ee92" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">所有这些评论都是英文的，两极分化的标签评论</li></ul><p id="a928" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">下面是我们实验中关键步骤的演示。</p><p id="ec0d" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">使用的库:PyTorch、FastAI</p><h1 id="9d5b" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated">为什么要使用预训练模型？</h1><ul class=""><li id="3420" class="la lb hu ix b iy kv jc kw ju lc jv ld jw le js lf lg lh li dt translated">达到的精确度优于传统方法</li><li id="b0db" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">微调模型是强大的</li></ul><h1 id="e860" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated">预训练</h1><p id="ad05" class="pw-post-body-paragraph iu iv hu ix b iy kv ja jb jc kw je jf ju kx ji jj jv ky jm jn jw kz jq jr js hn dt translated">本质上，我们将使用预训练网络，但这里我们将自己创建相同的网络。</p><p id="3cd7" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">我们使用PyTorch的Torchtext库对数据进行预处理</p><pre class="lo lp lq lr fq ls lt lu lv aw lw dt"><span id="2aa0" class="lx jy hu lt b fv ly lz l ma mb">TEXT = data.Field(lower=True, tokenize=spacy_tok)</span></pre><p id="8ad3" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">我们用空格来标记我们的数据，并保持小写。</p><p id="fd25" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">接下来，我们创建我们的模型数据，这些数据将被提供给学习模型来执行语言建模。</p><pre class="lo lp lq lr fq ls lt lu lv aw lw dt"><span id="ac97" class="lx jy hu lt b fv ly lz l ma mb">md = LanguageModelData(PATH, TEXT, **FILES, bs=64, bptt=70, min_freq=10)</span></pre><ul class=""><li id="b7a9" class="la lb hu ix b iy iz jc jd ju mc jv md jw me js lf lg lh li dt translated">Path指向数据集的路径。</li><li id="3f15" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">文本包含预处理的数据。</li><li id="9e7b" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">文件是我们数据集的字典。</li><li id="23e1" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">bs提到了批量大小</li><li id="5772" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">bptt:我们将反向传播的字数。</li><li id="141b" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">min_freq:频率低于此值的单词保持不分类</li></ul><p id="aed3" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">既然我们知道神经网络不能真正处理单词，我们需要将单词映射成整数。火炬文本已经通过映射我们的单词做到了这一点</p><pre class="lo lp lq lr fq ls lt lu lv aw lw dt"><span id="88e7" class="lx jy hu lt b fv ly lz l ma mb">TEXT.vocab </span></pre><h1 id="7dc1" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated">培养</h1><p id="061f" class="pw-post-body-paragraph iu iv hu ix b iy kv ja jb jc kw je jf ju kx ji jj jv ky jm jn jw kz jq jr js hn dt translated">接下来，我们创建一个学习者对象，并为其调用fit函数。</p><pre class="lo lp lq lr fq ls lt lu lv aw lw dt"><span id="732a" class="lx jy hu lt b fv ly lz l ma mb">learner = md.get_model(opt_fn, em_sz, nh, nl,dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)</span><span id="7aab" class="lx jy hu lt b fv mf lz l ma mb">learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)</span></pre><ul class=""><li id="70d2" class="la lb hu ix b iy iz jc jd ju mc jv md jw me js lf lg lh li dt translated">opt_fn: Optimizer函数，快速AI库使用<a class="ae jt" href="https://arxiv.org/abs/1708.02182" rel="noopener ugc nofollow" target="_blank"> AWD LSTM模型</a>，该模型通过ising dropout非常擅长正则化。</li><li id="56cc" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">我们传递嵌入大小</li><li id="0d4d" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">nh:隐藏层数</li><li id="1ae5" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">nn:神经网络的层数。</li><li id="b3e1" class="la lb hu ix b iy lj jc lk ju ll jv lm jw ln js lf lg lh li dt translated">我们在拟合函数中设置学习率、周期长度和其他参数。</li></ul><p id="801f" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">嵌入矩阵:<a class="ae jt" rel="noopener" href="/@krishnakalyan3/a-gentle-introduction-to-embedding-567d8738372b">这是一个关于嵌入的简介</a>的链接。</p><h1 id="1fd2" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated">语言模型</h1><p id="13f0" class="pw-post-body-paragraph iu iv hu ix b iy kv ja jb jc kw je jf ju kx ji jj jv ky jm jn jw kz jq jr js hn dt translated">这是一个由经过训练的模型生成的文本示例</p><pre class="lo lp lq lr fq ls lt lu lv aw lw dt"><span id="e321" class="lx jy hu lt b fv ly lz l ma mb">. So, it wasn’t quite was I was expecting, but I really liked it anyway! The bestperformance was the one in the movie where he was a little too old for the part . i think he was a good actor , but he was nt that good .the movie was a bit slow , but it was n’t too bad . the acting …</span></pre><p id="66b8" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">因此，到目前为止，我们已经创建了一个可以成功创建电影评论的模型，该模型开始时甚至不懂英语。接下来，我们根据我们的目标任务对此进行微调。</p><h1 id="bba1" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated">微调</h1><p id="f5b6" class="pw-post-body-paragraph iu iv hu ix b iy kv ja jb jc kw je jf ju kx ji jj jv ky jm jn jw kz jq jr js hn dt translated">到目前为止，我们已经在语言建模方面很好地训练了我们的模型。现在我们用同样的方法来预测电影评论的情绪。</p><p id="53f0" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">我们预加载我们的模型。</p><pre class="lo lp lq lr fq ls lt lu lv aw lw dt"><span id="6c65" class="lx jy hu lt b fv ly lz l ma mb">model.freeze_to(-1)<br/>model.fit(lr, 1, metrics=[accuracy])<br/>model.unfreeze()<br/>model.fit(lr, 1, metrics=[accuracy], cycle_len=1)</span></pre><p id="3b03" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">我们把模型冻结到最后一层，在设定了学习速率后再进行拟合。我们定义我们的准确性指标。</p><h1 id="a0f5" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated">表演</h1><p id="526c" class="pw-post-body-paragraph iu iv hu ix b iy kv ja jb jc kw je jf ju kx ji jj jv ky jm jn jw kz jq jr js hn dt translated"><a class="ae jt" href="https://einstein.ai/research/learned-in-translation-contextualized-word-vectors" rel="noopener ugc nofollow" target="_blank">在翻译中学习:语境化的词向量</a>是一篇比较所有前沿模型在IMDB数据集上的性能作为基准比较的论文。</p><figure class="lo lp lq lr fq mh fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/6ae7413a552bf5e837f2b14ec99e4016.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*rUFiL--cP9nZehmV6iWKGw.png"/></div><figcaption class="mk ml fg fe ff mm mn bd b be z ek">IMDB Performance Comparisions: Breden et al</figcaption></figure><p id="2e06" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">在微调学习率、调整周期长度后，模型达到的精度为</p><pre class="lo lp lq lr fq ls lt lu lv aw lw dt"><span id="31a4" class="lx jy hu lt b fv ly lz l ma mb">0.94511217948717952</span></pre><p id="9904" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt">94.51 !</p><h1 id="f355" class="jx jy hu bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dt translated">结论</h1><p id="ec48" class="pw-post-body-paragraph iu iv hu ix b iy kv ja jb jc kw je jf ju kx ji jj jv ky jm jn jw kz jq jr js hn dt translated">我们从制作IMBD电影评论的模式开始。</p><p id="5b83" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">2017年研究的艺术状态是94.1。因此，应用预先训练的语言模型的想法实际上也胜过了学术界的前沿研究。</p><p id="e45d" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf ju jh ji jj jv jl jm jn jw jp jq jr js hn dt translated">我个人正在与我的学院合作，开发一个模型来分析学生提交的教员评论中的观点。</p><blockquote class="ir is it"><p id="6965" class="iu iv iw ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hn dt translated">要了解更多关于深度学习的信息，请访问Fast.ai</p><p id="4a6a" class="iu iv iw ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hn dt translated">订阅<a class="ae jt" href="http://tinyletter.com/sanyambhutani" rel="noopener ugc nofollow" target="_blank">我的简讯</a>获取深度学习、计算机视觉的每周精选文章</p><p id="e10a" class="iu iv iw ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hn dt translated">如果你想在我正在做的项目上与我合作，请访问我的网站。</p></blockquote><figure class="lo lp lq lr fq mh"><div class="bz el l di"><div class="mo mp l"/></div></figure></div></div>    
</body>
</html>