<html>
<head>
<title>Playing with char-rnn and the NIPS 2015 data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用char-rnn和NIPS 2015数据</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/playing-with-char-rnn-and-the-nips-2015-data-6571eebad2dd?source=collection_archive---------0-----------------------#2015-12-14">https://medium.com/hackernoon/playing-with-char-rnn-and-the-nips-2015-data-6571eebad2dd?source=collection_archive---------0-----------------------#2015-12-14</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="34ef" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">自从<a class="jp jq gr" href="https://medium.com/u/f3c8148878e1?source=post_page-----6571eebad2dd--------------------------------" rel="noopener" target="_blank"> samim </a>发表了所有那些关于使用递归神经网络生成文本的可怕而有趣的帖子(参见:<a class="ae jr" rel="noopener" href="/@samim/zen-rrnn-on-meditation-machines-bbeb92aa62d3#.vn9ox6zb8"> Zen-RNN </a>、<a class="ae jr" rel="noopener" href="/@samim/ted-rnn-machine-generated-ted-talks-3dd682b894c0"> TED-RNN </a>、<a class="ae jr" rel="noopener" href="/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0">奥巴马-RNN </a>)，我一直在寻找机会自己尝试一下<a class="ae jr" href="https://github.com/karpathy/char-rnn" rel="noopener ugc nofollow" target="_blank"> char-nn </a>库。在今年的神经信息处理系统会议(<a class="ae jr" href="https://nips.cc/" rel="noopener ugc nofollow" target="_blank"> NIPS </a> 2015)上的所有论文都出现在网上之后，一个机会出现了。有什么比一堆大谈RNNs的论文更适合和*一个RNN玩呢？</p><h2 id="1620" class="js jt hu bd ju jv jw jx jy jz ka kb kc jc kd ke kf jg kg kh ki jk kj kk kl km dt translated"><strong class="ak">NIPS 2015数据集</strong></h2><p id="618e" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated">该数据集是作为这一竞赛的一部分提供的。它包括一个CSV文件，其中包含所有论文的文本，摘自今年接受的<a class="ae jr" href="https://nips.cc/Conferences/2015/AcceptedPapers" rel="noopener ugc nofollow" target="_blank">论文</a>。</p><h2 id="570f" class="js jt hu bd ju jv jw jx jy jz ka kb kc jc kd ke kf jg kg kh ki jk kj kk kl km dt translated"><strong class="ak">预处理</strong></h2><p id="5972" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated">文本数据(使用工具<a class="ae jr" href="https://en.wikipedia.org/wiki/Pdftotext" rel="noopener ugc nofollow" target="_blank"> pdftotext </a>从pdf中提取)非常嘈杂:pdftotext不提取页码、回车断字、等式、章节标题、变量、图形标题、表格、脚注以及研究人员可以用各种LaTeX命令放入简单文本的所有其他复杂性。结果是我们显然不想用来训练任何东西的文本。这里有一个相对常见的例子:</p><blockquote class="ks kt ku"><p id="82be" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">pβt xpiqβt y pjq Q2 mij " max<br/>minβt WMβ<br/>(3)<br/>βPb<br/>| |β| | 0 ďk</p></blockquote><p id="77b6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这段文字是由人类“生成”的。对于这个实验*，我希望使用<em class="kv">完整的句子</em>进行训练，这在技术/算法论文中是很少见的。根据我的经验，它们往往出现在摘要、引言、相关工作、讨论/结论部分。因此，我过滤了每篇论文——手动删除了引言之后和结论之前的所有内容(但这在不同的论文之间有所不同*)——是的，如果你想知道，这是一个巨大的痛苦，而且没有做到完美。</p><p id="6f4d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">注意:我确实先尝试了一些正则表达式(并且使用了一些来删除引用之类的东西)，但是只能做到这一步:在部分标题中有很多变化，并且总的来说有太多的情况/异常值/异常来合理地自动化这个。</p><h2 id="4442" class="js jt hu bd ju jv jw jx jy jz ka kb kc jc kd ke kf jg kg kh ki jk kj kk kl km dt translated">培养</h2><p id="f592" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated">char-rnn库使生活变得非常简单。一旦火炬(等。)已经安装好了，所有的论文都放入了一个单独的<em class="kv"> input.txt </em>文件中，训练模型就差一行代码了。</p><p id="2946" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我使用了具有较高压差值(0.5)的标准设置来最小化过度拟合——尤其是因为数据仍然相当嘈杂。</p><h2 id="546e" class="js jt hu bd ju jv jw jx jy jz ka kb kc jc kd ke kf jg kg kh ki jk kj kk kl km dt translated">比较，无意义的结果</h2><p id="9b76" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated">这是一些结果。人类输入的例子来自于从包含种子文本的输入数据中随机选取一行；然后使用相同的种子生成机器文本。</p><p id="8b1a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> Seed:“我们要解决的任务”</strong></p><blockquote class="ks kt ku"><p id="4f88" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">例子人类:“我们的目标是解决填补高维二进制时间序列数据中多个连续数据点的空白。”</p><p id="fbc3" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">机器:“我们的任务旨在解决推理学习问题的证明所提供的方法和算法方法是可能的后验和计算的状态时间的演示是预期的限制，在局部极大极小。”</p></blockquote><p id="38c2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">种子:【本文我们】</strong></p><blockquote class="ks kt ku"><p id="ddb0" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">例子人:“在本文中，我们提出了一种新的离散空间模型的参数估计器，它不需要计算归一化常数。”</p><p id="67a3" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">机器:“在本文中，我们提出f的输入信息对于每个预测都是增加的，并且minimax方法优于下面的分布，并且可以稳健地分析树图像mint离散化到s vret的计算实验，并且在可能的数据大小中仅可能是线性遗憾中的加速rime。”</p></blockquote><p id="1e90" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">种子:【总结】</strong></p><blockquote class="ks kt ku"><p id="b7fb" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">示例人类:<em class="hu"> " </em>最后，我们在图1中用黑色显示了一组优化的伪输入Z。我们还在实现中叠加了任意单点的边际，通过这里L的谱分解可以得到。”</p><p id="adf3" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">机器:“总结来说，每个相对可能发展的分布约束分解的子模型规模的目标是真实的恢复信息的预期概率的预测参数是步骤的算法是一种分析方法，这种分析后的随机性质的广泛程序的最大复杂性集。”</p></blockquote><h2 id="cbfe" class="js jt hu bd ju jv jw jx jy jz ka kb kc jc kd ke kf jg kg kh ki jk kj kk kl km dt translated">好玩的种子</h2><p id="803c" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated"><strong class="it hv">种子:“生命的意义在于”</strong></p><blockquote class="ks kt ku"><p id="7dd9" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">机器:“生命的意义是表明扩大我们的线性期望在一个计算机方差的水平生产控制分布的最小逃学特征值的相似状态。”</p></blockquote><p id="e89f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">种子:“今晚的晚餐是”</strong></p><blockquote class="ks kt ku"><p id="cb90" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">"今晚的晚餐显示出扩展函数大小点的学习兴趣，因为那时一个分别。"</p></blockquote><p id="7b92" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">种子:“机器学习研究应该”</strong></p><blockquote class="ks kt ku"><p id="996d" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">"机器学习的研究应该推广到网络中只有二次共享图像的情况."</p></blockquote><p id="49f3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> Seed:“我的预言是”</strong></p><blockquote class="ks kt ku"><p id="994b" class="ir is kv it b iu iv iw ix iy iz ja jb kw jd je jf kx jh ji jj ky jl jm jn jo hn dt translated">“我的预测与模型中的线性和非梯度函数的先验有关，也考虑了后验的MDM，并定义了用大型优化分析定义为计算p的状态的真实值。”</p></blockquote><h2 id="fc6e" class="js jt hu bd ju jv jw jx jy jz ka kb kc jc kd ke kf jg kg kh ki jk kj kk kl km dt translated"><strong class="ak">一些想法</strong></h2><ul class=""><li id="bb0c" class="kz la hu it b iu kn iy ko jc lb jg lc jk ld jo le lf lg lh dt translated">机器不会很快接管一切。</li><li id="fe82" class="kz la hu it b iu li iy lj jc lk jg ll jk lm jo le lf lg lh dt translated">从PDF中提取高质量的文本比训练一个RNN更难(正如这篇NIPS论文指出的“机器学习”是“机器学习系统”的一小部分).</li><li id="1f45" class="kz la hu it b iu li iy lj jc lk jg ll jk lm jo le lf lg lh dt translated">这是我第一次使用char-rnn库。很可能对它了解得多一点的人会得到更好的结果。</li><li id="a2ff" class="kz la hu it b iu li iy lj jc lk jg ll jk lm jo le lf lg lh dt translated">我想知道进一步的预处理是否会产生更好的训练数据集。例如，可以使用某种聚类来识别相似的论文(例如，对单词包进行比较)，然后只在一个特定的聚类上进行训练。</li></ul><h2 id="6e60" class="js jt hu bd ju jv jw jx jy jz ka kb kc jc kd ke kf jg kg kh ki jk kj kk kl km dt translated">感谢:</h2><ul class=""><li id="5a02" class="kz la hu it b iu kn iy ko jc lb jg lc jk ld jo le lf lg lh dt translated">由<a class="jp jq gr" href="https://medium.com/u/f3c8148878e1?source=post_page-----6571eebad2dd--------------------------------" rel="noopener" target="_blank"> samim </a>以前的职位。在这里找到了<a class="ae jr" rel="noopener" href="/@samim"/>。</li><li id="d440" class="kz la hu it b iu li iy lj jc lk jg ll jk lm jo le lf lg lh dt translated">github上<a class="ae jr" href="https://github.com/karpathy/char-rnn" rel="noopener ugc nofollow" target="_blank"> char-nn的作者和投稿人</a>。</li><li id="97ac" class="kz la hu it b iu li iy lj jc lk jg ll jk lm jo le lf lg lh dt translated">Kaggle，因为它的数据，因为它是一个非常棒的地方。在这里找到了<a class="ae jr" href="https://www.kaggle.com/c/nips-2015-papers" rel="noopener ugc nofollow" target="_blank"/>。</li></ul><p id="dade" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">[*]这是<strong class="it hv">不是</strong>科学。</p></div></div>    
</body>
</html>