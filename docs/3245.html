<html>
<head>
<title>Job Concurrency in Kubernetes: LXD and CPU-pinning to the rescue</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes中的作业并发性:LXD和CPU牵制拯救</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/job-concurrency-in-kubernetes-lxd-and-cpu-pinning-to-the-rescue-b9fb7b44f99d?source=collection_archive---------7-----------------------#2017-03-22">https://medium.com/hackernoon/job-concurrency-in-kubernetes-lxd-and-cpu-pinning-to-the-rescue-b9fb7b44f99d?source=collection_archive---------7-----------------------#2017-03-22</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="458d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">前几天有人跟我分享了一个在Kubernetes中运行视频转码作业的项目。</p><p id="552c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在她的测试中，Kubernetes默认安装在具有40个内核和512GB RAM的裸机服务器上，她为每个转码pod分配了5个完整的CPU内核，然后扩展到每个节点6个并发任务，因此机器的负载为75%(理论上)。人们的期望是，这些作业将以与单个任务相同的速度运行。</p><p id="8a92" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">他们的结果令人失望:当并发性上升时，单个任务的性能却下降了。在最大并发时，他们实际上观察到单个任务性能下降了50%。</p><p id="9939" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我做了一些研究来理解这种行为。它在几期Kubernetes中被提及，如<a class="ae jp" href="https://github.com/kubernetes/kubernetes/issues/10570" rel="noopener ugc nofollow" target="_blank"> #10570 </a>、<a class="ae jp" href="https://github.com/kubernetes/community/pull/171" rel="noopener ugc nofollow" target="_blank"> #171 </a>，一般通过<a class="ae jp" href="https://www.google.com/search?q=cpuset%20kubernetes&amp;*&amp;rct=j" rel="noopener ugc nofollow" target="_blank">谷歌搜索</a>。<a class="ae jp" href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" rel="noopener ugc nofollow" target="_blank">文档</a>本身揭示了默认调度程序如何工作，以及为什么性能会受到密集型任务并发性的影响。</p><p id="b4e2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为容器分配CPU时间有不同的方法:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff jq"><img src="../Images/7d599c7a75c510c1aeef3612c15a8dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l_PprqofJxoj94od44Aq0Q.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">CPU Pining: each container gets a set of cores</figcaption></figure><p id="b43a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> CPU Pining </strong>:如果主机有足够的CPU核心可用，则分配5个“物理核心”专用于该pod/container；</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff jq"><img src="../Images/998615b935ddc58158a44345d9fbfb38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5F6VKjig_Z9w336ilKAz1g.png"/></div></div></figure><p id="1a58" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">时间切片</strong>:考虑主机有N个内核，共同代表分配给容器的计算时间量。5%的CPU时间意味着每100毫秒就有5毫秒的计算时间用于该任务。</p><p id="895a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">显然，对某些特定的工作负载来说，pining CPUs可能很有意思，但是有一个很大的规模问题，原因很简单，您不能运行比您的集群中的核心更多的pod。<br/>因此，<a class="ae jp" href="https://hackernoon.com/tagged/docker" rel="noopener ugc nofollow" target="_blank"> Docker </a>默认为第二个，这也确保了分配给容器的CPU少于1个。<br/>这会对性能产生影响，这在HPC或任何CPU密集型任务中也会发生。</p><p id="f405" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们能降低这种风险吗？也许吧。Docker在引擎级别提供了cpuset选项。然而，它并没有被Kubernetes利用。然而，<a class="ae jp" href="https://www.ubuntu.com/containers/lxd" rel="noopener ugc nofollow" target="_blank"> LXD容器</a>能够通过cpusets以自动化的方式被pined到物理核心，正如<a class="ae jp" href="https://twitter.com/stgraber" rel="noopener ugc nofollow" target="_blank">@ str graber</a>在这篇<a class="ae jp" href="https://stgraber.org/2016/03/26/lxd-2-0-resource-control-412/" rel="noopener ugc nofollow" target="_blank">博客</a>中所解释的。</p><p id="b630" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这为安排我们的工作负载提供了两个新选项:</p><ul class=""><li id="c84c" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated">将我们的主机分成几个LXD Kubernetes工人，看看为工人钉CPU是否能有所帮助；</li><li id="19dc" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">在本地Kubernetes资源原语中包含一个“突发”选项，看看这是否有助于最大化我们集群中的计算吞吐量。</li></ul><p id="8a69" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们看看这些是如何比较的！</p><h2 id="42df" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">TL；速度三角形定位法(dead reckoning)</h2><p id="80ee" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">你们没有时间阅读整本书，所以简单来说:</p><ul class=""><li id="cfdd" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated">如果分配给pods的CPU总是少于1个，那么并发性不会影响CPU限制的性能；</li><li id="54e3" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">如果你预先知道你的最大并发性，并且它不是很高，那么通过LXD和CPU锁定来增加更多的工作线程总是比通过Docker的本地调度获得更好的性能；</li><li id="fd12" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">获胜的策略总是最大限度地超级配置CPU限制，以便将每一点性能都立即分配到您的pod</li></ul><p id="fe77" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">注意:</strong>这些结果在AWS中，在金属和单元之间有一个管理程序。我正在等待具有足够内核的硬件来完成任务。如果你有硬件可以用，请便，我会帮你做测试。</p><h2 id="db76" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">这个计划</h2><p id="2c3a" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">在这篇博文中，我们将做以下事情:</p><ol class=""><li id="5132" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo lu km kn ko dt translated">在严格分配CPU的LXD容器中设置各种Kubernetes集群:纯裸机、纯云。</li><li id="c207" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo lu km kn ko dt translated">设计一个极简的舵图，轻松创建并行</li><li id="6e0d" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo lu km kn ko dt translated">运行基准测试以扩展并发性(最多32个线程/节点)</li><li id="3bca" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo lu km kn ko dt translated">从这些运行中提取并处理日志，以了解并发性如何影响每个内核的性能</li></ol><h2 id="b84c" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">要求</h2><p id="34ed" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">对于这篇博文，我们假设</p><ul class=""><li id="1c64" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated">你对库伯内特很熟悉</li><li id="4461" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">你有赫尔姆制图或Go模板的概念，以及使用赫尔姆部署东西的概念</li><li id="7a49" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">对Kubernetes (CDK) 的<a class="ae jp" href="https://www.ubuntu.com/containers/kubernetes" rel="noopener ugc nofollow" target="_blank">规范分布有初步了解者优先，但不是必需的。</a></li><li id="5061" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">下载这篇文章的代码</li></ul><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="5c81" class="ku kv hu lw b fv ma mb l mc md">git clone <a class="ae jp" href="https://github.com/madeden/blogposts" rel="noopener ugc nofollow" target="_blank">https://github.com/madeden/blogposts</a><br/>cd blogposts/k8s-transcode</span></pre><h2 id="6559" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">方法学</h2><p id="1683" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">我们的基准是一个代码转换任务。它使用ffmpeg工作负载，旨在通过尽可能快地耗尽分配给计算的所有资源来最小化编码时间。我们使用单个视频进行编码，以便可以比较所有转码任务。为了最大限度地减少纯计算以外的瓶颈，我们使用相对低带宽的视频，存储在每台主机上。</p><p id="5d0a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">转码作业运行多次，有以下变化:</p><ul class=""><li id="f0f0" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated">从0.1到7个CPU核心的CPU分配</li><li id="2117" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">内存从0.5到8GB RAM</li><li id="68a3" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">每台主机1到32个并发线程的并发性</li><li id="5fe4" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">(并发* CPU分配)永远不会超过单个主机的内核数量</li></ul><p id="6cce" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们测量每个pod编码需要多长时间，然后查看编码和我们的变量之间的相关性。</p></div><div class="ab cl me mf hc mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="hn ho hp hq hr"><h1 id="52fa" class="ml kv hu bd kw mm mn mo la mp mq mr le ms mt mu lh mv mw mx lk my mz na ln nb dt translated">绘制一个简单的代码转换器</h1><h2 id="2caa" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">使用ffmpeg和Docker进行转码</h2><p id="8ebc" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">当我想用视频做点什么的时候，我做的第一件事就是给我的朋友罗南打电话(<a class="ae jp" href="http://twitter.com/ronan_delacroix" rel="noopener ugc nofollow" target="_blank">@罗南_德拉克洛瓦</a>)。他对转码的一切了如指掌！</p><p id="35a3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所以我问了他一些很直接的问题:<em class="nc">我想要你能想到的CPU最密集的ffmpeg代码转换一个liner】。</em></p><p id="ea33" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">他不仅带回了一艘班轮，还为它找到了一个非常整洁的码头工人形象，这是朱利安的功劳。</p><p id="8b2e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">总之，您将获得:</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="06f6" class="ku kv hu lw b fv ma mb l mc md">docker run --rm -v $PWD:/tmp jrottenberg/ffmpeg:ubuntu \<br/> -i /tmp/source.mp4 \<br/> -stats -c:v libx264 \<br/> -s 1920x1080 \<br/> -crf 22 \<br/> -profile:v main \<br/> -pix_fmt yuv420p \<br/> -threads 0 \<br/> -f mp4 -ac 2 \<br/> -c:a aac -b:a 128k \<br/> -strict -2 \<br/> /tmp/output.mp4</span></pre><p id="bc41" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这个设置的关键是<em class="nc"> -threads 0 </em>，它告诉ffmpeg这是一个自助餐。</p><p id="b9c6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对于测试视频，<a class="ae jp" href="http://www.hd-trailers.net/" rel="noopener ugc nofollow" target="_blank">高清预告片</a>或<a class="ae jp" href="https://download.blender.org/durian/trailer/" rel="noopener ugc nofollow" target="_blank">辛特尔预告片</a>是很好的来源。我用的是1080p的mp4预告片。</p><h2 id="ca6c" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">舵图</h2><p id="56b7" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">代码转换直接映射到Kubernetes中的<em class="nc">作业</em>的概念。作业是批处理过程，可以很容易地进行编排和配置，以便Kubernetes在作业完成时不会重新启动它们。</p><p id="9f3d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">与部署副本相当的是<em class="nc">作业并行度</em>。</p><p id="699b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了增加并发性，我想我首先试验了它。事实证明，这是一种糟糕的方法，使得分析输出日志变得更加复杂。所以我构建了一个图表，创建了许多(编号的)作业，每个作业运行一个pod，这样我就可以轻松地跟踪它们和它们的日志。</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="158f" class="ku kv hu lw b fv ma mb l mc md">{{- $type := .Values.type -}}<br/>{{- $parallelism := .Values.parallelism -}}<br/>{{- $cpu := .Values.resources.requests.cpu -}}<br/>{{- $memory := .Values.resources.requests.memory -}}<br/>{{- $requests := .Values.resources.requests -}}<br/>{{- $multiSrc := .Values.multiSource -}}<br/>{{- $src := .Values.defaultSource -}}<br/>{{- $burst := .Values.burst -}}<br/>---<br/>{{- range $job, $nb := until (int .Values.parallelism) }}<br/>apiVersion: batch/v1<br/>kind: Job<br/>metadata:<br/>  name: {{ $type | lower }}-{{ $parallelism }}-{{ $cpu | lower }}-{{ $memory | lower }}-{{ $job }}<br/>spec:<br/>  parallelism: 1<br/>  template:<br/>    metadata:<br/>      labels:<br/>        role: transcoder<br/>    spec:<br/>      containers:<br/>      - name: transcoder-{{ $job }}<br/>        image: jrottenberg/ffmpeg:ubuntu<br/>        args: [<br/>          "-y",<br/>          "-i", "/data/{{ if $multiSrc }}source{{ add 1 (mod 23 (add 1 (mod $parallelism (add $job 1)))) }}.mp4{{ else }}{{ $src }}{{ end }}",<br/>          "-stats",<br/>          "-c:v",<br/>          "libx264",<br/>          "-s", "1920x1080",<br/>          "-crf", "22",<br/>          "-profile:v", "main",<br/>          "-pix_fmt", "yuv420p",<br/>          "-threads", "0",<br/>          "-f", "mp4",<br/>          "-ac", "2",<br/>          "-c:a", "aac",<br/>          "-b:a", "128k",<br/>          "-strict", "-2",<br/>          "/data/output-{{ $job }}.mp4"<br/>        ]<br/>        volumeMounts:<br/>          - mountPath: /data<br/>            name: hostpath<br/>        resources:<br/>          requests: <br/>{{ toYaml $requests | indent 12 }}<br/>          limits:<br/>            cpu: {{ if $burst }}{{ max (mul 2 (atoi $cpu)) 8 | quote }}{{ else }}{{ $cpu }}{{ end }}<br/>            memory: {{ $memory }}<br/>      restartPolicy: Never<br/>      volumes:<br/>        - name: hostpath<br/>          hostPath:<br/>            path: /mnt<br/>---<br/>{{- end }}</span></pre><p id="6f41" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">与之配套的values.yaml文件非常非常简单:</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="6f66" class="ku kv hu lw b fv ma mb l mc md"># Number of // tasks<br/>parallelism: 8<br/># Separator name<br/>type: bm<br/># Do we want several input files<br/># if yes, the chart will use source${i}.mp4 with up to 24 sources<br/>multiSource: false<br/># If not multi source, name of the default file<br/>defaultSource: sintel_trailer-1080p.mp4<br/># Do we want to burst. If yes, resource limit will double request. <br/>burst: false<br/>resources:<br/>  requests:<br/>    cpu: "4"<br/>    memory: 8Gi</span></pre><p id="2bb8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这就是你所需要的。</p><p id="9547" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当然，所有的资源都在回购中供你使用，你不必复制粘贴这个。</p><h2 id="822c" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">创建测试文件</h2><p id="acc3" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">现在我们需要生成大量的values.yaml文件来覆盖许多用例。可达到的值将根据您的上下文而变化。我的家庭集群有6个工作线程，每个线程有4个内核和32GB RAM，所以我使用了</p><ul class=""><li id="32a1" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated">1、6、12、18、24、48、96和192个兼职(最多32个/工人)</li><li id="5d9a" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">CPU的情况正好相反(如果并行度=192，则从3到0.1)</li><li id="2e34" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">1至16GB内存</li></ul><p id="7d1a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在云中，我有16个使用60GB RAM的核心工作人员，所以我只对每个任务的1到7个CPU核心进行了测试。</p><p id="2b48" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我在这里没有做任何聪明的事情，只是一些bash循环来生成我的所有任务。如果需要的话，他们会参与回购。</p></div><div class="ab cl me mf hc mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="hn ho hp hq hr"><h1 id="b2d8" class="ml kv hu bd kw mm mn mo la mp mq mr le ms mt mu lh mv mw mx lk my mz na ln nb dt translated">部署Kubernetes</h1><h2 id="47d9" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">MAAS / AWS</h2><p id="e8d7" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">在MAAS上部署的方法与我在之前关于<a class="ae jp" href="https://hackernoon.com/installing-a-diy-bare-metal-gpu-cluster-for-kubernetes-364200254187#.si47g6h7e" rel="noopener ugc nofollow" target="_blank"> DIY GPU集群</a>的博客中描述的方法相同</p><p id="8984" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一旦安装了MAAS并配置Juju与之对话，就可以修改并使用src/juju/中的包文件</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="2710" class="ku kv hu lw b fv ma mb l mc md">juju deploy src/juju/k8s-maas.yaml</span></pre><p id="eba0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对于AWS，使用<em class="nc"> k8s-aws.yaml </em>包，它指定c4.4xlarge作为默认实例。</p><p id="a899" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">完成后，下载kubectl的配置，然后用</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="f2dc" class="ku kv hu lw b fv ma mb l mc md">juju show-status kubernetes-worker-cpu --format json | \<br/>    jq --raw-output '.applications."kubernetes-worker-cpu".units | keys[]' | \<br/>    xargs -I UNIT juju ssh UNIT "sudo wget <a class="ae jp" href="https://download.blender.org/durian/trailer/sintel_trailer-1080p.mp4" rel="noopener ugc nofollow" target="_blank">https://download.blender.org/durian/trailer/sintel_trailer-1080p.mp4</a> -O /mnt/sintel_trailer-1080p.mp4" <br/>done</span><span id="6f37" class="ku kv hu lw b fv nd mb l mc md">juju scp kubernetes-master/0:config ~/.kube/config<br/>helm init</span></pre><h2 id="4630" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">LXD的变化</h2><p id="3fb0" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">AWS上的LXD有点特别，因为网络。它打破了Kubernetes经常使用的一些原语，比如pod的代理，它必须经过2层而不是1层网络。</p><p id="af77" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">因此，</p><ul class=""><li id="b562" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated">kubectl代理不工作ootb</li><li id="3ad8" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">更重要的是，头盔无法工作，因为默认情况下它会消耗一个舵柄舱的代理</li></ul><p id="14c9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">然而，代码转换不需要网络访问，只需要在文件系统上做一些工作，所以这不是问题。</p><p id="88f2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我发现解决这个问题的最经济的方法是部署一个不在LXD的特定节点，而是一个“普通”的虚拟机或节点。这个节点将被标记为一个控制平面节点，我们修改tiller-deploy和kubernetes-dashboard的部署，将它们强制部署在这个节点上。使该节点足够小将确保不会在其上安排任何代码转换。</p><p id="40c8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我找不到完全自动化的方法，所以下面是要运行的一系列操作:</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="e621" class="ku kv hu lw b fv ma mb l mc md">juju deploy src/juju/k8s-lxd-&lt;nb cores per lxd&gt;c-&lt;max concurrency&gt;.yaml</span></pre><p id="93dd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这将部署整个系统，您需要等到它完成后再进行下一步。密切监视<em class="nc"> juju状态</em>直到你看到部署OK，但是法兰绒没有开始。</p><p id="f807" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">调整每个LXD节点的LXD配置文件必须允许嵌套容器。在不久的将来(2.3的路线图)，Juju将获得声明它希望用于LXD主机的配置文件的能力。但是现在，我们需要手动构建:</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="92ba" class="ku kv hu lw b fv ma mb l mc md">NB_CORES_PER_LXD=4 #This is the same number used above to deploy<br/>for MACHINE in 1 2 <br/>do<br/> ./src/bin/setup-worker.sh ${MACHINE} ${NB_CORES_PER_LXD}<br/>done</span></pre><p id="a3f3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你正在看<em class="nc"> juju状态</em>你会看到法兰绒突然开始工作。一切都好！现在下载kubectl的配置，然后用</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="9a7c" class="ku kv hu lw b fv ma mb l mc md">juju scp kubernetes-master/0:config ~/.kube/config<br/>helm init</span></pre><p id="40f2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们需要识别不是LXD容器的Worker，然后将其标记为我们的控制平面节点:</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="a070" class="ku kv hu lw b fv ma mb l mc md">kubectl label $(kubectl get nodes -o name | grep -v lxd) controlPlane=true<br/>kubectl label $(kubectl get nodes -o name | grep lxd) computePlane=true</span></pre><p id="2f84" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在我们需要依次编辑<em class="nc">RC/monitoring-influx db-grafana-v4</em>、<em class="nc"> deploy/heapster-v1.2.0.1、deploy/tiller-deploy </em>和<em class="nc">deploy/kubernetes-dashboard</em>，以添加</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="9435" class="ku kv hu lw b fv ma mb l mc md">nodeSelector:<br/> controlPlane: “true”</span></pre><p id="56f5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在清单的定义中。使用</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="3b7d" class="ku kv hu lw b fv ma mb l mc md">kubectl edit -n kube-system rc/monitoring-influxdb-grafana-v4</span></pre><p id="2f91" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">之后，集群就可以运行了！</p><h1 id="7cf8" class="ml kv hu bd kw mm ne mo la mp nf mr le ms ng mu lh mv nh mx lk my ni na ln nb dt translated">运行转码作业</h1><h2 id="4240" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">开始作业</h2><p id="f294" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">我们有许多测试要运行，并且我们不希望花费太长的时间来管理它们，所以我们围绕它们构建了一个简单的自动化</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="be9e" class="ku kv hu lw b fv ma mb l mc md">cd src <br/>TYPE=aws<br/>CPU_LIST="1 2 3"<br/>MEM_LIST="1 2 3"<br/>PARA_LIST="1 4 8 12 24 48"</span><span id="b3f3" class="ku kv hu lw b fv nd mb l mc md">for cpu in ${CPU_LIST}; do <br/>  for memory in ${CPU_LIST}; do <br/>    for para in ${PARA_LIST}; do <br/>    [ -f values/values-${para}-${TYPE}-${cpu}-${memory}.yaml ] &amp;&amp; \<br/>      { helm install transcoder --values values/values-${para}-${TYPE}-${cpu}-${memory}.yaml<br/>        sleep 60<br/>        while [ "$(kubectl get pods -l role=transcoder | wc -l)" -ne "0" ]; do<br/>          sleep 15<br/>        done<br/>      }<br/>    done<br/>  done<br/>done</span></pre><p id="99af" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这将尽可能快地运行测试。调整变量以适应您的本地环境</p><h2 id="af12" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">第一种调度方法</h2><p id="44d4" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">不需要任何调优或配置，Kubernetes就可以很好地将负载分散到主机上。本质上，所有的作业都是平等的，它像一个循环一样在所有的节点上分配它们。下面是我们观察到的并发数为12的情况。</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="971e" class="ku kv hu lw b fv ma mb l mc md">NAME READY STATUS RESTARTS AGE IP NODE<br/>bm-12–1–2gi-0–9j3sh 1/1 Running 0 9m 10.1.70.162 node06<br/>bm-12–1–2gi-1–39fh4 1/1 Running 0 9m 10.1.65.210 node07<br/>bm-12–1–2gi-11–261f0 1/1 Running 0 9m 10.1.22.165 node01<br/>bm-12–1–2gi-2–1gb08 1/1 Running 0 9m 10.1.40.159 node05<br/>bm-12–1–2gi-3-ltjx6 1/1 Running 0 9m 10.1.101.147 node04<br/>bm-12–1–2gi-5–6xcp3 1/1 Running 0 9m 10.1.22.164 node01<br/>bm-12–1–2gi-6–3sm8f 1/1 Running 0 9m 10.1.65.211 node07<br/>bm-12–1–2gi-7–4mpxl 1/1 Running 0 9m 10.1.40.158 node05<br/>bm-12–1–2gi-8–29mgd 1/1 Running 0 9m 10.1.101.146 node04<br/>bm-12–1–2gi-9-mwzhq 1/1 Running 0 9m 10.1.70.163 node06</span></pre><p id="05a0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对于较大的并发性也实现了相同的分布，在192时，我们观察到每种情况下每台主机有32个作业。我的测试的一些截图</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff nj"><img src="../Images/71b8ff26b5cd472b1a143a60ab0cf945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-uyNXA8NrFCkiaAA6JSbpg.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">KubeUI showing 192 concurrent pods</figcaption></figure><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff nk"><img src="../Images/e932dd669fa611007d8163331d044223.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DV5pPM00bLTIdbYxDLQ8MQ.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Compute Cycles at different concurrencies</figcaption></figure><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff nl"><img src="../Images/c1e067285b3be7f0f4e8852b021563ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nk68Hr9fkccd-fKAtey8CQ.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">LXD pining Kubernetes Workers to CPUs</figcaption></figure><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff nm"><img src="../Images/fe1cd6b91fbcf0136190264d0a61f91d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bqi-QK1PVxFT1gkwnTkldQ.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Aoutch! About 100% on the whole machine</figcaption></figure><h1 id="c373" class="ml kv hu bd kw mm ne mo la mp nf mr le ms ng mu lh mv nh mx lk my ni na ln nb dt translated">收集和汇总结果</h1><h2 id="4425" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">原始日志</h2><p id="8910" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">这就是事情变得有点棘手的地方。我们可以使用ELK堆栈，并在那里提取日志，但是我找不到一种方法来真正轻松地测量我们的KPI。</p><p id="ee82" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">看看Docker在日志记录方面做了什么，您需要在每台机器上查看<em class="nc">/var/lib/Docker/containers/&lt;uuid&gt;/&lt;uuid&gt;-JSON . log</em></p><p id="536e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在这里，我们可以看到每个作业正好生成82行日志，但其中只有一部分是有趣的:</p><ul class=""><li id="f828" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated"><strong class="it hv">第一行</strong>:给出日志的开始时间</li></ul><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="9cce" class="ku kv hu lw b fv ma mb l mc md">{“log”:”ffmpeg version 3.1.2 Copyright © 2000–2016 the FFmpeg developers\n”,”stream”:”stderr”,”time”:”2017–03–17T10:24:35.927368842Z”}</span></pre><ul class=""><li id="2043" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated"><strong class="it hv">第13行</strong>:来源名称</li></ul><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="e573" class="ku kv hu lw b fv ma mb l mc md">{“log”:”Input #0, mov,mp4,m4a,3gp,3g2,mj2, from ‘/data/sintel_trailer-1080p.mp4’:\n”,”stream”:”stderr”,”time”:”2017–03–17T10:24:35.932373152Z”}</span></pre><ul class=""><li id="068e" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated"><strong class="it hv">最后一行</strong>:转码时间戳结束</li></ul><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="5e7e" class="ku kv hu lw b fv ma mb l mc md">{“log”:”[aac @ 0x3a99c60] Qavg: 658.896\n”,”stream”:”stderr”,”time”:”2017–03–17T10:39:13.956095233Z”}</span></pre><p id="ec07" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对于高级性能极客，line 64还为我们提供了每帧的代码转换速度，这有助于分析视频的复杂性。目前，我们并不真的需要它。</p><h2 id="9667" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">映射到职务</h2><p id="09a1" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">原始日志只是一个Docker uuid，对理解它与什么作业相关没有太大帮助。Kubernetes在<em class="nc"> /var/log/containers/ </em>中优雅地创建链接，将pod名称映射到docker uuid。</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="26c8" class="ku kv hu lw b fv ma mb l mc md">bm-1–0.8–1gi-0-t8fs5_default_transcoder-0-a39fb10555134677defc6898addefe3e4b6b720e432b7d4de24ff8d1089aac3a.log</span></pre><p id="430d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所以我们是这样做的:</p><ol class=""><li id="4c6a" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo lu km kn ko dt translated">收集每台主机上的日志列表:</li></ol><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="a9ff" class="ku kv hu lw b fv ma mb l mc md">for i in $(seq 0 1 ${MAX_NODE_ID}); do <br/>  [ -d stats/node0${i} ] || mkdir -p node0${i}<br/>  juju ssh kubernetes-worker-cpu/${i} "ls /var/log/containers | grep -v POD | grep -v 'kube-system'" &gt; stats/node0${i}/links.txt<br/>  juju ssh kubernetes-worker-cpu/${i} "sudo tar cfz logs.tgz /var/lib/docker/containers"<br/>  juju scp kubernetes-worker-cpu/${i}:logs.tgz stats/node0${i}/<br/>  cd node0${i}/<br/>  tar xfz logs.tgz --strip-components=5 -C ./<br/>  rm -rf config.v2.json host* resolv.conf* logs.tgz var shm<br/>  cd ..<br/>done</span></pre><p id="10af" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">2.提取导入日志行(适应每个环境的nb节点……)</p><pre class="jr js jt ju fq lv lw lx ly aw lz dt"><span id="5d14" class="ku kv hu lw b fv ma mb l mc md">ENVIRONMENT=lxd<br/>MAX_NODE_ID=1<br/>echo "Host,Type,Concurrency,CPU,Memory,JobID,PodID,JobPodID,DockerID,TimeIn,TimeOut,Source" | tee ../db-${ENVIRONMENT}.csv<br/>for node in $(seq 0 1 ${MAX_NODE_ID})<br/>do<br/>  cd node0${node}<br/>  while read line; do<br/>    echo "processing ${line}"</span><span id="a963" class="ku kv hu lw b fv nd mb l mc md">NODE="node0${node}"<br/>    CSV_LINE="$(echo ${line} | head -c-5 | tr '-' ',')" # node it's -c-6 for logs from bare metal or aws, -c-5 for lxd<br/>    UUID="$(echo ${CSV_LINE} | cut -f8 -d',')"<br/>    JSON="$(sed -ne '1p' -ne '13p' -ne '82p' ${UUID}-json.log)"<br/>    TIME_IN="$(echo $JSON | jq --raw-output '.time' | head -n1 | xargs -I {} date --date='{}' +%s)"<br/>    TIME_OUT="$(echo $JSON | jq --raw-output '.time' | tail -n1 | xargs -I {} date --date='{}' +%s)"<br/>    SOURCE=$(echo $JSON | grep from | cut -f2 -d"'")</span><span id="1fec" class="ku kv hu lw b fv nd mb l mc md">echo "${NODE},${CSV_LINE},${TIME_IN},${TIME_OUT},${SOURCE}" | tee -a ../../db-${ENVIRONMENT}.csv</span><span id="243a" class="ku kv hu lw b fv nd mb l mc md">done &lt; links.txt<br/>  cd ..<br/>done</span></pre><p id="711d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一旦我们有了所有的结果，我们加载到<a class="ae jp" href="https://docs.google.com/spreadsheets/d/1KcC5nKnbTKaFcsg8_K_p_zodq3r-haRur1-_uJqJ4iI/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌电子表格</a>并查看结果…</p></div><div class="ab cl me mf hc mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="hn ho hp hq hr"><h1 id="f60c" class="ml kv hu bd kw mm mn mo la mp mq mr le ms mt mu lh mv mw mx lk my mz na ln nb dt translated">结果分析</h1><h2 id="0596" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">记忆的影响</h2><p id="720b" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">一旦分配超过ffmpeg对视频进行转码所需的量，内存在第一近似值上就是一个无影响的变量。但是，在第二个级别，我们可以看到在分配的1gb和4GB之间，性能略有提高，幅度在0.5%到1%之间。</p><p id="b694" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">然而，这一因素没有被考虑在内。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff nn"><img src="../Images/81073da0fdc5f9b96156a3edb03783fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*VPyXDg1HVN-uAGT8whmtqw.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">RAM does not impact performance (or only marginally)</figcaption></figure><h2 id="a97b" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">CPU分配和固定的影响</h2><p id="6b7d" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">无论采用何种部署方法(AWS或裸机),当分配少于或多于1个“等效”CPU时，行为都会发生变化。</p><ol class=""><li id="5433" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo lu km kn ko dt translated">在线上或线下</li></ol><p id="c35a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在1以下运行CPU分配可以提供最好的一致性。该图显示，变化是包含在内的，我们看到的是性能的平均变化不到4%。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff no"><img src="../Images/6663784396e2d4e088e7b6184b112926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*2bEbRTl1iGdRscpicEQAeQ.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Running jobs with CPU request &lt;1 is optimal for concurrency</figcaption></figure><p id="4577" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有趣的是，热图显示，当(并发* CPU计数)~ 1时，性能最差。我不知道如何解释那种行为。想法？</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff np"><img src="../Images/046b784d3a4c7ce19d9a7f690ef56628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wb6x9jHrKWm3Xh5owRZTog.png"/></div></div></figure><p id="087d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">2.在线上</p><p id="069d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一旦分配的内存超过一个CPU，并发性就会直接影响性能。不管分配如何，都会有影响，并发性3.5会导致大约10%到15%的损失。使用更多的工作线程和更少的内核将会增加影响，在高并发情况下可达40~50%</p><p id="aac9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如图所示，并非所有的并发性都是相同的。下图显示了各种设置的并发持续时间函数。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff nq"><img src="../Images/0ceddd75e7e16daf4fae7cd115b0d31f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*URzovlorEN1-OiUESYUgHQ.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">AWS with or without LXD, 2 cores / job</figcaption></figure><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff nr"><img src="../Images/3d3f88d01af1d08955929d192414fd5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nFBKue3vqODJEaGE3ezzvA.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">and 5 cores / job</figcaption></figure><p id="5c73" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当并发性较低且性能状况良好时，借助LXD CPU锁定对主机进行切片始终是一种有效的策略。</p><p id="feb0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">默认情况下，在这种情况下，LXD CPU-pinning将系统地优于Docker和Kubernetes的本地调度。</p><p id="4976" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">似乎每台主机2.5的并发性是Kubernetes分配比通过LXD强制传播更有效的地方。</p><p id="7b37" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">然而，解除作业的CPU限制将允许Kubernetes在任何时间点使用它所能使用的任何东西，从而带来整体更好的性能。</p><p id="6f65" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当使用最后一种策略时，无论作业需要多少个内核，性能都是一样的。下图总结了所有结果:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff ns"><img src="../Images/b2bf59d9304ca0a2bbb0ba5833d00f5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IWILSQHXWnF2cT74VYS3Ow.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">All results: unbounding CPU cores homogenizes performance</figcaption></figure><h2 id="4ed6" class="ku kv hu bd kw kx ky kz la lb lc ld le jc lf lg lh jg li lj lk jk ll lm ln lo dt translated">并发性对个人绩效的影响</h2><p id="415e" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">并发会影响性能。下表显示了各种设置下由于并发性造成的性能损失百分比。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff nt"><img src="../Images/32d0e825bd121535049973aaeb759e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qxSdPeq6gcVpaYFx75eHhA.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">performance is impacted from 10 to 20% when concurrency is 3 or more</figcaption></figure><h1 id="d898" class="ml kv hu bd kw mm ne mo la mp nf mr le ms ng mu lh mv nh mx lk my ni na ln nb dt translated">结论</h1><p id="92cd" class="pw-post-body-paragraph ir is hu it b iu lp iw ix iy lq ja jb jc lr je jf jg ls ji jj jk lt jm jn jo hn dt translated">在代码转换或其他CPU密集型任务的情况下，</p><ul class=""><li id="5500" class="kg kh hu it b iu iv iy iz jc ki jg kj jk kk jo kl km kn ko dt translated">如果分配给pods的CPU总是少于1个，那么并发性不会影响CPU限制的性能；尽管如此，还是要注意其他方面。我们的用例不依赖于内存或磁盘IO，而您的可以。</li><li id="8c95" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">如果您事先知道您的最大并发性，并且它不是太高，那么通过LXD和CPU锁定来添加更多的工作线程总会比通过Docker进行本地调度获得更好的性能。这还有其他有趣的特性，比如在不停机的情况下动态调整工作线程的大小，以及非常快速地提供新的工作线程。本质上，对于相同数量的物理节点，您可以获得高度灵活的集群。相当棒。</li><li id="227e" class="kg kh hu it b iu kp iy kq jc kr jg ks jk kt jo kl km kn ko dt translated">获胜的策略总是最大限度地超级配置CPU限制，以便将每一点性能都立即分配到您的pod。当然，这不能在所有环境下都工作，所以在使用时要小心，在应用到生产中之前，要测试它是否适合您的用例。</li></ul><p id="d129" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这些结果出现在AWS中，在金属和单元之间有一个管理程序。我正在等待具有足够内核的硬件来完成任务。如果你有硬件可以用，请便，我会帮你做测试。</p><p id="5df6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最后，为了展开讨论，下一步也可以使用GPU来执行相同的任务。限制是集群中可用的GPU数量。我正在等待一些新的nVidia GPUs和戴尔硬件，希望我能测试一下。</p><p id="381f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有些未知的东西我无法理清。我在这里打开了<a class="ae jp" href="https://docs.google.com/spreadsheets/d/1KcC5nKnbTKaFcsg8_K_p_zodq3r-haRur1-_uJqJ4iI/edit#gid=714649755" rel="noopener ugc nofollow" target="_blank">大约1900份工作的结果数据集，所以你可以运行你自己的分析！如果你发现什么有趣的东西，请告诉我！</a></p><div class="jr js jt ju fq ab cb"><figure class="nu jv nv nw nx ny nz paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="nu jv nv nw nx ny nz paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="nu jv nv nw nx ny nz paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="oa ob oc"><p id="f922" class="ir is nc it b iu iv iw ix iy iz ja jb od jd je jf oe jh ji jj of jl jm jn jo hn dt translated"><a class="ae jp" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae jp" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae jp" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae jp" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="ir is nc it b iu iv iw ix iy iz ja jb od jd je jf oe jh ji jj of jl jm jn jo hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae jp" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae jp" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff og"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></div></figure><figure class="jr js jt ju fq jv"><div class="bz el l di"><div class="oh oi l"/></div></figure></div></div>    
</body>
</html>