<html>
<head>
<title>Traffic Sign Recognition using Convolutional Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于卷积神经网络的交通标志识别</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/traffic-sign-recognition-using-convolutional-neural-network-8a1f90e8fb24?source=collection_archive---------17-----------------------#2017-10-15">https://medium.com/hackernoon/traffic-sign-recognition-using-convolutional-neural-network-8a1f90e8fb24?source=collection_archive---------17-----------------------#2017-10-15</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/9c7eb1c131a30c9389b807e1b342373a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iBJ_SZKT7k-SQNen.jpg"/></div></div></figure><p id="4634" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我将描述在<a class="ae ka" href="https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd013" rel="noopener ugc nofollow" target="_blank"> Udacity课程</a>“自动驾驶汽车工程师”中提出的<strong class="je hv">交通标志识别</strong>问题的完整流程。交通标志识别是自动驾驶汽车一项基本的日常任务。这就是为什么它必须包含在关于自动驾驶汽车的<a class="ae ka" href="http://tomaszkacmajor.pl/index.php/2017/05/07/self-driving-cars-in-python/" rel="noopener ugc nofollow" target="_blank">系列</a>中，在那里我展示了与该领域相关的不同项目。识别系统处理从道路场景中提取的交通标志图像。最终，它应该将该标志归入43个类别中的一个。为了做到这一点，应用了一个<strong class="je hv">卷积神经网络</strong>，预先用50，000幅图像对其进行训练。</p><h1 id="8756" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">项目的目标</h1><p id="90dc" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">交通标志识别项目的目标是建立一个<strong class="je hv">深度神经网络</strong> (DNN)，用于对交通标志进行分类。我们应该训练模型，以便它可以使用德国交通标志数据集<a class="ae ka" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank">从自然图像中解码交通标志。为了最大化模型性能，应该首先预处理这些数据。在选择模型架构、微调和训练之后，该模型将在网上找到的新交通标志图像上进行测试。因为我们处理图像分类，所以选择卷积神经网络作为一种DNN，这是这类问题的常见选择。代码用<strong class="je hv"> Python </strong>编写，使用<strong class="je hv"> TensorFlow </strong>库。这对于在我们的模型架构中进行快速、高层次的改变是非常好的。此外，TensorFlow支持GPU上的计算，可以真正加快所需的计算。最后，为了进行所有计算，我启动了Amazon Web Services EC2 GPU实例，以获得比我的笔记本电脑更大的优势。</a></p><h1 id="178b" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">项目管道</h1><p id="ff44" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">我的管道由7个步骤组成，这在分类问题中很常见:</p><ol class=""><li id="f797" class="le lf hu je b jf jg jj jk jn lg jr lh jv li jz lj lk ll lm dt translated">加载数据</li><li id="0358" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz lj lk ll lm dt translated">数据集探索和可视化</li><li id="9f53" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz lj lk ll lm dt translated">数据预处理</li><li id="482e" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz lj lk ll lm dt translated">数据扩充</li><li id="82e5" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz lj lk ll lm dt translated">设计、训练和测试CNN模型</li><li id="443f" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz lj lk ll lm dt translated">在新图像上使用模型</li><li id="a12b" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz lj lk ll lm dt translated">分析软最大概率</li></ol><blockquote class="ls lt lu"><p id="c35d" class="jc jd lv je b jf jg jh ji jj jk jl jm lw jo jp jq lx js jt ju ly jw jx jy jz hn dt translated"><em class="hu">你可以在</em> <a class="ae ka" href="https://github.com/tomaszkacmajor/CarND-Traffic-Sign-Classifier-P2/blob/master/Traffic_Sign_Classifier.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="hu"> github </em> </a> <em class="hu">上找到该项目的完整代码。使用</em><strong class="je hv"><em class="hu">Jupyter Notebook</em></strong><em class="hu">以一种方便的方式呈现，其中在每个代码块之后显示即时结果。</em></p></blockquote><h1 id="2da3" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">资料组</h1><p id="7e39" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">数据集分为训练集(34.799个样本)、验证集(4.410个样本)和测试集(12.630个样本)。每个样本代表一个标记为43个类别之一的交通标志。例如，它可以是停车标志、让行、30公里/小时限速等。交通标志图像的形状以3通道RGB表示法(32x32x3)缩放为32x32像素。下面是数据集中的一些随机样本:</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lz"><img src="../Images/708513e6b3b8b8742319abba82b8372f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H8YQvhJtmYiqxFoe.png"/></div></div></figure><p id="b3ff" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们应该首先探索数据集，针对要解决的问题理解它。让我们看看每个交通标志类别有多少个样本。我们不希望这个模型偏向任何一个班级。下面是每个标签在训练集中出现的样本的直方图。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff me"><img src="../Images/9d67ff9f0edcd0b47b16fadf57f8063d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*X-DsQGNCFLy_6ON0.png"/></div></div></figure><p id="75dd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在，我们可以看到，一些标签在数据集中的代表性非常低，而其他标签则有相当多的代表性。我们是否应该忽略后两者来均衡直方图？让我们首先画出属于同一类的图像的子集。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lz"><img src="../Images/dfe113115a39eef6195c193117d2b86c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pJ022OVEpNln6XJ1.png"/></div></div></figure><p id="956f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们可以观察到，来自同一类的图像可以在数据集中以非常不同的方式表示。一般可以有不同的<strong class="je hv">光照条件</strong>，图像可以<strong class="je hv">模糊</strong>、<strong class="je hv">旋转</strong>或<strong class="je hv">缩放</strong>。事实上，这些是从真实世界图像中提取的样本。我们的模型必须处理所有这些情况。因此，为了获得数据平衡，最好不要截断我们的数据集。让我们“生产”一些新的样本，主要是代表不足的迹象。</p><h1 id="3d25" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">数据预处理</h1><p id="263a" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">为了生成所谓的<strong class="je hv">增强数据</strong>，我随机选择了要复制的图像。为了给模型提供额外的信息，我随机旋转了这个副本并改变了它的亮度。所有这些操作都使用了OpenCV库。我执行这些操作，直到每个标签有3200个样本。这将训练集增加到139.148个样本。作为一个例子，这里有一个带有生成图像(旋转和不同亮度)的样本交通标志的绘图。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div class="fe ff mf"><img src="../Images/69026c3d64510f2da5bcf02e44a7ac90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/0*aYsJYWMpJfxJ10Cg.jpg"/></div></figure><p id="62b0" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">接下来，我决定将图像从RGB转换成灰度。因此，我们要处理的数据减少了三分之一，这极大地影响了训练时间。此外，在处理交通标志识别的<a class="ae ka" href="http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中，作者发现拒绝颜色信息甚至可以提高最终结果。为了进行实验，在我的模型架构的早期阶段，我使用RGB、YUV颜色空间和灰度图像对模型进行了20个时期的训练。同样，最新的变化最终得到了最好的结果。最后，我还归一化了图像数据，使每个像素位于-1和1之间。它防止了当数据远离零值时可能发生的数值不稳定性。</p><p id="fed1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">以下是灰度化和规范化前后的交通标志图像示例。还描绘了两幅图像的直方图。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/64dc7061a5e78a5cc0f9b181e12de534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/0*gUe_Mt19zmMhCfax.png"/></div></figure><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mh"><img src="../Images/46db4fb6be2699b0b45edca42c7b30c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/0*XDKXTQNw3p9Bu_ZR.png"/></div></div></figure><h1 id="becb" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">设计深度神经网络模型</h1><p id="2596" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">现在，终于到了将数据输入神经网络的时候了。选择<a class="ae ka" href="https://hackernoon.com/tagged/network" rel="noopener ugc nofollow" target="_blank">网络</a>架构，一次又一次地调整不同的参数可能是最苛刻的任务。模型优化没有明确的规则。除了一些已被证实的经验法则之外，我们的经验也起着很大的作用。此外，当处理深度神经网络时，你必须等待每个测试模型的结果相对较长的时间。当然，这取决于可用的处理能力。对于这个项目，我使用了内置Nvidia GPU的<a class="ae ka" href="https://www.cloudar.be/awsblog/how-to-use-aws-ec2-gpu-instances/" rel="noopener ugc nofollow" target="_blank"> AWS EC2实例</a>，与运行i7 CPU内核的笔记本电脑相比，速度提高了约6倍。</p><p id="4c23" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">为了简要概述模型的复杂性，我将列出最重要的模型参数。由于这是对交通标志识别项目的概述，我不打算详细解释它们。这些参数有时被称为“超参数”，它们是:<a class="ae ka" rel="noopener" href="/towards-data-science/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9">批量大小、时期数</a>、<a class="ae ka" href="https://datascience.stackexchange.com/questions/410/choosing-a-learning-rate" rel="noopener ugc nofollow" target="_blank">学习率</a>、<a class="ae ka" href="https://chatbotslife.com/regularization-in-deep-learning-f649a45d6e0" rel="noopener ugc nofollow" target="_blank">损失规则化</a>、<a class="ae ka" rel="noopener" href="/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5">退出率</a>或池类型。他们经常被研究人员讨论和衡量。但是，类型和模型结构本身的选择也同样重要。卷积神经网络，这里很好地介绍了<a class="ae ka" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets" rel="noopener ugc nofollow" target="_blank"/>，非常适合我们的任务。但CNN有许多成熟的子类型，如<a class="ae ka" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" rel="noopener ugc nofollow" target="_blank">LeNet</a>(20世纪90年代)、<a class="ae ka" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank"> AlexNet </a> (2012年)、<a class="ae ka" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank"> GoogLeNet </a> (2014年)或<a class="ae ka" href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" rel="noopener ugc nofollow" target="_blank"> VGGNet </a> (2014年)。它们因神经元层数(模型深度)、神经元之间的连接、运算次数或每次迭代更新的参数而异。最流行的架构的比较可以在<a class="ae ka" rel="noopener" href="/towards-data-science/neural-network-architectures-156e5bad51ba">这里</a>找到。</p><h2 id="674b" class="mi kc hu bd kd mj mk ml kh mm mn mo kl jn mp mq kp jr mr ms kt jv mt mu kx mv dt translated">卷积神经网络</h2><p id="13ee" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">让我们简单讨论一下卷积神经网络的概念。他们在图像识别方面非常成功。CNN区别于传统神经网络的关键部分是<strong class="je hv">卷积</strong>运算。在输入端有一个图像，CNN对其进行多次扫描，寻找某些<strong class="je hv">特征</strong>。这种扫描(卷积)可以用两个主要参数设置:步幅和填充类型。正如我们在下图中看到的，第一次卷积的过程给了我们一组新的帧，显示在第二列(层)。每一帧包含关于一个特征及其在扫描图像中的存在的信息。在某个特征非常明显的地方，生成的帧将具有较大的值，而在没有或很少有此类特征的地方，生成的帧将具有较低的值。此后，对每个获得的帧重复该过程选定的次数。在这个项目中，我选择了一个经典的<a class="ae ka" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" rel="noopener ugc nofollow" target="_blank"> LeNet </a>模型，它只包含两个卷积层。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mw"><img src="../Images/3d9180a917f19ec26da609d1351661ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eVft9WEk_9LofP74.png"/></div></div><figcaption class="mx my fg fe ff mz na bd b be z ek">from <a class="ae ka" href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/" rel="noopener ugc nofollow" target="_blank">https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/</a></figcaption></figure><p id="45ef" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们正在卷积的后一层，正在搜索更高级的特征。它的工作原理类似于人的感知。举一个例子，下面是一个很有描述性的图片，上面有在不同CNN层搜索到的特征。可以看到，这个模型的应用是人脸识别。您可能会问，模型如何知道要寻找哪些特性。如果你从头开始构建CNN，搜索到的特征是随机的。然后，在训练过程中，神经元之间的权重被调整，慢慢地，CNN开始找到能够满足预定目标的特征，即，从训练集中成功地识别图像。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nb"><img src="../Images/8c127aa2dc097aec341031eebbe13c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*20-cv2j2DBjSgWKM.jpg"/></div></div><figcaption class="mx my fg fe ff mz na bd b be z ek">from <a class="ae ka" href="https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/" rel="noopener ugc nofollow" target="_blank">from: https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/</a></figcaption></figure><p id="c029" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在所描述的层之间还有<strong class="je hv">汇集</strong>(子采样)操作，其减少了最终帧的尺寸。此外，在每次卷积后，我们将一个非线性函数(称为<strong class="je hv"> ReLU </strong>)应用于结果帧，以将非线性引入模型。</p><p id="7306" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最终，在网络的末端还有<strong class="je hv">全连接层</strong>。卷积运算得到的最后一组帧被展平，得到神经元的一维向量。从这一点上，我们把一个标准的，完全连接的神经网络。在最末端，对于分类问题，有一个<strong class="je hv"> softmax </strong>层。它将模型的结果转换为每个类别的正确猜测概率，这里是交通标志指数。</p><p id="ff27" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">下面是我选择的模型的总结，并对每一层的标注尺寸进行了微调。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div class="fe ff nc"><img src="../Images/18bd0309283f97efc5654b6e12b768b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/0*AoSTQ4Mr0YJHrxGC.jpg"/></div></figure><h2 id="26e0" class="mi kc hu bd kd mj mk ml kh mm mn mo kl jn mp mq kp jr mr ms kt jv mt mu kx mv dt translated">调整模型</h2><p id="bc92" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">我遵循一个简单的迭代过程来寻找最佳的模型架构。在更改其中一个模型参数后，我只运行了20个时期的训练，并观察到试图将其设置为最低水平的验证错误。在调整模型时，主要考虑验证误差是非常重要的。仅最小化基于训练数据的误差很容易导致不想要的模型<a class="ae ka" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过拟合</a>。</p><p id="1bd8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">下面是我采取的中间步骤的细节，以及在20个时期的训练后相应的验证准确性。有时，两种给定方法之间的差异似乎很大，很难在它们之间做出选择。但是注意，对于每个训练过程，存在影响最终误差的随机权重初始化。尤其是当历元数量很小时。这就是为什么在最终的模型调整过程中，我使用了20多个历元——大约100个。</p><ul class=""><li id="d093" class="le lf hu je b jf jg jj jk jn lg jr lh jv li jz nd lk ll lm dt translated">初始LeNet模型，选择输入图像颜色表示— 91 %</li><li id="25f9" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz nd lk ll lm dt translated">输入图像标准化— ~91 %</li><li id="758a" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz nd lk ll lm dt translated">训练集扩充— 93 %</li><li id="a960" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz nd lk ll lm dt translated">学习速率优化，从这个阶段开始，我测试了100个时期— 95 %</li><li id="22fa" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz nd lk ll lm dt translated">在训练集扩充过程中寻找最佳图像变换— 96 %</li><li id="ddb7" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz nd lk ll lm dt translated">尝试不同的池方法，尝试辍学，选择L2损失，再次调整学习率-96.8</li></ul><p id="3fc9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我的<strong class="je hv">最终模型结果</strong>如下:</p><ul class=""><li id="9230" class="le lf hu je b jf jg jj jk jn lg jr lh jv li jz nd lk ll lm dt translated"><strong class="je hv">的训练集准确率为99.5 % </strong></li><li id="e198" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz nd lk ll lm dt translated"><strong class="je hv">的验证设定准确率为96.8 % </strong></li><li id="fd87" class="le lf hu je b jf ln jj lo jn lp jr lq jv lr jz nd lk ll lm dt translated"><strong class="je hv">的测试设定准确率为94.6 % </strong></li></ul><p id="d83f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我对这些结果相当满意。早先引用的<a class="ae ka" href="http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>的作者(Sermanet和LeCun)达到了等于99.17%的准确度水平。它被认为是高于人类的表现是98.81%！</p><h1 id="14da" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">在新图像上测试模型</h1><p id="7382" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">最后，我们想在完全看不见的标志图像上测试我们的交通标志识别系统。当然，在测试集上获得的精度也是模型性能的一个很好的指示。但是，让我们找到一些新的图像，这些图像不是来自我们的德国交通标志数据集。在图像下，有模型预测、预测是否正确的指示和模型确定性。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ne"><img src="../Images/52eefd4d46370a3a6b905596dd92fcaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K2T4_AwNt2GzC6kQ.jpg"/></div></div></figure><p id="7f8e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们可以看到效果确实不错。我还从格但斯克的波兰道路上收集了图像，并提取了一些交通标志来测试我的模型。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nf"><img src="../Images/e06bb91eee6c344498de157f9e51c0d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*j5L6IBSjguVrbP6j.jpg"/></div></div></figure><p id="f944" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">虽然我选择了与德国标志相同的标志，但结果要糟糕得多。一个例外是黄色而不是白色的让行标志。因此，这是一个积极的惊喜，模型预测正确。不幸的是，有两个标志根本没有被识别出来。到目前为止，我没有做更多的研究为什么会发生这种情况。</p><h1 id="e3b3" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">结论</h1><p id="81ad" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">我成功地实现了一个卷积神经网络的交通标志识别任务。这是使用Python的开源Tensorflow库完成的。我选择了一个流行简单的LeNet CNN架构。我看到了最大的改进空间。许多现代深度学习系统使用更新更复杂的架构，如GoogLeNet或ResNet。另一方面，这会带来更多的计算成本。<a class="ae ka" href="https://www.analyticsvidhya.com/blog/2017/08/10-advanced-deep-learning-architectures-data-scientists/" rel="noopener ugc nofollow" target="_blank">在这里</a>你可以找到最流行的架构的简要对比。这个项目最困难的部分是微调CNN的模型参数。有时这很麻烦，因为我不确定我应该朝哪个方向走。但这是机器学习的艺术。我研究了类似的项目，并试图在我的模型中引入一些想法。有趣的部分也是数据增加与图像旋转和改变亮度，这也是许多人做这个项目的建议。</p><p id="aa7a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">更多细节和完整代码可以在<a class="ae ka" href="https://github.com/tomaszkacmajor/CarND-Traffic-Sign-Classifier-P2" rel="noopener ugc nofollow" target="_blank"> github </a>上找到。</p></div><div class="ab cl ng nh hc ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="hn ho hp hq hr"><p id="a1d9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="lv">最初发表于</em><a class="ae ka" href="http://tomaszkacmajor.pl/index.php/2017/10/15/traffic-sign-recognition-using-cnn/" rel="noopener ugc nofollow" target="_blank"><em class="lv">ProggBlogg</em></a><em class="lv">。</em></p><figure class="ma mb mc md fq iv"><div class="bz el l di"><div class="nn no l"/></div></figure></div></div>    
</body>
</html>