<html>
<head>
<title>Parallel Scan &amp; Scroll an Elasticsearch Index</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">平行扫描和滚动弹性搜索索引</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/parallel-scan-scroll-an-elasticsearch-index-db02583d10d1?source=collection_archive---------8-----------------------#2017-07-10">https://medium.com/hackernoon/parallel-scan-scroll-an-elasticsearch-index-db02583d10d1?source=collection_archive---------8-----------------------#2017-07-10</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/></div><div class="ab cl ir is hc it" role="separator"><span class="iu bw bk iv iw ix"/><span class="iu bw bk iv iw ix"/><span class="iu bw bk iv iw"/></div><div class="hn ho hp hq hr"><blockquote class="iy iz ja"><p id="40fc" class="jb jc jd je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">编辑:<a class="ae ka" href="https://www.reddit.com/user/warkolm" rel="noopener ugc nofollow" target="_blank"> /u/warkolm </a>告诉我【elasticsearch为我的问题提供了一个名为<a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/reference/5.5/search-request-scroll.html#sliced-scroll" rel="noopener ugc nofollow" target="_blank">切片卷轴</a>的原生解决方案。这个特性是在Elasticsearch 5.0中引入的。如果你有es &lt; 5.0，你仍然可以使用我在这里提出的路由解决方案；我希望其他信息对您也有帮助。</p></blockquote></div><div class="ab cl ir is hc it" role="separator"><span class="iu bw bk iv iw ix"/><span class="iu bw bk iv iw ix"/><span class="iu bw bk iv iw"/></div><div class="hn ho hp hq hr"><p id="ccac" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">Elasticsearch提供了一个本地api来扫描和滚动索引。这意味着你得到一个“光标”,你可以在上面滚动。您可以使用<a class="ae ka" href="http://elasticsearch-py.readthedocs.io/en/master/helpers.html#elasticsearch.helpers.scan" rel="noopener ugc nofollow" target="_blank"> scan </a> helper方法来更轻松地使用scroll api:</p><figure class="ke kf kg kh fq ki"><div class="bz el l di"><div class="kj kk l"/></div></figure><p id="14df" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">这个动作的缺点是它限制你只能滚动一次。要获得下一批文档，您需要下一个scroll_id，它将在下一个scroll命令中获得。</p><p id="3837" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">扫描大型索引(数百万++文档)可能需要一段时间。如何在合理的时间内滚动包含数百万(或更多)文档的大型索引？解决方案是并行扫描。</p><h2 id="063d" class="kl km hu bd kn ko kp kq kr ks kt ku kv kb kw kx ky kc kz la lb kd lc ld le lf dt translated">弹性研究中的并行性</h2><p id="6500" class="pw-post-body-paragraph jb jc hu je b jf lg jh ji jj lh jl jm kb li jp jq kc lj jt ju kd lk jx jy jz hn dt translated">在Elasticsearch中，每个索引被分割成更小的元素，称为<a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/reference/5.0/glossary.html#glossary-shard" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">碎片</strong> </a>。这些碎片分布在多个节点上。您可以定义主碎片的数量和副本的数量，以确保主碎片出现故障时的数据完整性，并提高性能—副本碎片可以处理搜索请求。</p><p id="6a23" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated"><a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/hadoop/current/arch.html" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">elastic search——Hadoop</strong></a>使用分片进行并行。要使用Elasticsearch-hadoop，您需要Spark或hadoop集群，这可能会有很高的使用开销，尤其是如果您的任务非常简单。我们将尝试自己实现一种并行扫描的方法。</p><p id="4a76" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">elasticsearch索引中的默认碎片数是5；这意味着elasticsearch-hadoop可以将扫描并行到多达5个并行任务。<a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html" rel="noopener ugc nofollow" target="_blank">确定</a>创建索引时的碎片数量，以提高大型索引的并行性。</p><h2 id="8237" class="kl km hu bd kn ko kp kq kr ks kt ku kv kb kw kx ky kc kz la lb kd lc ld le lf dt translated">碎片Api</h2><p id="0c03" class="pw-post-body-paragraph jb jc hu je b jf lg jh ji jj lh jl jm kb li jp jq kc lj jt ju kd lk jx jy jz hn dt translated">如何自己实现并行扫描？我们不想扫描整个索引，而是想单独滚动每个片段。</p><blockquote class="iy iz ja"><p id="f9fe" class="jb jc jd je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">search shards api返回搜索请求将被执行的碎片(<a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-shards.html" rel="noopener ugc nofollow" target="_blank"> link </a>)</p></blockquote><p id="f5dc" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">要获取碎片和节点信息，请使用:</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="ffee" class="kl km hu lm b fv lq lr l ls lt">$ curl -XGET <a class="ae ka" href="https://esprod.senexx.com/linkedin-profiles-2017-01-23/_search_shards" rel="noopener ugc nofollow" target="_blank">http://elasticsearch:9200/index/_search_shards</a></span></pre><p id="289c" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated"><strong class="je hv"> routing </strong>参数决定请求将针对哪个碎片执行。</p><p id="a84f" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">当我们用routing参数查询search shards api时，结果将是请求将被执行的碎片。</p><p id="6cfc" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">例如，对路由为<code class="eh lu lv lw lm b">hello</code>的索引为<code class="eh lu lv lw lm b">my-index</code>的搜索请求将针对碎片号1执行:</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="1743" class="kl km hu lm b fv lq lr l ls lt">$ <strong class="lm hv">curl </strong><a class="ae ka" href="https://esprod.senexx.com/linkedin-profiles-2017-01-23/_search_shards?routing=hello" rel="noopener ugc nofollow" target="_blank"><strong class="lm hv">http://elasticsearch:9200/my-index/_search_shards?routing=hello</strong></a></span><span id="c7b7" class="kl km hu lm b fv lx lr l ls lt">{<br/>  "nodes": {<br/>    ...<br/>  },<br/>  "shards": [<br/>    [<br/>      {<br/>        "state": "STARTED",<br/>        "primary": true,<br/>        "node": "nu81I57KRCWw8zq27fKd1A",<br/>        "shard": 1,<br/>        "index": "index",<br/>      }<br/>    ]<br/>  ]<br/>}</span></pre><p id="abac" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">要找到路由到shard的完整映射，我们可以使用以下脚本:</p><figure class="ke kf kg kh fq ki"><div class="bz el l di"><div class="kj kk l"/></div></figure><p id="c342" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">结果将是这样的:</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="e9e5" class="kl km hu lm b fv lq lr l ls lt">{0: 491, 83: 493, 27: 465, 74: 403, 111: 508, 57: 404, 78: 495, 106: 463... }</span></pre><p id="9581" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">这意味着如果你使用路由<strong class="je hv"> 491 </strong>的话，预期的分片将是零号分片。</p><p id="4e5c" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">每个碎片保存着大约<code class="eh lu lv lw lm b">total documents / number of shards</code>的文件。我们可以通过发送路由491的搜索请求来验证这一点。在我的例子中，shard zero获得了大约300万次点击，整个索引中总共有3.56亿个文档，也就是大约120个碎片(实际的碎片数)。</p><h2 id="fa3e" class="kl km hu bd kn ko kp kq kr ks kt ku kv kb kw kx ky kc kz la lb kd lc ld le lf dt translated">实施并行扫描</h2><p id="b9bf" class="pw-post-body-paragraph jb jc hu je b jf lg jh ji jj lh jl jm kb li jp jq kc lj jt ju kd lk jx jy jz hn dt translated">我们现在有了分片到路由的映射。下一步是扫描和滚动每个碎片:</p><figure class="ke kf kg kh fq ki"><div class="bz el l di"><div class="kj kk l"/></div></figure><p id="4c38" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">我们设法将扫描/滚动分割为每个分片，但上述方法仍然是同步的；每个碎片扫描必须在另一个碎片扫描开始之前完成。让我们使用<a class="ae ka" href="https://docs.python.org/2/library/multiprocessing.html#using-a-pool-of-workers" rel="noopener ugc nofollow" target="_blank">多重处理。Pool </a>为本地机器上的每个CPU运行一个worker(碎片扫描):</p><figure class="ke kf kg kh fq ki"><div class="bz el l di"><div class="kj kk l"/></div></figure><p id="7859" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">我使用这个池在一台4 CPUs的机器上计算5个碎片索引中每个碎片上的文档数量(并添加了日志)。该池将工作线程的数量限制为CPU的数量，即4个并行任务。</p><p id="e8ad" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">您可以看到，只有在第一个工人完成(*)之后，最后一个工人才开始(**)。</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="7145" class="kl km hu lm b fv lq lr l ls lt">[16:42:26.485186] Starting: ForkPoolWorker-1 Pid: 11447<br/>[16:42:26.485286] Starting: ForkPoolWorker-2 Pid: 11448<br/>[16:42:26.485437] Starting: ForkPoolWorker-3 Pid: 11449<br/>[16:42:26.485457] Starting: ForkPoolWorker-4 Pid: 11450</span><span id="6845" class="kl km hu lm b fv lx lr l ls lt">[16:42:28.235941] Name: ForkPoolWorker-4 Pid: 11450 Result: 3==149<br/>[16:42:28.264004] Name: ForkPoolWorker-3 Pid: 11449 Result: 2==152<br/>[16:42:28.581638] Name: ForkPoolWorker-1 Pid: 11447 Result: 0==170<br/>[16:42:29.845960] Name: ForkPoolWorker-2 Pid: 11448 Result: 1==133</span><span id="aabb" class="kl km hu lm b fv lx lr l ls lt">*  [16:42:33.240230] Exiting: ForkPoolWorker-4 Pid: 11450<br/><strong class="lm hv">** [16:42:33.240581] Starting: ForkPoolWorker-4 Pid: 11450</strong><br/>[16:42:33.264458] Exiting: ForkPoolWorker-3 Pid: 11449<br/>[16:42:33.586739] Exiting: ForkPoolWorker-1 Pid: 11447<br/>[16:42:34.850162] Exiting: ForkPoolWorker-2 Pid: 11448<br/><strong class="lm hv">[16:42:34.851107] Name: ForkPoolWorker-4 Pid: 11450 Result: 5==148</strong><br/><strong class="lm hv">[16:42:39.854437] Exiting: ForkPoolWorker-4 Pid: 11450</strong></span></pre><h2 id="6828" class="kl km hu bd kn ko kp kq kr ks kt ku kv kb kw kx ky kc kz la lb kd lc ld le lf dt translated">码头工人</h2><p id="1fb6" class="pw-post-body-paragraph jb jc hu je b jf lg jh ji jj lh jl jm kb li jp jq kc lj jt ju kd lk jx jy jz hn dt translated">下一步是将工人分配到一组机器上。我将每个工人打包成一个docker映像，并在一个<a class="ae ka" href="https://github.com/coreos/fleet" rel="noopener ugc nofollow" target="_blank">机群</a>中运行它。</p><p id="ae9f" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">要运行单个docker，您可以使用:</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="0038" class="kl km hu lm b fv lq lr l ls lt">$ <strong class="lm hv">docker run -ti -e ES_HOST=*** -e ES_PORT=*** -e INDEX=index -e DOC_TYPE=doc_type -e SHARD=1 es-parallel</strong></span></pre><p id="c99f" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">每个工人将获得一个分片号，确定相关的路由号，运行scan_shard命令并退出。</p><p id="95b2" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">worker代码类似于前面的sync和pool代码，但是它只运行一次分片扫描。你可以在这里看到工人<a class="ae ka" href="https://github.com/amityo/es-parallel-scan/blob/master/worker.py" rel="noopener ugc nofollow" target="_blank">的最终结果</a>:</p><h2 id="a693" class="kl km hu bd kn ko kp kq kr ks kt ku kv kb kw kx ky kc kz la lb kd lc ld le lf dt translated">机群并行</h2><p id="36b4" class="pw-post-body-paragraph jb jc hu je b jf lg jh ji jj lh jl jm kb li jp jq kc lj jt ju kd lk jx jy jz hn dt translated"><code class="eh lu lv lw lm b">es-parallel@.service</code>是在车队集群上启动的示例单元文件。设置正确的配置，让我们从以下内容开始:</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="41ca" class="kl km hu lm b fv lq lr l ls lt">$ <strong class="lm hv">fleetctl start es-parallel@{0..4} </strong></span></pre><p id="7f7c" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">其中4是碎片的数量(减1)。</p><p id="e865" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">注意，<code class="eh lu lv lw lm b">ExecStart</code>命令使用单元号作为分片号:</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="b8e6" class="kl km hu lm b fv lq lr l ls lt">ExecStart=/bin/sh -c '\<br/>    /usr/bin/docker run \<br/>        --name %p-%i \<br/>        -e ES_HOST="" \<br/>        -e ES_PORT="" \<br/>        -e INDEX="" \<br/>        -e DOC_TYPE="" \<br/>        -e ROUTING="<strong class="lm hv">%i</strong>" \<br/>        es-parallel '</span></pre><p id="5d42" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">结果是:</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="5354" class="kl km hu lm b fv lq lr l ls lt">$ <strong class="lm hv">fleetctl journal es-parallel@1</strong></span><span id="e5f3" class="kl km hu lm b fv lx lr l ls lt">$ g-t-5 docker[43117]: Using default tag: latest<br/>$ g-t-5 docker[43117]: latest: Pulling from es-parallel<br/>$ g-t-5 systemd[1]: Started Es Parallel.<br/>$ g-t-5 sh[43160]: Namespace(doc_type='doc_type', es_auth=None, es_host='elasticsearch', es_port=9200, es_use_ssl=False, index='index', shard='1')<br/>$ g-t-5 sh[43160]: <strong class="lm hv">Result: 148</strong><br/>$ g-t-5 docker[43312]: es-parallel-1</span></pre><p id="6b5c" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">笔记和想法:</p><ul class=""><li id="1c81" class="ly lz hu je b jf jg jj jk kb ma kc mb kd mc jz md me mf mg dt translated">当前—结果打印到控制台。你可以对他们为所欲为。</li><li id="b2d3" class="ly lz hu je b jf mh jj mi kb mj kc mk kd ml jz md me mf mg dt translated">所有工人将同时开始。确保你的elasticsearch集群可以处理它。如果没有，您可以编写一个脚本，根据需要启动workers。</li></ul><h2 id="2867" class="kl km hu bd kn ko kp kq kr ks kt ku kv kb kw kx ky kc kz la lb kd lc ld le lf dt translated">切片卷轴</h2><p id="b8c3" class="pw-post-body-paragraph jb jc hu je b jf lg jh ji jj lh jl jm kb li jp jq kc lj jt ju kd lk jx jy jz hn dt translated">Elasticsearch 5.0 <a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/reference/5.5/search-request-scroll.html#sliced-scroll" rel="noopener ugc nofollow" target="_blank">引入了</a>的<code class="eh lu lv lw lm b">sliced scroll</code>功能——一种将卷轴分割成多个切片的原生方式:</p><pre class="ke kf kg kh fq ll lm ln lo aw lp dt"><span id="c46c" class="kl km hu lm b fv lq lr l ls lt">GET /index/doc_type/_search?scroll=1m<br/>{<br/>    "slice": {<br/>        "id": 0, <br/>        "max": 2 <br/>    },<br/>   "query": { ... }<br/>}</span><span id="29da" class="kl km hu lm b fv lx lr l ls lt">GET /index/doc_type/_search?scroll=1m<br/>{<br/>    "slice": {<br/>        "id": 1,<br/>        "max": 2<br/>    },<br/>    "query": { ... }<br/>}</span></pre><p id="0c85" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated"><code class="eh lu lv lw lm b">max</code>是切片数，<code class="eh lu lv lw lm b">id</code>是切片数。最大值可以等于碎片的数量，更低或更高。首先在碎片上进行分割，然后在每个碎片上进行局部分割。这意味着如果<code class="eh lu lv lw lm b">max == num_of_shards</code>每个切片将是一个单独碎片上的滚动。</p><p id="0dc8" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">请注意，当切片数量大于碎片数量时，会发生内存开销操作。</p><p id="abc5" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">您可以使用切片滚动进行<a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html#docs-reindex-automatic-slice" rel="noopener ugc nofollow" target="_blank">并行重新索引</a>、<a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update-by-query.html#docs-update-by-query-automatic-slice" rel="noopener ugc nofollow" target="_blank">按查询更新</a>和<a class="ae ka" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete-by-query.html#docs-delete-by-query-automatic-slice" rel="noopener ugc nofollow" target="_blank">按查询删除</a>。点击阅读更多<a class="ae ka" href="https://stackoverflow.com/a/43316335/1626280" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="2519" class="kl km hu bd kn ko kp kq kr ks kt ku kv kb kw kx ky kc kz la lb kd lc ld le lf dt translated">摘要</h2><p id="f991" class="pw-post-body-paragraph jb jc hu je b jf lg jh ji jj lh jl jm kb li jp jq kc lj jt ju kd lk jx jy jz hn dt translated">es-parallel可以很好地替代在elasticsearch上使用Spark/Hadoop集群的开销。它非常适合映射、过滤和选择文档，但是你(仍然)没有办法减少结果。</p><p id="5eef" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">在这里找到源代码<a class="ae ka" href="https://github.com/amityo/es-parallel-scan" rel="noopener ugc nofollow" target="_blank">，在这里</a>找到docker <a class="ae ka" href="https://hub.docker.com/r/amityo/es-parallel/" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>