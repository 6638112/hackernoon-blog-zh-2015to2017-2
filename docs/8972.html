<html>
<head>
<title>DL05: Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DL05:卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/dl05-convolutional-neural-networks-1d3bb7fff586?source=collection_archive---------11-----------------------#2017-12-21">https://medium.com/hackernoon/dl05-convolutional-neural-networks-1d3bb7fff586?source=collection_archive---------11-----------------------#2017-12-21</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="c0ac" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">理解和可视化CNN</h2></div><p id="d3e3" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">往期帖子:<br/> <a class="ae kf" href="https://hackernoon.com/dl01-writing-a-neural-network-from-scratch-theory-c02ccc897864" rel="noopener ugc nofollow" target="_blank"> DL01:神经网络理论</a> <br/> <a class="ae kf" href="https://hackernoon.com/dl02-writing-a-neural-network-from-scratch-code-b32f4877c257" rel="noopener ugc nofollow" target="_blank"> DL02:从零开始编写神经网络(代码)</a> <br/> <a class="ae kf" href="https://hackernoon.com/dl03-gradient-descent-719aff91c7d6" rel="noopener ugc nofollow" target="_blank"> DL03:梯度下降</a> <br/> <a class="ae kf" href="https://hackernoon.com/dl04-backpropagation-bbcfbf2528d6" rel="noopener ugc nofollow" target="_blank"> DL04:反向传播</a></p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff kg"><img src="../Images/3ae0554d3befabd53f778a1f6e3dd530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_YnzecdAt9K-6xsqEDXQmg.png"/></div></div></figure><p id="092b" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">现在我们已经了解了反向传播，让我们深入了解卷积神经网络(CNN)！</p><p id="9820" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">(这本书里有很多图片，所以请耐心等待)</p><blockquote class="ks"><p id="7ee2" class="kt ku hu bd kv kw kx ky kz la lb ke ek translated">可视化代码可以在<a class="ae kf" href="https://github.com/thesemicolonguy/convisualize_nb" rel="noopener ugc nofollow" target="_blank">这里</a>(<a class="ae kf" href="https://github.com/thesemicolonguy/convisualize_nb" rel="noopener ugc nofollow" target="_blank">https://github.com/thesemicolonguy/convisualize_nb</a>)找到</p></blockquote><h1 id="8579" class="lc ld hu bd le lf lg lh li lj lk ll lm ja ln jb lo jd lp je lq jg lr jh ls lt dt translated">直觉</h1><p id="ec14" class="pw-post-body-paragraph jj jk hu jl b jm lu iv jo jp lv iy jr js lw ju jv jw lx jy jz ka ly kc kd ke hn dt translated">*将前馈网络应用于图像极其困难。与这样一个网络相关的参数数量是巨大的。一个更好的、改进的网络是图像所需要的。</p><p id="6d87" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">Hubel和Wiesel进行了一些实验，这些实验给出了一些关于大脑如何生物处理图像的直觉。他们发现，当大脑看到边缘、图案等时，会做出特定的反应。<br/>据报道，视皮层分为多层，其中前面的层识别像边缘这样的简单特征，但是后面的层识别更复杂的特征。</p><h1 id="5db6" class="lc ld hu bd le lf lg lh li lj lk ll lm ja lz jb lo jd ma je lq jg mb jh ls lt dt translated">概念</h1><ul class=""><li id="6a7c" class="mc md hu jl b jm lu jp lv js me jw mf ka mg ke mh mi mj mk dt translated"><strong class="jl hv">过滤器</strong></li></ul><p id="f242" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">CNN背后的基本概念是过滤器/内核。你可以把它们想象成较小的图像，然后在输入图像上滑动。通过滑动，我的意思是将同一滤波器乘以图像中的不同区域(即，在图像上卷积)。</p><p id="43c0" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">图像由形状阵列(高度、宽度、深度/通道)表示，其中彩色图像有3个通道(RGB ),灰度图像有1个通道。对于能够在图像上“卷积”的滤波器，它应该具有与输入相同数量的通道。输出是滤波器元素和图像的元素乘法的和(可以认为是点积)。</p><p id="505c" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">因此，我们可以使用任意数量的过滤器。输出深度尺寸将等于我们使用的过滤器的数量。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff ml"><img src="../Images/856947b40f41ffe4f5849c35a2c2fab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9J3MK1gd2zrFDzDN.gif"/></div></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Source: <a class="ae kf" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/convolutional-networks/</a></figcaption></figure><p id="6859" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在上面的动画中，使用了两个滤镜。请注意，每个滤镜的深度(或通道)维度与输入深度相同(在本例中为3)。动画中也清晰地描绘了卷积运算。输出深度尺寸等于过滤器的数量(在本例中为2)。输出是所有通道上的滤波器和镜像的逐元素乘法之和(加上一些可选的偏置项)。所以，可以认为是3x3x 3(filter _ height * filter _ width * input _ depth)体积的点积。</p><p id="59fd" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">为了更直观地了解滤镜，我们来看一个检测垂直边缘的滤镜示例。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff mq"><img src="../Images/a175e56a3998fd1bdc247bfb73fda6d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*JfR2Z5xtadoepVMtjGYyMA.jpeg"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Source: <a class="ae kf" href="https://www.coursera.org/learn/convolutional-neural-networks/lecture/4Trod/edge-detection-example" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/learn/convolutional-neural-networks/lecture/4Trod/edge-detection-example</a></figcaption></figure><p id="61db" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">滤镜可以被认为是检测图像中左边较亮而右边较暗的部分。</p><p id="bcfb" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">滑动过滤器还提供了平移不变性的额外优势，因为可以在任何地方检测到相同的特征，而不管它们出现在图像中的什么位置。</p><p id="2577" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">此外，在实践中，发现初始层倾向于学习更简单的特征，如边、角等。而较深的层倾向于学习复杂的特征，如眼睛、嘴唇、脸等。</p><p id="76a0" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">直观上，可以认为我们正在组合较低级别的特征(例如边缘)，并且这些组合导致这些特征的混合，从而导致较高级别的特征。一个过于简单的例子是，以某种方式组合两个边缘检测滤波器来检测拐角:</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff mr"><img src="../Images/debe5b545f65e473b7fc1319d53a2759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iYn-8Q5KGDgplJKckOuEoQ.jpeg"/></div></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">This is just for intuition (made using awwapp.com)</figcaption></figure><p id="2f91" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">因此，完整的convnet通常如下所示:</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff ms"><img src="../Images/4365b0a8cbb60348ce2e051d5b64be39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/0*vwXnUGFuUVs0705u.jpeg"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Source: <a class="ae kf" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/convolutional-networks/</a></figcaption></figure><p id="1b7a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">过滤器被随机初始化，然后通过反向传播学习。</p><ul class=""><li id="8d6f" class="mc md hu jl b jm jn jp jq js mt jw mu ka mv ke mh mi mj mk dt translated"><strong class="jl hv">层</strong></li></ul><p id="70e5" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">CNN中主要有4种类型的层:</p><ol class=""><li id="be25" class="mc md hu jl b jm jn jp jq js mt jw mu ka mv ke mw mi mj mk dt translated">Conv层:这些层执行卷积运算，如上所述。这些层中可学习参数的数量等于每个滤波器中参数的数量乘以滤波器的数量，即滤波器高度*滤波器宽度*滤波器数量</li><li id="9c36" class="mc md hu jl b jm mx jp my js mz jw na ka nb ke mw mi mj mk dt translated">非线性:Conv层之后通常是非线性层。通常使用ReLU。该层中没有可学习的参数。</li><li id="bf95" class="mc md hu jl b jm mx jp my js mz jw na ka nb ke mw mi mj mk dt translated">池层:该层用于对图像进行缩减像素采样。它导致下一层中的参数较少，因此convnet可以做得更深一点。</li></ol><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff nc"><img src="../Images/bc8f2cbc0607b288264bd2db8d9440e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*e273EgtyFyo7eTsO.jpeg"/></div></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Source: <a class="ae kf" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/convolutional-networks/</a></figcaption></figure><p id="4fd0" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">理论上，平均池看起来是最好的选择，即取图像的一部分，并对该部分进行平均，以给出该部分图像的一个像素值。但在实践中，发现最大池效果更好，即从图像中的该区域获取最大值。汇集层保持深度维度，即在输入的所有通道上独立完成汇集。该层中没有可学习的参数。</p><p id="fef9" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">4.完全连接:这些通常位于convnet的末端。它们是简单的前馈层，具有与普通前馈网络一样多的可学习参数。</p><ul class=""><li id="17be" class="mc md hu jl b jm jn jp jq js mt jw mu ka mv ke mh mi mj mk dt translated"><strong class="jl hv">填充</strong></li></ul><p id="1c32" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">有人可能会说，根据上述卷积运算，图像的边缘和拐角的重要性不如图像中间的部分。为了克服这一点，输入通常被零填充，即在图像的所有边上添加一层零。此外，零填充允许我们根据需要改变输出图像的大小。</p><ul class=""><li id="36e1" class="mc md hu jl b jm jn jp jq js mt jw mu ka mv ke mh mi mj mk dt translated"><strong class="jl hv">步幅</strong></li></ul><p id="174c" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在图像上滑动滤镜时跳跃的大小称为步幅。步幅越大，输出图像越小。</p><p id="fbda" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">用于计算conv层之后的下一层的大小的公式是((<em class="nd">W</em>-<em class="nd">F</em>+2<em class="nd">P</em>)/<em class="nd">S)</em>+1，其中W是图像的大小(水平维度的宽度，垂直维度的高度)，F是过滤器的大小，P是填充，S是跨距。</p><p id="a170" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">另一个值得注意的酷想法是，随着我们向网络的更深处移动，节点的<strong class="jl hv">有效感受域</strong>增加，也就是说，与之前的层相比，节点可以被认为是在查看图像的更大部分。</p><h1 id="a9ce" class="lc ld hu bd le lf lg lh li lj lk ll lm ja lz jb lo jd ma je lq jg mb jh ls lt dt translated">反向传播</h1><p id="a733" class="pw-post-body-paragraph jj jk hu jl b jm lu iv jo jp lv iy jr js lw ju jv jw lx jy jz ka ly kc kd ke hn dt translated">反向传播通常像前馈神经网络一样完成。所有权重(或参数)的导数都是根据r.t .损失计算的，并通过梯度下降(或梯度下降的一些变体，将在后面的帖子中讨论)进行更新。</p><p id="4a7a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在应用链规则寻找梯度w.r.t. loss时，一个权重的梯度将来自下一层中该权重在前向传递中贡献的所有节点(根据微分的<strong class="jl hv">多元链规则</strong>，它将是所有这些梯度的总和)。</p><h1 id="7677" class="lc ld hu bd le lf lg lh li lj lk ll lm ja lz jb lo jd ma je lq jg mb jh ls lt dt translated">形象化</h1><p id="01ad" class="pw-post-body-paragraph jj jk hu jl b jm lu iv jo jp lv iy jr js lw ju jv jw lx jy jz ka ly kc kd ke hn dt translated">现在我们已经了解了convnet的工作原理，让我们试着想象一下在convnet内部发生的一些事情。</p><p id="f6d2" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">一些著名网络架构的精彩解释可以在<a class="ae kf" href="https://www.youtube.com/watch?v=DAOcjicFr1Y&amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&amp;index=9" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="03c4" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">可视化VGG网络的重量没有多大用处，因为过滤器只有3x3大小。然而，alexnet有11x11大小的过滤器。下图显示了alexnet学习的一些滤镜。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff ne"><img src="../Images/4643ede42b08e8c535d784c292a07509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*01pTBZwGwMnr2E895LKfYg.jpeg"/></div></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Source: <a class="ae kf" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/convolutional-networks/</a></figcaption></figure><p id="468e" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">从这一点开始，所有的可视化都是在Pytorch的VGG16上完成的。代码可以在<a class="ae kf" href="https://github.com/thesemicolonguy/convisualize_nb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="2a9e" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">那么，让我们看看每一层的输出是什么样的:</p><p id="dc9b" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">输入图像:</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff nf"><img src="../Images/26f004e88b42ccb9b9ee5fa4df2b7682.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*ING-0jfTSc52zHxHB3oP6w.png"/></div></figure><p id="61d8" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">不同层的输出:</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff ng"><img src="../Images/4f88b8304631e653b335f32da9d18e42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SFk7rQ9DXnWj0DTg06dsWg.png"/></div></div></figure><p id="7efe" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">由于每一层的通道数量是不同的(不是1或3)，我对所有通道进行了平均，最终得到一个灰度图像(颜色方案是因为matplotlib使用的默认cmap方案)。</p><p id="3346" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">请注意，maxpooling只是对图像进行缩减采样。</p><p id="6a3e" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">如果我们不对所有通道取平均值，我们可以在特定层看到每个通道的输出(即每个滤波器的输出)。让我们来看看:</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/75d94fcfb62d461565451268153e823b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*m3Yv81XXHpMpjEaDLmn7SA.png"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Output from first conv layer filters (all 64 channels from this layer)</figcaption></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff ni"><img src="../Images/ebe0c6f8d4c60cc5b4951eb74d2fc9a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*c6CHLeuBNJbWGe5Ms6yuvw.png"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Output from last conv layer filters (first 484 channels are shown out of the total 512 channels at this layer)</figcaption></figure><p id="05c9" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我们已经看到了滤波器的输出，现在让我们看看滤波器的实际情况:</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff nj"><img src="../Images/e59d238fd7b11446741b80656f7611fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*eWcl0_j-Ql-oif7nNVNjdg.png"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">3x3 filters from first conv layer (64 filters)</figcaption></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff nk"><img src="../Images/0e9d2498944d1d40208d756b9de0f3d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Ia-6AK1R5m8ZNj2Lbhs_rQ.png"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">3x3 filters from last conv layer (first 484 out of total 512 filters at this layer)</figcaption></figure><h2 id="72a4" class="nl ld hu bd le nm nn no li np nq nr lm js ns nt lo jw nu nv lq ka nw nx ls ny dt translated">闭塞</h2><p id="15ee" class="pw-post-body-paragraph jj jk hu jl b jm lu iv jo jp lv iy jr js lw ju jv jw lx jy jz ka ly kc kd ke hn dt translated">现在让我们来看看图像的哪一部分负责图像的分类。</p><p id="5f3c" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">首先，我使用了一种叫做遮挡的技术。在这种情况下，我们简单地从图像中移除一个区域，然后找到该图像作为真实类别的分类概率。我们对图像中的许多区域都这样做(基本上，我们通过在整个图像上滑动来移除区域)。</p><p id="f453" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">如果概率得分很高，那么我们知道涂黑的区域对于分类并不重要；没有那个区域，图像被正确分类。如果出现的概率很低，这意味着涂黑的区域对于正确分类图像是很重要的。</p><p id="a6d8" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">蓝色部分表示低输出得分概率，黄色区域表示高输出类别概率。因此，蓝色部分描述了对分类很重要的部分。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff nz"><img src="../Images/9f0ed3c821a467090c1864749322af12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e8lo2FZtiuysUq8e5ECJYQ.png"/></div></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Occlusion Heatmap</figcaption></figure><p id="ae90" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">印象深刻，对吧？</p><p id="4c7a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">但是结果不太好，算法运行时间很长(因为运行分类的正向传递次数太多)。</p><p id="70d5" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">所以，我们尝试不同的方法。</p><h2 id="8817" class="nl ld hu bd le nm nn no li np nq nr lm js ns nt lo jw nu nv lq ka nw nx ls ny dt translated">显著图</h2><p id="874f" class="pw-post-body-paragraph jj jk hu jl b jm lu iv jo jp lv iy jr js lw ju jv jw lx jy jz ka ly kc kd ke hn dt translated">显著图背后的概念很简单。我们找到(图像，类别)对的输入图像w.r.t .输出分数的导数。根据定义，导数告诉我们分类分数相对于该像素的变化率。</p><p id="68d5" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">也就是说，如果我们改变输入图像中的特定像素，输出类得分会改变多少。</p><p id="ac7a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">以下是一些例子:</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff nz"><img src="../Images/a00ddaba7a44b47a7d52dc1976ceb981.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NDf3JFSYXaECSXvUFjjiQA.png"/></div></div></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff nz"><img src="../Images/3c061e39d6183e35386c9a5f25d356e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bWo0VLY734Tg1QzHbymXUQ.png"/></div></div></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff nz"><img src="../Images/f7cdeeb8e109511dfc8fab7105bb2100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q1W_R_eJpTHRt4LOFZMEYA.png"/></div></div></figure><p id="c118" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">这运行得非常快，并且结果相当好。但是正如你所看到的，仍然有很大的改进空间。</p><h2 id="5d03" class="nl ld hu bd le nm nn no li np nq nr lm js ns nt lo jw nu nv lq ka nw nx ls ny dt translated">SmoothGrad</h2><p id="1308" class="pw-post-body-paragraph jj jk hu jl b jm lu iv jo jp lv iy jr js lw ju jv jw lx jy jz ka ly kc kd ke hn dt translated">我们可以使用SmoothGrad技术来改进显著图(也称为敏感度图)。我想在这里引用这篇论文作者的话:</p><pre class="kh ki kj kk fq oa ob oc od aw oe dt"><span id="3ab4" class="nl ld hu ob b fv of og l oh oi">"The apparent noise one sees in a sensitivity map may be due to essentially meaningless local variations in partial derivatives. After all, given typical training techniques there is no reason to expect derivatives to vary smoothly."</span></pre><p id="58ff" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">作者向图像添加了一些噪声，并绘制了三个通道(RGB)的导数w.r.t .输出类别分数:</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff oj"><img src="../Images/8768f528ede59b80d2f5062235afcd2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*rvQ8MESesKyTv6IFqoSp1g.jpeg"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Source: <a class="ae kf" href="https://arxiv.org/pdf/1706.03825.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1706.03825.pdf</a> (The original SmoothGrad paper)</figcaption></figure><p id="50aa" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">这里，t决定了添加到图像中的噪声量。在添加了一点点噪声之后，对于肉眼来说，图像看起来根本没有变化，即，它看起来是相同的图像，这是显而易见的。然而，输入图像的导数波动很大。</p><p id="9bd1" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">所以，作者建议我们进行多次迭代，每次迭代，给原始图像添加一点随机噪声。我们将为每次迭代计算输入图像的导数(添加了噪声),然后在绘制之前最后取这些导数的平均值。</p><p id="61ab" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">平均而言，只有那些像素将具有在每次迭代中具有高值的相应导数的高值。因此，导数中无意义的局部变化将被移除。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff nz"><img src="../Images/188e92cae993b0f60007d7f792cf8579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1HI5R3jm5V6m6DUFDZTZUA.png"/></div></div></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff nz"><img src="../Images/3dfb32ce599e04e62694788ff6986afb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wzaWEQ54ovJ8wDGa6OMqXg.png"/></div></div></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff nz"><img src="../Images/ac74d0a67726d23dfac77fcc58209a62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OpxrFaRMRFoMbPzZdJJZDQ.png"/></div></div></figure><p id="8969" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">如你所见，结果比简单的显著图好得多。</p><p id="58a6" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">这些技术极其有用，可以用GrabCut算法(我自己还没实现)进行语义切分。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff ok"><img src="../Images/30a99df2317f85ba91ee745c0ba0ff76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jMhxXocYCH2e3Ej51iIkdQ.jpeg"/></div></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Source: <a class="ae kf" href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf" rel="noopener ugc nofollow" target="_blank">http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf</a></figcaption></figure><h2 id="0716" class="nl ld hu bd le nm nn no li np nq nr lm js ns nt lo jw nu nv lq ka nw nx ls ny dt translated">班级模型</h2><p id="ffab" class="pw-post-body-paragraph jj jk hu jl b jm lu iv jo jp lv iy jr js lw ju jv jw lx jy jz ka ly kc kd ke hn dt translated">我们也可以可视化班级模型，即CNN认为某个特定班级的最佳代表。这是通过一种叫做梯度上升的算法来实现的。</p><p id="ba02" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我们用零初始化输入图像(尽管将其初始化为imagenet训练示例的平均值会给出稍微好一点的结果)。然后我们向前传递，并计算该图像的类别分数。后面的传球是事情变得有趣的地方。我们不更新权重(就像我们通常在训练时做的那样)。重量保持不变。相反，我们计算输入图像的梯度w.r.t .类得分，并以最大化输出类得分的方式更新所有输入像素。</p><p id="dfef" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><em class="nd">附注:我们希望最大化职业分数，而不是softmax概率，因为softmax概率也可以通过降低其他职业的分数来增加，但只是希望增加目标职业的分数。</em></p><p id="354a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">各种正则化技术也可以在这里使用(如L2，剪辑等。).</p><p id="2dd3" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在下面的动画中，我们从一个空白的图像开始，注意看类似真实物体的部分是如何开始出现的！</p><p id="c277" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">所以让我们来看看这是怎么回事吧！</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff ol"><img src="../Images/14368e397e3f276cb726b556be611476.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/1*-6ne6kwUbwnAobsN4FvFiA.gif"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Flamingo</figcaption></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff ol"><img src="../Images/d1abb25b1f076eeba32ae260d2c21286.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/1*V06GvMBAIIHwoahlArNJbQ.gif"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Mosque</figcaption></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff ol"><img src="../Images/0c29b22bcde0fbb1111f5d38186d684d.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/1*Z9x5g7re_Z0FwGQYf7OtEA.gif"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Zebra</figcaption></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff ol"><img src="../Images/2394f7308a316d5d22696254639196e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/1*OjHtShYxdgtD2EEHotPCwA.gif"/></div><figcaption class="mm mn fg fe ff mo mp bd b be z ek">Dumbbell</figcaption></figure><p id="d714" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">伙计们，这就是全部了！如果你有任何问题，请在评论中提出。</p><p id="b702" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">如果你喜欢这个，给我一个🌟在<a class="ae kf" href="https://github.com/thesemicolonguy/convisualize_nb/" rel="noopener ugc nofollow" target="_blank"> Github </a>和👏在这篇文章中:)</p></div></div>    
</body>
</html>