<html>
<head>
<title>Deeper Still: Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">更深层次:卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/deeper-still-convolutional-neural-networks-495efdbba435?source=collection_archive---------16-----------------------#2017-09-04">https://medium.com/hackernoon/deeper-still-convolutional-neural-networks-495efdbba435?source=collection_archive---------16-----------------------#2017-09-04</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="debe" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">两周前，我们通过构建一个完整的神经网络开始了我们的机器研究。但按照深度学习的标准，这个网络仍然非常简单。在这篇文章中，我们将解决一个更加困难的问题:图像识别。当然，我们仍将使用众所周知的数据集和众所周知的结果，所以这只是冰山一角。我们将使用<a class="ae jp" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>。该集合将手写数字图像分类为数字0-9。这个问题是如此众所周知，以至于张量流的人们将其称为机器学习的“你好世界”。</p><p id="2dfa" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们将使用与Iris数据集非常相似的方法来解决这个问题。我们将制作一个具有两层的全连接神经网络，然后使用“Adam”优化器。按照我们初学者的标准，这会给我们一些不错的结果。但是MNIST是一个众所周知的问题，有着非常大的数据集。所以这一次我们要保持更高的精确度。这将迫使我们使用一些更先进的技术。但是首先，让我们检查一下我们需要改变什么来使我们的Iris模型适用于MNIST问题。和过去几周一样，如果你想继续学习，这一切的代码都在Github 上。</p><h1 id="4073" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">重复使用和回收！</h1><p id="ee54" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">一般来说，我们可以重用Iris的大部分代码，这是个好消息！尽管如此，我们仍然需要在一些地方做一些调整。首先，我们将使用一些不同的常数。我们将用<code class="eh kt ku kv kw b">mnistFeatures</code>代替<code class="eh kt ku kv kw b">irisFeatures</code>，用<code class="eh kt ku kv kw b">mnistLabels</code>代替<code class="eh kt ku kv kw b">irisLabels</code>。我们还将增加隐藏层的大小和每次迭代中要绘制的样本数:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="8893" class="lf jr hu kw b fv lg lh l li lj">mnistFeatures :: Int64<br/>mnistFeatures = 784</span><span id="85e4" class="lf jr hu kw b fv lk lh l li lj">mnistLabels :: Int64<br/>mnistLabels = 10</span><span id="fe58" class="lf jr hu kw b fv lk lh l li lj">numHiddenUnits :: Int64<br/>numHiddenUnits = 1024</span><span id="102b" class="lf jr hu kw b fv lk lh l li lj">sampleSize :: Int<br/>sampleSize = 1000</span></pre><p id="0a2f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们还将改变我们的模型，使用<code class="eh kt ku kv kw b">Word8</code>作为结果类型，而不是<code class="eh kt ku kv kw b">Int64</code>。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="9d18" class="lf jr hu kw b fv lg lh l li lj">data Model = Model<br/> { train :: TensorData Float<br/>         -&gt; TensorData Word8 -- Used to be Int64<br/>         -&gt; Session ()<br/> , errorRate :: TensorData Float<br/>             -&gt; TensorData Word8 -- Used to be Int64<br/>             -&gt; SummaryTensor<br/>             -&gt; Session (Float, ByteString)<br/> }</span></pre><p id="6841" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在，我们必须改变获取输入数据的方式。这次我们的数据不是CSV格式的。我们将使用张量流库中的辅助函数来提取图像和标签:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="8b39" class="lf jr hu kw b fv lg lh l li lj">import TensorFlow.Examples.MNIST.Parse (readMNISTSamples, readMNISTLabels)<br/>…<br/>runDigits :: FilePath -&gt; FilePath -&gt; FilePath -&gt; FilePath -&gt; IO ()<br/>runDigits trainImageFile trainLabelFile testImageFile testLabelFile = <br/> withEventWriter eventsDir $ \eventWriter -&gt; runSession $ do</span><span id="51c0" class="lf jr hu kw b fv lk lh l li lj">   -- trainingImages, testImages :: [Vector Word8]<br/>   trainingImages &lt;- liftIO $ readMNISTSamples trainImageFile<br/>   testImages &lt;- liftIO $ readMNISTSamples testImageFile</span><span id="43f0" class="lf jr hu kw b fv lk lh l li lj">   -- traininglabels, testLabels :: [Word8]<br/>   trainingLabels &lt;- liftIO $ readMNISTLabels trainLabelFile<br/>   testLabels &lt;- liftIO $ readMNISTLabels testLabelFile</span><span id="011f" class="lf jr hu kw b fv lk lh l li lj">   -- trainingRecords, testRecords :: Vector (Vector Word8, Word8)<br/>   let trainingRecords = fromList $ zip trainingImages trainingLabels<br/>   let testRecords = fromList $ zip testImages testLabels<br/>   ...</span></pre><p id="bbd4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们的“输入”类型由<code class="eh kt ku kv kw b">Word8</code>元素的向量组成。这些代表各种像素的强度。我们的“输出”类型是<code class="eh kt ku kv kw b">Word8</code>，指的是实际的标签(0-9)。我们从不同的文件中读取图像和标签。然后我们将它们压缩在一起，传递给我们的处理函数。我们必须对这个数据集的这些处理函数进行一些修改。首先，我们必须概括随机化函数的类型:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="acbc" class="lf jr hu kw b fv lg lh l li lj">-- Used to be IrisRecord Specific<br/>chooseRandomRecords :: Vector a -&gt; IO (Vector a)</span></pre><p id="01c0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">接下来，我们必须编写一个新的编码函数，将我们的数据转换成<code class="eh kt ku kv kw b">TensorData</code>格式。这看起来像我们的旧版本，除了处理新的元组类型而不是<code class="eh kt ku kv kw b">IrisRecord</code>。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="6776" class="lf jr hu kw b fv lg lh l li lj">convertDigitRecordsToTensorData <br/> :: Vector (Vector Word8, Word8)<br/> -&gt; (TensorData Float, TensorData Word8)<br/>convertDigitRecordsToTensorData records = (input, output)<br/> where<br/>   numRecords = Data.Vector.length records <br/>   input = encodeTensorData [fromIntegral numRecords, mnistFeatures]<br/>     (fromList $ concatMap recordToInputs records)<br/>   output = encodeTensorData [fromIntegral numRecords] (snd &lt;$&gt; records)<br/>   recordToInputs :: (Vector Word8, Word8) -&gt; [Float]<br/>   recordToInputs rec = fromIntegral &lt;$&gt; (toList . fst) rec</span></pre><p id="8e4c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">然后，我们只需替换我们的新功能和参数，我们将能够运行我们的数字训练器！</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="b46d" class="lf jr hu kw b fv lg lh l li lj">Current training error 89.8<br/>Current training error 19.300001<br/>Current training error 13.300001<br/>Current training error 11.199999<br/>Current training error 8.700001<br/>Current training error 6.5999985<br/>Current training error 6.999999<br/>Current training error 5.199999<br/>Current training error 4.400003<br/>Current training error 5.000001<br/>Current training error 2.3000002</span><span id="f61f" class="lf jr hu kw b fv lk lh l li lj">test error 6.830001</span></pre><p id="f8d3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所以我们的准确率是93.2%。这似乎是一个不错的数字。但是想象一下，作为一个邮局，你有6.8%的邮件被分入了错误的邮政编码！(这是该数据集的原始用例)。所以让我们看看我们是否能做得更好。</p><h1 id="0846" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">卷积和最大池化</h1><p id="e06c" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">现在我们可以更长时间地训练我们的模型。这将有助于提高我们的错误率。但是我们也可以通过使我们的模型更复杂来帮助我们自己。到目前为止，我们所得到的基本缺陷是，它没有考虑到图像的2D性质。这意味着我们正在丢失大量有用的信息。所以我们要做的第一件事是把我们的图像当作28x28的张量，而不是1x784。通过这种方式，我们的模型可以挑选出对识别手指有意义的特定区域。</p><p id="89b0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们要考虑的一件事是，我们的图像可能不在画面的中心。为了说明这一点，我们将应用卷积。当使用卷积时，我们将图像分解成许多不同的重叠图像块。在我们的例子中，我们将在每个方向上使我们的步幅大小为“1”，并且我们将使用5x5的面片大小。因此，这意味着我们将在图像中的每个不同像素周围放置一个5x5的图块，然后得出一个分数。这个分数告诉我们这部分图像是否包含任何重要信息。我们可以将这个分数表示为一个具有许多特征的向量。</p><p id="bbd7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对于2D卷积，我们将处理4维张量。第一个维度是样本量。后两个维度是图像的形状。最后一个维度是图像每个部分的“分数”的特征数量。因此，每幅原始图像都以单个特征作为每个像素的“分数”。这个分数就是那个像素的实际强度！然后每一层卷积将充当每个像素的迷你神经网络，生成我们想要的尽可能多的特征。</p><figure class="kx ky kz la fq lm fe ff paragraph-image"><div class="fe ff ll"><img src="../Images/735f987e6aceb2b7a975924e14b8cb2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/0*_v2vVkfnuJHoTS5y."/></div><figcaption class="lp lq fg fe ff lr ls bd b be z ek">The different sliding windows correspond to scores we store in the next layer. This example uses 3x3 patches; we’ll use 5x5.</figcaption></figure><p id="2632" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最大池是一种下采样形式。在我们的第一个卷积步骤之后，我们将得到28x28图像的分数。我们将使用2x2 max-pooling，这意味着我们将每个图像分成2x2个正方形。然后，我们将创建一个14x14的新图层，仅使用每个2x2盒子中的“最佳”分数。这使得我们的模型更加高效，同时保留了最重要的信息。</p><figure class="kx ky kz la fq lm fe ff paragraph-image"><div class="fe ff lt"><img src="../Images/d2f2177cbcf630c895083bbbebc88e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*gbgQsTN8q0dWxiWTbAgWkA.jpeg"/></div><figcaption class="lp lq fg fe ff lr ls bd b be z ek">Simple demonstration of max-pooling</figcaption></figure><h1 id="42d2" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">实现卷积层</h1><p id="0c04" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">我们将进行两轮卷积和最大汇集。因此，我们将创建一个函数来创建执行这两个步骤的层。这将看起来很像我们的其他神经网络层。我们将获取层的输入和输出通道的大小的参数，以及张量本身。因此，我们的第一步将是使用这些参数创建权重和偏差张量:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="dfda" class="lf jr hu kw b fv lg lh l li lj">patchSize :: Int64<br/>patchSize = 5</span><span id="0d62" class="lf jr hu kw b fv lk lh l li lj">buildConvPoolLayer :: Int64 -&gt; Int64 -&gt; Tensor v Float -&gt; Text<br/>                  -&gt; Build (Variable Float, Variable Float, Tensor Build Float)<br/>buildConvPoolLayer inputChannels outputChannels input layerName = withNameScope layerName $ do<br/> weights &lt;- truncatedNormal (vector weightsShape)<br/>   &gt;&gt;= initializedVariable<br/> bias &lt;- truncatedNormal (vector [outputChannels]) &gt;&gt;= initializedVariable<br/> ...<br/> where<br/>   weightsShape :: [Int64]<br/>   weightsShape = [patchSize, patchSize, inputChannels, outputChannels]</span></pre><p id="36f5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在我们要调用卷积和最大池函数。这些仍然有点粗糙(Haskell库还很年轻)。这些函数的C版本有许多可选的命名属性。目前，似乎没有任何函数对这些参数使用普通的Haskell值。相反，我们将使用<code class="eh kt ku kv kw b">OpAttr</code>值，给值分配字节串名称。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="f676" class="lf jr hu kw b fv lg lh l li lj">where<br/> ...<br/> convStridesAttr = opAttr "strides" .~ ([1,1,1,1] :: [Int64])<br/> poolStridesAttr = opAttr "strides" .~ ([1,2,2,1] :: [Int64])<br/> poolKSizeAttr = opAttr "ksize" .~ ([1,2,2,1] :: [Int64])<br/> paddingAttr = opAttr "padding" .~ ("SAME" :: ByteString)<br/> dataFormatAttr = opAttr "data_format" .~ ("NHWC" :: ByteString)<br/> convAttrs = convStridesAttr . paddingAttr . dataFormatAttr<br/> poolAttrs = poolKSizeAttr . poolStridesAttr . paddingAttr . dataFormatAttr</span></pre><p id="02e3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">卷积的<code class="eh kt ku kv kw b">strides</code>参数指的是我们每次移动窗口的量。关于合用的<code class="eh kt ku kv kw b">strides</code>论点指的是我们执行合用的窗口有多大。在这种情况下，它是2x2。现在我们有了自己的属性，我们可以调用库函数<code class="eh kt ku kv kw b">conv2D’</code>和<code class="eh kt ku kv kw b">maxPool’</code>。这就给出了我们的合成矢量。我们还在这些步骤之间加入了对<code class="eh kt ku kv kw b">relu</code>的调用。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="ee83" class="lf jr hu kw b fv lg lh l li lj">buildConvPoolLayer :: Int64 -&gt; Int64 -&gt; Tensor v Float -&gt; Text<br/>                  -&gt; Build (Variable Float, Variable Float, Tensor Build Float)<br/>buildConvPoolLayer inputChannels outputChannels input layerName = withNameScope layerName $ do<br/> weights &lt;- truncatedNormal (vector weightsShape)<br/>   &gt;&gt;= initializedVariable<br/> bias &lt;- truncatedNormal (vector [outputChannels]) &gt;&gt;= initializedVariable<br/> let conv = conv2D' convAttrs input (readValue weights)<br/>       `add` readValue bias<br/> let results = maxPool' poolAttrs (relu conv)<br/> return (weights, bias, results)<br/> where<br/>   ...</span></pre><h1 id="885a" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">修改我们的模型</h1><p id="c607" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">现在，我们将对我们的模型进行一些更新，我们将处于良好的状态。首先，我们需要将输入数据整形为四维。然后，我们将应用两个卷积/池层:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="7f9b" class="lf jr hu kw b fv lg lh l li lj">imageDimen :: Int32<br/>imageDimen = 28</span><span id="4ba4" class="lf jr hu kw b fv lk lh l li lj">createModel :: Build Model<br/>createModel = do<br/> let batchSize = -1 -- Allows variable sized batches<br/> let conv1OutputChannels = 32<br/> let conv2OutputChannels = 64<br/> let denseInputSize = 7 * 7 * 64 :: Int32 -- 3136<br/> let numHiddenUnits = 1024</span><span id="65bb" class="lf jr hu kw b fv lk lh l li lj"> inputs &lt;- placeholder [batchSize, mnistFeatures]<br/> outputs &lt;- placeholder [batchSize]</span><span id="da99" class="lf jr hu kw b fv lk lh l li lj"> let inputImage = reshape inputs (vector [batchSize, imageDimen, imageDimen, 1])</span><span id="8119" class="lf jr hu kw b fv lk lh l li lj"> (convWeights1, convBiases1, convResults1) &lt;- <br/>   buildConvPoolLayer 1 conv1OutputChannels inputImage "convLayer1"<br/> (convWeights2, convBiases2, convResults2) &lt;-<br/>   buildConvPoolLayer conv1OutputChannels conv2OutputChannels convResults1 "convLayer2"</span></pre><p id="97e1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">完成后，我们将像以前一样应用两个完全连接的(密集)层。请注意，我们将把我们的结果从四维重新调整为二维:</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="fc00" class="lf jr hu kw b fv lg lh l li lj">let denseInput = reshape convResults2 (vector [batchSize, denseInputSize])<br/>(denseWeights1, denseBiases1, denseResults1) &lt;-<br/>  buildNNLayer (fromIntegral denseInputSize) numHiddenUnits denseInput "denseLayer1"  <br/>let rectifiedDenseResults = relu denseResults1<br/>(denseWeights2, denseBiases2, denseResults2) &lt;-<br/>   buildNNLayer numHiddenUnits mnistLabels rectifiedDenseResults "denseLayer2"</span></pre><p id="57b8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">之后，我们可以同样对待模型的其余部分。我们将更新参数名称，并向模型可以改变的<code class="eh kt ku kv kw b">params</code>添加新的权重和偏差。</p><p id="68c7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">作为回顾，我们来看看这里每个中间张量的维数。然后我们可以看到对不同操作的维度的限制。每个卷积步骤需要两个四维张量。参数1的最后一个维度必须与参数2的第三个维度匹配。那么结果将交换到参数2的最后一个维度。同时，具有2×2步幅大小的池将得到这个4维张量，并将每个内部维度减半。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="246d" class="lf jr hu kw b fv lg lh l li lj">input: n x 784<br/>inputImage: n x 28 x 28 x 1<br/>convWeights1: 5 x 5 x 1 x 32<br/>convBias1: 32<br/>conv (first layer): n x 28 x 28 x 32<br/>convResults1: n x 14 x 14 x 32<br/>convWeights2:  5 x 5 x 32 x 64<br/>conv (second layer): n x 14 x 14 x 64<br/>convResults2: n x 7 x 7 x 64<br/>denseInput: n x 3136<br/>denseWeights1: 3136 x 1024<br/>denseBias1: 1024<br/>denseResults1: n x 1024<br/>denseWeights2: 1024 x 10<br/>denseBias2: 10<br/>denseResults2: n x 10</span></pre><p id="49c4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所以对于每一个输入，我们会有所有10个可能输入的概率。我们挑选其中最大的作为选择的标签。</p><h1 id="66e2" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">结果</h1><p id="ce8f" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">我们将再次运行我们的模型，只是这次我们将使用更小的样本量(每次训练迭代100)。这允许我们训练更多的迭代(20000)。这需要相当长的时间来训练，但是我们得到了这些结果(每1000次迭代打印一次)。</p><pre class="kx ky kz la fq lb kw lc ld aw le dt"><span id="9d24" class="lf jr hu kw b fv lg lh l li lj">Current training error 91.0<br/>Current training error 6.0<br/>Current training error 2.9999971<br/>Current training error 2.9999971<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.99999905<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0<br/>Current training error 0.0</span><span id="81b8" class="lf jr hu kw b fv lk lh l li lj">test error 1.1799991</span></pre><p id="80fa" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">不算太差！一旦它开始运行，我们看到很少的训练错误，尽管仍然以一个有点过拟合的模型结束。张量流MNIST <a class="ae jp" href="https://www.tensorflow.org/get_started/mnist/pros" rel="noopener ugc nofollow" target="_blank">专家教程</a>建议使用一个失落因子。这有助于减少过度拟合的影响。但是这个选项在Haskell中还不可用。尽管如此，我们还是达到了接近99%的准确率，这对我们来说是一个成功！</p><p id="6296" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这是我们最终的图表。请注意我们为卷积添加的额外层:</p><figure class="kx ky kz la fq lm fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff lu"><img src="../Images/01ea2dacd80d7ea06230b7ec66b8ec56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5yuQbSbitKMOcPOcME4Zw.png"/></div></div></figure><h1 id="af58" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">结论</h1><p id="3161" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">这就是卷积神经网络！我们的目标是调整我们以前的神经网络模型来识别数字。我们不仅选择了一个更难的问题，而且我们还想要更高的准确性。我们通过使用更先进的机器学习技术实现了这一点。卷积使我们能够充分利用图像的2x2性质。无论手指在图像中的什么位置，它都会检查手指。Max pooling使我们能够在保留最重要信息的同时提高算法的效率。</p><p id="1ad9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你想看看Haskell还能用张量流做什么，看看我们的<a class="ae jp" href="https://www.mmhaskell.com/tensorflow" rel="noopener ugc nofollow" target="_blank">张量流指南</a>。它将带您了解让库在本地机器上工作的一些更棘手的部分。它还将介绍您需要了解的关于该库中类型的最重要的信息。</p><p id="ff9d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果您是Haskell的新手，在尝试张量流之前，这里有几个资源可供您研究。首先，是我们的<a class="ae jp" href="https://www.mmhaskell.com/checklist" rel="noopener ugc nofollow" target="_blank">入门清单</a>。这将为你指出一些有助于学习语言的资源。接下来，您可以查看我们的<a class="ae jp" href="http://academy.mondaymorninghaskell.com/p/your-first-haskell-project" rel="noopener ugc nofollow" target="_blank">堆栈迷你课程</a>，这样您就可以学习如何组织项目！如果想在Haskell中使用张量流，Stack是必须的！</p></div></div>    
</body>
</html>