<html>
<head>
<title>Training an Architectural Classifier — III</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练建筑分类器— III</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/training-an-architectural-classifier-iii-84dd5f3cf51c?source=collection_archive---------30-----------------------#2017-10-11">https://medium.com/hackernoon/training-an-architectural-classifier-iii-84dd5f3cf51c?source=collection_archive---------30-----------------------#2017-10-11</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="7bae" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">深度神经网络</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff jj"><img src="../Images/d9109db75d9571244dc3500b3bcc2c85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*Pn42wNB6_HBKgpvxRzGBWw.png"/></div></figure><p id="8256" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated"><em class="kn">这是5篇文章系列的第3部分:</em></p><ol class=""><li id="a045" class="ko kp hu jt b ju jv jx jy ka kq ke kr ki ks km kt ku kv kw dt translated"><a class="ae kx" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-5f1b4f512368"> <em class="kn">训练一个架构分类器:动机</em> </a></li><li id="4d9f" class="ko kp hu jt b ju ky jx kz ka la ke lb ki lc km kt ku kv kw dt translated"><a class="ae kx" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-ii-bf29eca3cfa6"> <em class="kn">训练一个架构分类器:Softmax回归</em> </a></li><li id="8d2c" class="ko kp hu jt b ju ky jx kz ka la ke lb ki lc km kt ku kv kw dt translated"><a class="ae kx" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iii-84dd5f3cf51c"> <em class="kn">训练一个架构分类器:深度神经网络</em> </a></li><li id="b116" class="ko kp hu jt b ju ky jx kz ka la ke lb ki lc km kt ku kv kw dt translated"><a class="ae kx" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iv-4f76bc6844bc"> <em class="kn">训练一个架构分类器:卷积网络</em> </a></li><li id="6317" class="ko kp hu jt b ju ky jx kz ka la ke lb ki lc km kt ku kv kw dt translated"><a class="ae kx" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-v-fe82e83e94ec"> <em class="kn">训练一个架构分类器:迁移学习</em> </a></li></ol><p id="5148" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt ld translated"><span class="l le lf lg bm lh li lj lk ll di">在</span>这篇文章中，我将在TensorFlow中构建一个深度神经<a class="ae kx" href="https://hackernoon.com/tagged/network" rel="noopener ugc nofollow" target="_blank">网络</a>，试图击败我们在上一篇文章中构建的softmax分类器的准确性。</p><p id="b4cf" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">回顾上一篇文章，我们用softmax训练了5000个时期，达到了75%的最大训练准确率，这促使我们寻找更复杂的模型。在测试集上，验证准确率达到了大约60%，而只有55%，这表明过度拟合也将是一个问题。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="fe ff lm"><img src="../Images/ad0c15d165b5b9c3c29e7f039683a7a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4cy36IGk3jWPiozSNVgEQ.png"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">tensorboard accuracy summary for softmax regression</figcaption></figure><h2 id="15bf" class="lv lw hu bd lx ly lz ma mb mc md me mf ka mg mh mi ke mj mk ml ki mm mn mo mp dt translated">深度神经网络的直觉</h2><p id="c610" class="pw-post-body-paragraph jr js hu jt b ju mq iv jw jx mr iy jz ka ms kc kd ke mt kg kh ki mu kk kl km hn dt translated">页面顶部的图表说明了深度神经网络的概念。输入层的每个节点代表图像中要分类的一个像素，与逻辑回归类似，这些像素中的每个都连接到下一层中的一个神经元，该神经元本身就是逻辑分类器。现在的区别是，我们在下一层中有许多神经元，每个像素都与每个神经元相连，我们在多层中复制这一点。</p><p id="a46a" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">虽然逻辑模型允许像素值给出类成员资格的证据，但是这种密集连接的模型允许神经元找到给出成员资格证据的像素 之间的<strong class="jt hv"> <em class="kn">关系。随着越来越多的层叠加起来，甚至可以发现具有预测能力的更深层次的关系。这个过程被称为“特征工程”，通常在其他机器学习方法中人工完成，但深度神经网络可以自行完成。</em></strong></p><p id="5325" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">从数学上来说，与我们上一个模型相比，深度网络中没有什么可怕的新东西，只是更多。我们将输入乘以各自的权重，但现在是对每个神经元进行。</p><p id="772a" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">类似地，乘法的输出将通过每个神经元的非线性函数，这次使用“整流线性单元”或ReLU，而不是<a class="ae kx" href="https://hackernoon.com/tagged/softmax" rel="noopener ugc nofollow" target="_blank"> softmax </a>非线性。</p><p id="aca2" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">你可以在这里阅读更多关于ReLUs <a class="ae kx" href="http://ryantm.io" rel="noopener ugc nofollow" target="_blank">的内容</a>，但可以说，它们只是另一种非线性，已被证明在深度神经网络中是有用的。它们可以与tanh或sigmoid等其他函数自由互换。</p><h2 id="f75a" class="lv lw hu bd lx ly lz ma mb mc md me mf ka mg mh mi ke mj mk ml ki mm mn mo mp dt translated">实验笔记本</h2><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mv mw l"/></div></figure><p id="8179" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">这给了我们一个更好的测试精度<strong class="jt hv"> 65% </strong>！以及5000个时代的张量板总结:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="fe ff mx"><img src="../Images/6ace50afe1cd626a28faa638d9336238.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kSg5XwlkQxhbR9aJ1q7WTA.png"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">tensorboard summary for training. Blue: training accuracy, Purple: validation accuracy.</figcaption></figure><p id="9168" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">看起来我们在训练精度上有了很大的提高，在验证方面也有了一点进步，但是我们有一个更大的过度拟合问题。这是有意义的，因为我们已经建立了一个模型，它可以更好地从看到的图像中提取数据，但图像包含大量无关数据，我们没有向它显示足够的图像来区分概化数据和无关数据。</p><p id="209d" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">我们发现的被称为<a class="ae kx" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank"> ' <em class="kn">维度诅咒</em> ' </a>。随着输入维数的增加，您需要更多的示例来防止过度拟合。寻找更多数据的另一种方法是降低输入的维数。简单地减小图像大小并不理想，因为您可能会破坏有价值的数据，所以我们将转向一种称为卷积的技术，这种技术实际上将成为我们网络架构的一个组成部分。</p><p id="3c8e" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">请阅读我的下一篇文章“卷积神经网络”</p><p id="d275" class="pw-post-body-paragraph jr js hu jt b ju jv iv jw jx jy iy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated"><a class="ae kx" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iv-4f76bc6844bc">下一个:卷积神经网络</a></p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="my mw l"/></div></figure></div></div>    
</body>
</html>