# 为什么我们仍然处于影响网络行为的炼金术时代

> 原文：<https://medium.com/hackernoon/ronny-kohavi-on-why-we-are-still-in-the-alchemy-days-of-influencing-online-behavior-c6382f18162d>

## 罗尼·科哈维关于可信实验的访谈

![](img/a685fe0178b9d730580de648cf9620f3.png)

Ronny Kohavi 是微软的技术人员和公司副总裁，负责分析和实验。2005 年加入微软，2006 年创立 [**实验平台**](http://exp-platform.com/) **团队。**

**他的论文被引用超过** [**27，000 次**](http://scholar.google.com/citations?hl=en&user=O3RYHGwAAAAJ&view_op=list_works&pagesize=100) **，其中三篇论文位列计算机科学领域被引用次数最多的** [**前 1，000 篇**](http://citeseerx.ist.psu.edu/stats/articles?t=articles&st=200) **论文。**

简而言之，Ronny 是实验界的大佬，我很高兴他能抽出时间和我讨论这个问题。

**跑步实验是在不同学科中完成的。最近有很多关于 A/B 测试或在线随机控制实验的关注，例如在社交网络和搜索引擎结果页面中。**

在一些工程学科中，也使用实验，实验者经常试图创建一个健壮的过程，一个受外部可变性来源影响最小的过程。这可以用于新产品设计或配方、制造工艺开发和工艺改进。

你认为这两种实验的最大区别是什么？我们能从彼此身上学到什么？

让我们来看看实验所需的一些属性，并对这两类实验进行比较，为了简单起见，我将这两类实验称为“实验室”实验和“随机”实验。

## 感兴趣的因变量

这是我们试图理解的现象。在物理学中，我们可能对确定一个常数感兴趣，比如光速，或者欧姆定律中因子之间的关系。在在线随机实验中，因变量通常由业务驱动，可能是像会话/用户这样的东西(Bing 的 northstar 指标，如 [*值得信赖的在线控制实验:五个令人困惑的结果解释*](http://www.exp-platform.com/Pages/PuzzlingOutcomesExplained.aspx) 中所述)。我们经常将因变量称为总体评估标准(OEC)，以强调它可能是多个因素的组合(例如，会话/用户是一个因素，但收入是另一个因素)。

## 重复性对于在实验室和随机实验中建立因果关系至关重要

在罗伯特·弗罗斯特的《未选之路》中，他写道:

> 一片树林里分出两条路，我——
> 我选择了人迹较少的一条，
> 
> 这使得一切都不同了

但是，这种说法是因果关系，不能真正知道。作为一个单独的人，他不能确定，正如安格里斯特和皮施克在 [*掌握“度量:从原因到效果的路径*](http://www.amazon.com/Mastering-Metrics-Path-Cause-Effect/dp/0691152845/) *t.* 中指出的那样

另一个很好的例子来自 2008 年大衰退后的刺激计划，名为《2009 年美国复苏和再投资法案》。该法案的价值引起了激烈的争论，但鉴于这是一个独特的事件，几乎不可能估计反事实，或如果不这样做的结果。正如 Jim Manzi 在他的巨著[](http://www.amazon.com/Uncontrolled-Surprising-Trial-Error-Business/dp/046502324X)**中所指出的那样，考虑到这些相互矛盾的观点，我们唯一有把握说的是，至少有几位诺贝尔经济学奖得主对其影响的判断是不正确的。我们甚至不知道他们谁对谁错，即使在事后。**

**实验室实验和随机实验都需要一个设置，在这个设置中我们可以复制一些设置并观察两个动作，其中一个可能是无效动作。在网站的在线控制实验中，我们通过为每个用户随机选择两个(或更多)版本的网站来实现这一点，保持体验的一致性(粘性)。**

## **实验室与现实世界的实验**

**我们在实验室(或焦点小组)模拟真实世界的能力可能会失败，实验室结果可能无法预测实际的消费者行为。人们说一件事，然后在实验室外做出不同的反应。**

**这里有两个很好的例子。**

**1.飞利浦电子公司组织了一个焦点小组来深入了解青少年对音箱功能的偏好。焦点小组的与会者在焦点小组会议期间表达了对黄色吊杆盒的强烈偏好，认为黑色吊杆盒“保守”然而，当与会者离开房间并有机会将一个音箱带回家作为他们参与的奖励时，大多数人选择了黑色(Cross and Dixit，2005，[以客户为中心的定价:盈利的惊人秘密](http://www.sciencedirect.com/science/article/pii/S0007681305000492))。**

**2.一项关于食物消费的研究显示，当账单是个人支付还是在用餐者之间平均分配时，在实验室和餐馆环境中会得出不同的结果。在一家餐馆里，当六名参与者知道费用最终会被分摊时，他们会消费更多的食物，相对于个人支付他们点的食物，每人支付总数的六分之一；但是实验室的一项类似研究并没有显示消费的统计增长([格尼兹](/i-love-experiments/maximizing-the-roi-of-incentives-with-uri-4f5feec8f418#.jdji8f5zd)，哈鲁维，亚菲，2004，[分摊账单的低效率](http://rady.ucsd.edu/faculty/directory/gneezy/pub/docs/splitting-bill.pdf))。**

## **影响相关因变量的因素**

**这就是最大的差异所在。我们可以在实验室中控制一些变量，但当要控制的潜在变量数量很大时，我们必须求助于随机实验。**

**从历史上看，基于统计的随机对照实验真正开始于 20 世纪 20 年代 R.A. Fisher 的农业实验。美国的药物审批从专家意见演变为更客观的随机对照试验(RCT)。在软件领域，许多公司正在采用在线控制实验来帮助评估功能和辅助产品开发。在所有这些设置中，因素的数量是如此之大，以至于几乎不可能控制所有的因素。将用户(或实验单元)随机分配给不同的变体要容易得多，也更值得信赖。**

**在软件开发的早期，微软将软件测试作为实验室实验:阅读规范，设计测试用例，并检查预期的输出。2005 年我加入微软的时候，Office 的开发人员和测试人员的比例是 1:1！**

**随着 Bing 扩展其 A/B 测试程序，很明显这是一种更具可扩展性的评估软件的方法，不仅仅是因为测试矩阵增长太快，还因为它提供了一种通过查看用户行为来评估功能价值的方法，因此我们可以评估想法的价值，而不仅仅是开发人员是否编写了规范所说的内容。**

**假设你正在改变一个搜索引擎的排名算法(比如 Bing，Google)。这改变了数百万次查询的搜索引擎结果页面(SERP)。如何确定新算法是否更好？我们可以(也确实)让法官评估一些查询，但是数据集的大小有限，成本也很高。我们也从来不知道用户的意图是什么。我们可以告诉法官用户的设备(如台式机或手机)和位置(当可用时)，但我们关于用户的精神状态和意图的整体信息是有限的(而且有许多因素)。**

**以查询“出租车”为例。你在找出租车吗？你在找 70 年代末 80 年代初的电视剧吗？你是在找 taxi.com 吗，它自称是世界领先的独立艺术家和剧目公司？你在找优步的应用吗？也许你最近听到的出租车相撞的新闻已经关闭了通往你的目的地的一条主要高速公路？**

**受控实验“整合”了所有这些因素，为实验中的不同变量提供了您所关心的关键指标。我们可以评估关键指标，例如:用户是否回来得更多(会话/用户)，是否有更多用户成功点击(X 秒内没有后退按钮)以及他们点击页面的位置(通常越高越好)，他们点击需要多长时间，页面加载需要多长时间，以及我们获得的收入。虽然我们仅根据几个指标来做出我们的船舶决策，但我们与我们的实验者分享数千个指标，因为这些指标可以产生有趣的(通常令人惊讶的)见解。每个建立功能的人都相信他们的新治疗方法将会执行控制，但我们 80%的实验在 Bing 上是平的或负的，所以这种体验是非常令人羞愧的。**

## **并行实验**

**根据统计功效公式，以及确保我们不降低关键指标的需要，Bing 实验处理运行在 10%-20%的用户上(见本讨论[)。因为许多实验需要客户控制来进行反事实触发，如果实验必须是分离的，那么在一个给定的时间点，您只能运行大约 5 个实验！](http://bit.ly/quoraABHowLong)**

**在 Bing 上运行更多受控实验的需求导致了支持并发实验的系统的设计。用户不再处于单个实验中，而是处于多个并发实验中。在 [*大规模在线控制实验*](http://www.exp-platform.com/Pages/ControlledExperimentsAtLargeScale.aspx) 中，我们注意到，随着用户陷入 15 个并发实验，他们陷入了 Bing 的 300 亿个可能变种之一！在实验室实验中尝试一下😉。**

**![](img/7b83b2912222290c98da846095860c6a.png)**

****Douglas Montgomery 的** [**实验的设计与分析**](http://eu.wiley.com/WileyCDA/WileyTitle/productCd-EHEP002024.html) **是“实验工程师”的圣经。****

****我非常喜欢蒙哥马利的方法，因为他专注于建立实证模型。精心设计的实验可以产生系统性能的模型。当你把一个设计好的实验结果转化成一个正在研究的系统的经验模型时，科学家/工程师可以操纵这样的模型，就像他们可以操纵机械模型一样。****

**我同意这是一个理想的目标。在我的几次演讲中(最近一次是我在 2015 年 KDD 上的[主题演讲)，我分享了一个采用实验的四阶段文化模型，从(1)傲慢到(2)测量和控制到(3)塞梅尔维斯反射，最后是(4)基本理解。](http://bit.ly/KDD2015Kohavi)**

**蒙哥马利建议建立经验模型，这有助于更好地理解潜在因素。在 Semmelweis 的案例中，随着路易斯·巴斯德发现链球菌，我们破解了“儿童热”的原因。**

**也就是说，我们试图总结成千上万个受控实验的结果，但收效甚微。参见 [*网站实验者的七条经验法则*](http://www.exp-platform.com/Pages/SevenRulesofThumbforWebSiteExperimenters.aspx) 了解一些经验法则。**

**现实是，我们的用户在线行为模型非常有限，可能类似于炼金术的早期，当时科学家试图将铅变成黄金。史蒂夫·克鲁格的书 [*不要让我认为*](https://www.amazon.com/Dont-Make-Think-Revisited-Usability-ebook/dp/B00HJUBRPG) 是我推荐的一个很棒的资源，他的建议是基于一个专家的经验，用很少的数据让我们明白它们的适用性和局限性。炼金术导致了化学，化学改变了世界，但我们需要谦虚地看待我们离拥有良好的用户行为模型还有多远:我们仍处于炼金术时代，模型受到严重限制，大量随机想法被尝试。**

**当工程师们谈论健壮性时，我想这符合你对可信性的想法。正如你多次说过的，“生成数字很容易；生成您应该信任的数字很难！”但是产生可信赖的不是实验最难的事情吗？**

**稳健性是一种通常与抵抗扰动或异常值相关联的属性。**

**可信度是一个更一般的概念，涵盖了整个端到端系统。**

**这里有一个真实的例子，我们以前没有分享过。当我们开始在移动设备上运行实验时，我们使用我们非常值得信赖的 ExP 系统进行分析。这些指标是从桌面世界继承来的，被认为对于我们通常观察到的模式(异常值、机器人等)是健壮的。**

**但事实证明，传入的点击数据存在严重缺陷:手机上的每一次滚动事件都被记录为一次点击。**

**用怀疑的眼光审核数据，调查那些看起来可疑的指标，并识别潜在原因的能力，是导致可信结果的原因。**

**几个月前，我在 quora 和 [ConversionXL](http://www.exp-platform.com/Pages/ConversionXL_AB_Pitfalls.aspx) 上分享了一组陷阱。理解这些并避免它们有助于提高结果的可信度。**

****许多工程实验设计通常是析因设计，它们研究两个或更多因素的影响。我确实看到了这些析因设计的价值，因为这个世界是相当复杂的，在你想要研究的背景下，往往有多种因素在起作用。****

**但是这增加了实验的复杂性，我猜也限制了人们对它们的理解。目前的情况是，没有多少人完全理解简单的实验和它们的必要性。你认为更复杂的实验是一种进步，还是会损害实验的广泛接受？**

**我们在我们的[调查论文](http://bit.ly/expSurvey)中讨论了这一点。如你所说，由于交互作用，析因设计确实有帮助。在许多情况下，通过 OFAT(一次一个因素)，你会在同一个山头结束，但显然不是在所有情况下。**

**我们的方法是鼓励组合的显式测试，但通常是在低交互水平:选择两个因素并尝试所有的组合，或者选择三个因素并选择那些“有意义的”在许多情况下，UX 准则可能会限制一些组合，所以你不想尝试全因子。**

**在文化模型中，用户将受控实验视为一种工具，我们倾向于简单和灵活。**

**如果你把实验者作为实验对象，就会发现许多有趣的认知偏见和错觉。你在一次演讲中提到了泰曼定律:“任何看起来有趣或不同的数字通常都是错误的”**

**你认为哪些认知偏见和错觉经常发生，如何克服它们？**

**最常见的偏见是接受好的结果，调查坏的结果。**

**如果一个实验改变了一些与收入无关的特性，但收入出乎意料地提高了，人们倾向于想出一些不成熟的解释并庆祝成功。相反，如果收入意外下降，实验者将倾向于声称“噪音”或试图找到一个大幅下降的细分市场并进行一些关联(例如，星期二是糟糕的，但这是我们有其他问题的一天，所以我们不能相信星期二)。**

**最好的数据科学家对两个方向的惊人结果都持怀疑态度。**

**一个常见的偏见是当实验具有统计学意义时就结束实验。在我最近在[conversation XL](http://bit.ly/ABPitfalls)幻灯片 20 上的陷阱演讲中，我注意到两本好的 A/B 测试[书](https://hackernoon.com/tagged/books)把程序搞错了。通过强迫实验者提前决定实验持续时间，并确保它是 7 的倍数(例如，一周或两周是常见的)，这种偏差很容易克服。**

**一个常见的偏见是认为表现不佳的新功能会受到首因效应的影响:用户只是习惯了旧的方式，需要时间来适应。有时，通过查看累积图很容易落入这个陷阱，这是我们在可信的在线控制实验中提出的一点:[解释了五个令人困惑的结果](http://bit.ly/expPuzzling)(3.3 节)。**

**一个特征由 stat-sig 阴性转为 stat-sig 阳性的情况极为罕见。大多数情况下，当负面结果没有改善时,“希望”会在一段时间后消失。**