# 调试偏差:质疑数字伦理

> 原文：<https://medium.com/hackernoon/ethics-in-programming-questions-we-need-to-ask-230dd4335bc1>

![](img/1aa08430436adbfee18cc2c152ca66e9.png)

对我们这些书呆子来说，曾经有过一段美好的时光。这是一次很好的演出。那群可爱的不适应者，聪明但被误解的书呆子有很多懈怠。我们犯错误的范围过去要小得多；在一个智能手机新奇、高速互联网奢侈的世界里，一个拙劣的发布或一个恶意程序只能造成如此大的损害。但是精灵溜走了。现在，科技迷们正受到来自四面八方的压力。不管喜欢与否，这些天我们有很多问题要回答。

利益集团、记者、业内人士和其他人开始关注我们令人担忧的多样性缺乏。他们开始注意到，当[算法根据你住在哪个街区](http://www.npr.org/2016/09/12/493654950/weapons-of-math-destruction-outlines-dangers-of-relying-on-data-analytics)来给东西定价时。当[警方面部识别数据库充满错误](http://www.npr.org/sections/alltechconsidered/2016/10/25/499176469/it-aint-me-babe-researchers-find-flaws-in-police-facial-recognition)、[过滤气泡强化你的认知偏见](http://www.theverge.com/2016/11/16/13653026/filter-bubble-facebook-election-eli-pariser-interview)、[聊天机器人了解到他们无法忘却的种族敌意](http://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist)、[社交网络成为不可过滤的宣传机器](http://motherboard.vice.com/read/how-hackers-broke-into-john-podesta-and-colin-powells-gmail-accounts)时，很难捍卫科技行业是良性和善意的观念。技术带来的潜在威胁不再是抽象的。

当你梦想使用技术创造一个更好、更公平、更公正的世界时，面对这个现实是不舒服的——我们的代码无意中带有种族主义色彩。

## **消除误解:有意还是无意的种族主义**

两条共同的线索将新闻媒体的当前主题联系在一起。一个是，由真实世界数据训练的无害的、高雅的算法正在产生可证明的种族主义结果(T2)。另一个观点是，背后的书呆子们不应该被放过:“[人工智能将反映其创造者的价值观](https://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html?_r=0)”

在我们开始解决不计后果地使用技术的问题之前，重要的是要区分无意的偏见，这些偏见可能会进入技术产品或服务，并利用技术平台进行种族主义。

人们将算法视为种族主义者，并认为它们生来就是如此。作为自由世界的公民，我们对种族不公正的权力体系有一种理性的恐惧，这已经与我们对自主的非人道统治者的恐惧相冲突。

然而，编程任何有效的东西都是困难的；将一个像种族主义这样复杂且具有文化地方性的概念建模成一个可预测但动态的算法是一项令人困惑的任务。追求它确实是道德上的荒谬。

这些算法不会以这种方式模拟行为。相反，一个众所周知的机器学习算法利用历史数据进行训练，以产生一个预测模型，然后该模型将继续对新的数据进行预测。与此类似的算法可能正在为您推荐搜索结果和交通路线。

偏见是如何进入科技领域的？我们需要问一些棘手的问题:

## **1。为什么我们看起来都一样？**

这真的没有帮助，它大多是高薪，大多是白人，大多是幕后的男人。那么，白人拿着牌有什么关系呢？关于这一点已经说了很多，但这是我的观点:我们对与我们不同的人了解得还不够。例如，我们不太可能有很多黑人朋友，我们可以用他们的照片来训练我们的机器人。我们可能不会觉得世界上有太多的不公平。我们不需要考虑它。

种族歧视的不是算法，而是我们收集的数据。从书呆子的角度来看，这是一个艰难的技术现实，“机器学习”并不是真正的“学习”——它是对数据的模式发现。如果你希望未来和过去很像，但是垃圾进来，垃圾出去，那么预测未来是很有用的；它没有给系统注入我们称之为“智能”的直觉、判断或谨慎我们有盲点，我们的工作反映了这一点。

## **2。为什么我们不关心老板在打什么主意？**

数字行业给你一种远离责任的感觉:许多程序员感觉工程世界和他们老板的所作所为之间有一种隔阂。因为软件是很难的，世界是复杂的，所以有必要专注于让你的代码工作。你可以建造一堵舒适的墙，将你的工作与外界隔离开来，专注于解决最具挑战性的问题，而不必后退一步，放眼全局。

## **3。我们的道德准则在哪里？**

创造者和使能者分离的问题是编程特有的吗？不。出于各种原因，许多古老的职业已经认识到，道德规范是弥合差距和维护职业诚信的必要条件。医生和律师都受到非常具体的道德准则的约束，违反这些准则可能会让你失业。工程专业人员通过桥梁倒塌、矿难和其他灾难了解到，他们的工作可能危及公共福利，应该遵守某种道德标准。

事实上，有一个组织推荐软件开发的道德准则，这对于许多程序员来说可能是新闻。对我来说是。计算机器协会不是一个在开发圈里响亮的名字，但是他们发布了一个软件开发的道德规范。它主要关注的是单个开发人员的行为，特别是在标准和测试方面，但是它确实建议开发人员不要“批准”软件，除非它“不会降低生活质量、减少隐私或损害环境”。这项工作的最终效果应该是对公众有益。”例如，建立一个有助于提出量刑建议的系统是否符合公共利益？如果它建议对黑人施以更严厉的惩罚呢？数字世界在这一道德标准上失败的时间已经够长了，不足以引起人们的注意。

要解开的东西太多了，但是为了开发人员社区的持续成功，必须解决这个问题。在本系列的后续文章中，我们将探索为什么在技术领域很难做到合乎道德，找出谁已经在努力使软件更加公平，并深入探讨如果你是当今的一名在职开发人员，你将会遇到的具体的道德问题，包括我们作为[HYFN](https://hyfn.com/)在技术领域绘制一条道德道路所做的事情。

![](img/ab2af5f0e0c1936edffbaa2aee4fa6c0.png)

HYFN 的首席技术官斯科特·伯顿

[![](img/50ef4044ecd4e250b5d50f368b775d38.png)](http://bit.ly/HackernoonFB)[![](img/979d9a46439d5aebbdcdca574e21dc81.png)](https://goo.gl/k7XYbx)[![](img/2930ba6bd2c12218fdbbf7e02c8746ff.png)](https://goo.gl/4ofytp)

> [黑客中午](http://bit.ly/Hackernoon)是黑客如何开始他们的下午。我们是 [@AMI](http://bit.ly/atAMIatAMI) 家庭的一员。我们现在[接受投稿](http://bit.ly/hackernoonsubmission)并乐意[讨论广告&赞助](mailto:partners@amipublications.com)机会。
> 
> 如果你喜欢这个故事，我们推荐你阅读我们的[最新科技故事](http://bit.ly/hackernoonlatestt)和[趋势科技故事](https://hackernoon.com/trending)。直到下一次，不要把世界的现实想当然！

![](img/be0ca55ba73a573dce11effb2ee80d56.png)