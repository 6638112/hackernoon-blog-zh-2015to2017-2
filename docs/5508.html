<html>
<head>
<title>The problems with DynamoDB Auto Scaling and how it might be improved</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DynamoDB自动缩放的问题以及如何改进</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/the-problems-with-dynamodb-auto-scaling-and-how-it-might-be-improved-a92029c8c10b?source=collection_archive---------1-----------------------#2017-07-31">https://medium.com/hackernoon/the-problems-with-dynamodb-auto-scaling-and-how-it-might-be-improved-a92029c8c10b?source=collection_archive---------1-----------------------#2017-07-31</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="9bf3" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">AWS宣布了期待已久的DynamoDB自动扩展功能，但我们发现它需要太长的时间来扩展，并且扩展不够积极，因为它通过使用消耗的容量而不是实际的请求数作为扩展指标。</h2></div><p id="fa12" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在<a class="ae kf" href="http://spaceapegames.com/" rel="noopener ugc nofollow" target="_blank"> Space Ape Games </a>这里，我们开发了一项内部技术来自动扩展DynamoDB吞吐量，并在生产中成功使用了几年。它甚至与我们的<a class="ae kf" href="https://www.youtube.com/watch?v=zywAS1NB9V4" rel="noopener ugc nofollow" target="_blank"> LiveOps </a>工具相集成，并根据现场活动的时间表扩展我们的DynamoDB表。这样，我们的表总是在事件开始时不可避免的流量高峰之前提供。</p><figure class="kg kh ki kj fq kk"><div class="bz el l di"><div class="kl km l"/></div></figure><p id="3bc1" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">自动伸缩DynamoDB是AWS客户的一个常见问题，我在之前的两家公司亲自实现了类似的技术来处理这个问题。在Yubl的时候，我甚至把同样的技术应用到了<a class="ae kf" href="https://read.acloud.guru/auto-scaling-kinesis-streams-with-aws-lambda-299f9a0512da" rel="noopener ugc nofollow" target="_blank">的自动缩放动作流</a>上。</p><p id="2c4f" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">当AWS <a class="ae kf" href="https://aws.amazon.com/about-aws/whats-new/2017/06/announcing-amazon-dynamodb-auto-scaling/" rel="noopener ugc nofollow" target="_blank">宣布DynamoDB自动缩放</a>时，我们非常兴奋。然而，伴随公告的<a class="ae kf" href="https://aws.amazon.com/blogs/aws/new-auto-scaling-for-amazon-dynamodb/" rel="noopener ugc nofollow" target="_blank">博客文章</a>说明了两个问题:</p><ul class=""><li id="a309" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ks kt ku kv dt translated">扩大规模的反应时间很慢(10-15分钟)</li><li id="4dd0" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">它的规模不足以维持70%的利用率水平</li></ul><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div class="fe ff lb"><img src="../Images/60bb69160fd184452ed027e548aaf426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*SRJsrZGhS17eL3pxsmtPBw.png"/></div><figcaption class="le lf fg fe ff lg lh bd b be z ek">Notice the high no. of throttled operations despite the scaling activity. If you were scaling the table manually, would you have settled for this result?</figcaption></figure><p id="fe87" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">看起来作者的测试并不符合DynamoDB Auto Scaling旨在适应的工作负载类型:</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff li"><img src="../Images/68ec0e9108e2664729e4f900444688e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TIrTdD04LJ_uhjYFT3FDGA.png"/></div></div></figure><p id="5b67" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在我们的例子中，我们也有一个很高的读写比率(通常在1:1左右)，因为玩家在游戏中执行的每个动作都会以某种方式改变他们的状态。所以不幸的是，我们不能把DAX作为一张免罪卡。</p><h1 id="1029" class="ln lo hu bd lp lq lr ls lt lu lv lw lx ja ly jb lz jd ma je mb jg mc jh md me dt translated">DynamoDB自动缩放的工作原理</h1><p id="d3ba" class="pw-post-body-paragraph jj jk hu jl b jm mf iv jo jp mg iy jr js mh ju jv jw mi jy jz ka mj kc kd ke hn dt translated">当您修改表的读取或写入吞吐量的自动缩放设置时，它会自动为该表创建/更新CloudWatch警报—四个用于写入，四个用于读取。</p><p id="9b60" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">从下面的截图可以看出，DynamoDB自动缩放使用CloudWatch警报来触发缩放操作。当消耗的容量单位连续5分钟超过表中的利用率级别(默认为70%)时，它将按比例增加相应调配的容量单位。</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff mk"><img src="../Images/3562f83441d643121f94d29659cc0870.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TyNzN4uR-6SyaLrRUCjidA.png"/></div></div></figure><h1 id="f802" class="ln lo hu bd lp lq lr ls lt lu lv lw lx ja ly jb lz jd ma je mb jg mc jh md me dt translated">当前系统的问题，以及如何改进</h1><p id="0bc4" class="pw-post-body-paragraph jj jk hu jl b jm mf iv jo jp mg iy jr js mh ju jv jw mi jy jz ka mj kc kd ke hn dt translated">从我们自己的测试中，我们发现DynamoDB在扩展时表现平平，这源于两个问题:</p><ol class=""><li id="778b" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ml kt ku kv dt translated">CloudWatch警报需要连续5次阈值突破。当您考虑到CloudWatch指标中的延迟(通常落后几分钟)时，这意味着在首次突破指定利用率级别后的10分钟内会发生<strong class="jl hv">扩展操作</strong>。这个反应时间太慢了。</li><li id="1f1d" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated"><strong class="jl hv">新供应的容量单位是根据消耗的容量单位计算的，而不是根据实际请求数</strong>计算的。消耗的容量单位本身受到供应的容量单位的限制，即使有可能通过<a class="ae kf" href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GuidelinesForTables.html#GuidelinesForTables.Bursting" rel="noopener ugc nofollow" target="_blank">突发容量</a>暂时超过供应的容量单位。这意味着，一旦您用尽了节省的突发容量，实际请求数量可能会开始超过消耗的容量单位，而扩展无法跟上实际请求数量的增长。稍后我们将在控制组的结果中看到这种影响。</li></ol><p id="c754" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">基于这些观察，我们假设您可以对系统进行两项修改以提高其有效性:</p><ol class=""><li id="6802" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ml kt ku kv dt translated">在1次阈值突破后触发扩大，而不是5次，这符合<strong class="jl hv">“早扩大，慢缩小”</strong>的口头禅。</li><li id="2a35" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated"><strong class="jl hv">根据实际请求数</strong>而不是消耗的容量单位触发扩展活动，并使用实际请求数计算新供应的容量单位。</li></ol><p id="fe60" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">作为这个实验的一部分，我们还原型化了这些变化(通过劫持CloudWatch警报)来展示它们的改进。</p><h1 id="cc61" class="ln lo hu bd lp lq lr ls lt lu lv lw lx ja ly jb lz jd ma je mb jg mc jh md me dt translated">测试方法</h1><p id="70f7" class="pw-post-body-paragraph jj jk hu jl b jm mf iv jo jp mg iy jr js mh ju jv jw mi jy jz ka mj kc kd ke hn dt translated">该测试最重要的事情是以一种<strong class="jl hv">可靠的</strong>和<strong class="jl hv">可再现的</strong>方式生成期望的流量模式。</p><p id="f872" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">为了做到这一点，我们有一个递归函数，它将每秒钟对测试中的DynamoDB表发出<code class="eh mm mn mo mp b">BatchWrite</code>请求。每秒项目速率是基于以秒为单位的运行时间(<code class="eh mm mn mo mp b">t</code>)计算的，因此它为我们提供了很大的灵活性来形成我们想要的流量模式。</p><p id="149a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">由于Lambda函数最多只能运行5分钟，当<code class="eh mm mn mo mp b">context.getRemainingTimeInMillis()</code>小于2000时，该函数将递归并传递有效负载中最后记录的运行时间(<code class="eh mm mn mo mp b">t</code>)以供下次调用。</p><p id="96d8" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">其结果是一个连续的，顺利的交通模式，你看到如下。</p><p id="f146" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我们测试了我们经常看到的两种流量模式。</p><h2 id="45ee" class="mq lo hu bd lp mr ms mt lt mu mv mw lx js mx my lz jw mz na mb ka nb nc md nd dt translated">钟形曲线</h2><p id="1fed" class="pw-post-body-paragraph jj jk hu jl b jm mf iv jo jp mg iy jr js mh ju jv jw mi jy jz ka mj kc kd ke hn dt translated">对于大多数人来说，这应该是一种熟悉的流量模式——流量从低谷到高峰缓慢而稳定地增长，然后随着用户进入睡眠状态而快速下降。经过一夜稳定的交通之后，第二天情况又开始好转。</p><p id="6f2b" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">对于我们中许多用户群集中在北美地区的人来说，高峰通常在英国时间凌晨3-4点左右——我们更需要<em class="ne"> DynamoDB Auto Scaling </em>来完成它的工作，而不是吵醒我们！</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nf"><img src="../Images/d53166b411b6611d743e0f1154fde533.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dK4g2q4zWCq2CKfFuq7SuA.png"/></div></div><figcaption class="le lf fg fe ff lg lh bd b be z ek">This traffic pattern is characterised by a) steady traffic at the trough, b) slow &amp; steady build up towards the peak, c) fast drop off towards the trough, and repeat.</figcaption></figure><h2 id="192e" class="mq lo hu bd lp mr ms mt lt mu mv mw lx js mx my lz jw mz na mb ka nb nc md nd dt translated">头重</h2><p id="ae6b" class="pw-post-body-paragraph jj jk hu jl b jm mf iv jo jp mg iy jr js mh ju jv jw mi jy jz ka mj kc kd ke hn dt translated">这种流量的突然爆发通常是由一个事件促成的——营销活动、应用程序商店的促销，或者在我们的情况下，是一个预定的LiveOps活动。</p><p id="899c" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在大多数情况下，这些事件是可预测的，我们通过自动化工具提前扩展DynamoDB表。然而，在意外流量突发的情况下(这种情况在我们身上发生过几次),一个好的<strong class="jl hv"><em class="ne"/></strong>自动缩放系统应该快速而积极地扩展，以最大限度地减少对我们玩家的干扰。</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff ng"><img src="../Images/f5459217197f9ad745baf37c52b37fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QSKq4B8JC11luR265tjKyQ.png"/></div></div><figcaption class="le lf fg fe ff lg lh bd b be z ek">This pattern is characterised by a) sharp climb in traffic, b) a slow &amp; steady decline, c) stay at a stead level until the anomaly finishes and it goes back to the Bell Curve again.</figcaption></figure><p id="8963" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我们根据几个<code class="eh mm mn mo mp b">utilization level</code>设置(默认为70%)测试了这些流量模式，看看它是如何处理它们的。我们通过以下方式衡量系统的性能:</p><ul class=""><li id="b672" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ks kt ku kv dt translated">成功请求的百分比(即消耗的容量/请求数)</li><li id="1432" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">测试期间被抑制的请求总数</li></ul><p id="2d3c" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">这些结果将作为我们的对照组。</p><p id="788e" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">然后，我们针对我们在上面提出的两个假设的自动缩放变化测试了相同的流量模式。</p><p id="4f9b" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">为了对提议的更改进行原型化，我们劫持了由DynamoDB auto scaling使用CloudWatch事件创建的CloudWatch警报。</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nh"><img src="../Images/8574e2701c12063ac6e3644a4d86ad02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qkiZBJRb-JPAa0xKLhPotg.png"/></div></div></figure><p id="7a07" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">当进行一个<code class="eh mm mn mo mp b">PutMetricAlarm</code> API调用时，我们的<code class="eh mm mn mo mp b">change_cw_alarm</code>函数被调用，并用相关的更改替换现有的CloudWatch警报——即。对于假设1，将<code class="eh mm mn mo mp b">EvaluationPeriods</code>设置为1分钟。</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff ni"><img src="../Images/a2f6bb2a855754ed792da0ec9d42f81b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oMCuiUZf4ZF2uD7JyyvIjw.png"/></div></div><figcaption class="le lf fg fe ff lg lh bd b be z ek">To avoid an invocation loop, the Lambda function will only make changes to the CloudWatch alarm if the EvaluationPeriod has not been changed to 1 min already.</figcaption></figure><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nj"><img src="../Images/043b7d5836df15d4744d5093f2ed5b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zhlTBUgKnZeAh9HCveodqw.png"/></div></div><figcaption class="le lf fg fe ff lg lh bd b be z ek">The change_cw_alarm function changed the breach threshold for the CloudWatch alarms to 1 min.</figcaption></figure><p id="fd35" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">对于假设2，我们必须接管扩展表的责任，因为我们需要使用跟踪实际请求数的自定义指标来计算新调配的容量单位。因此，为什么CloudWatch警报的<code class="eh mm mn mo mp b">AlarmActions</code>在这里也被覆盖了。</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nk"><img src="../Images/8777da6f64117c141471c5b3e1bda36c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kPPCTPJF7czMB91q5R-tfA.png"/></div></div><figcaption class="le lf fg fe ff lg lh bd b be z ek">The SNS topic is subscribed to a Lambda function which scales up the throughput of the table.</figcaption></figure><h1 id="38da" class="ln lo hu bd lp lq lr ls lt lu lv lw lx ja ly jb lz jd ma je mb jg mc jh md me dt translated">结果(钟形曲线)</h1><p id="35c8" class="pw-post-body-paragraph jj jk hu jl b jm mf iv jo jp mg iy jr js mh ju jv jw mi jy jz ka mj kc kd ke hn dt translated">测试设置如下:</p><ol class=""><li id="f381" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ml kt ku kv dt translated">表格从50个写容量单位开始</li><li id="85e9" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">流量以每秒25次写入的速度稳定保持15分钟</li><li id="e4f9" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">然后，在接下来的45分钟内，流量以稳定的速率增加到峰值水平(每秒300次写入)</li><li id="85d9" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">在接下来的15分钟内，流量以稳定的速度回落到25次写入/秒</li><li id="75d9" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">流量稳定在每秒25次写入</li></ol><p id="b235" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">图中所有的单位都是SUM/min，这是CloudWatch跟踪<code class="eh mm mn mo mp b">ConsumedWriteCapacityUnits</code>和<code class="eh mm mn mo mp b">WriteThrottleEvents</code>的方式，但我必须将<code class="eh mm mn mo mp b">ProvisionedWriteCapacityUnits</code>(按秒单位跟踪)标准化，以使它们保持一致。</p><p id="331f" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">让我们先来看看对照组(vanilla DynamoDB auto scaling)在30%到80%的不同利用率水平下的表现。</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nj"><img src="../Images/51eee13d91271afb51cc2386d8acb82e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rpdctBDI-7ejyyLoke7iFQ.png"/></div></div></figure><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nl"><img src="../Images/ca72bf6e7fee53927c60aff5f24d5a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZYWuJAKikVDuWjOsSLai1A.png"/></div></div><figcaption class="le lf fg fe ff lg lh bd b be z ek">I’m not sure why the <code class="eh mm mn mo mp b">total consumed units</code> and <code class="eh mm mn mo mp b">total request count</code> metrics didn’t match exactly when the utilization is between 30% and 50%, but seeing as there were no throttled events I’m going to put that difference down to inaccuracies in CloudWatch.</figcaption></figure><p id="ac21" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我从这些结果中得出几点看法:</p><ol class=""><li id="4592" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ml kt ku kv dt translated">在30%-50%的利用率级别，写操作永远不会受到限制，这是我们希望在生产中看到的。</li><li id="251f" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">在60%的利用率级别，缓慢的反应时间(问题1)导致写入在系统调整以适应负载稳定增长的早期受到抑制，但它最终能够适应。</li><li id="27d5" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">在70%和80%的利用率水平，事情真的分崩离析。实际请求数量的增长超过了消耗的容量单位的增长，越来越多的写操作受到抑制，因为系统无法适应新水平的<strong class="jl hv">实际利用率</strong>(与按消耗的容量单位衡量的<em class="ne">“允许”</em>利用率相反，即问题2)。</li></ol><h2 id="d830" class="mq lo hu bd lp mr ms mt lt mu mv mw lx js mx my lz jw mz na mb ka nb nc md nd dt translated">假设1:1分钟破裂后的缩放</h2><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nj"><img src="../Images/cc906418cb48ffd1ce557ae1f06374bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LVSH2dlZj3gNv5LEyVct5Q.png"/></div></div></figure><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nh"><img src="../Images/020af80e6cfea4b30b1116a3297a3f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KYKqThy_lPS98sfkUrgr-g.png"/></div></div></figure><p id="7200" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">一些观察结果:</p><ol class=""><li id="e4f2" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ml kt ku kv dt translated">在30%-50%的利用率水平下，性能没有差别。</li><li id="6643" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">在60%的利用率级别，我们在控制组中看到的早期限制写入现在得到了解决，因为我们缩短了系统的反应时间。</li><li id="5702" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">在70%-80%的利用率水平下，性能差异可以忽略不计。这是预料之中的，因为对照组中的不良表现是由问题2引起的，所以在这些情况下，仅仅提高反应时间不可能显著提高表现。</li></ol><h2 id="cc4a" class="mq lo hu bd lp mr ms mt lt mu mv mw lx js mx my lz jw mz na mb ka nb nc md nd dt translated">假设2:违反实际请求计数1分钟后进行缩放</h2><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nj"><img src="../Images/e62efbe2f9e9a5f937bc9543c190851b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dx2Fsl_1ow-6gqD8Pyut0A.png"/></div></div></figure><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nm"><img src="../Images/881c52db412a3fb24fc419e663957142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YnLAYQf0J_VkJQjmwTiekA.png"/></div></div></figure><p id="ff8a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">根据实际请求数进行扩展，并使用实际请求数来计算新调配的容量单位，会产生惊人的结果。在30%-70%的利用率水平上，没有<strong class="jl hv">节流事件</strong>。</p><p id="6bf6" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">即使在80%的利用率水平下,<code class="eh mm mn mo mp b">success rate</code>和节流事件的总数都有显著提高。</p><p id="8953" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">对于自动伸缩系统来说，这是一个可以接受的性能水平，我很乐意在生产环境中使用。尽管如此，我还是倾向于谨慎，选择70%或更低的利用率水平，以便为表提供足够的空间来处理流量的突然增加。</p><h1 id="0f62" class="ln lo hu bd lp lq lr ls lt lu lv lw lx ja ly jb lz jd ma je mb jg mc jh md me dt translated">结果(头重脚轻)</h1><p id="5d12" class="pw-post-body-paragraph jj jk hu jl b jm mf iv jo jp mg iy jr js mh ju jv jw mi jy jz ka mj kc kd ke hn dt translated">测试设置如下:</p><ol class=""><li id="b970" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ml kt ku kv dt translated">表格从50个写容量单位开始</li><li id="2a2b" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">流量以每秒25次写入的速度稳定保持15分钟</li><li id="f393" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">然后，在接下来的5分钟内，流量以稳定的速率跃升至峰值水平(每秒300次写入)</li><li id="53a9" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">然后，流量以每分钟3次写入/秒的速度下降</li></ol><p id="ca33" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">同样，让我们先来看看控制组(vanilla DynamoDB auto scaling)在不同利用率水平下的性能。</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nj"><img src="../Images/d8eb20b3ff8c29d760ffd8ef222876cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJbTmKBtFo8cqm01eDm58Q.png"/></div></div></figure><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nn"><img src="../Images/204ffe735781549652ae634399a85bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8U55z9cWunqFG_oha4_nwg.png"/></div></div></figure><p id="19dd" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">以上结果的一些观察结果:</p><ol class=""><li id="222b" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ml kt ku kv dt translated">在30%-60%的利用率水平下，大多数受抑制的写入可归因于缓慢的反应时间(问题1)。一旦该表开始扩大，受限制的写入数量就会迅速减少。</li><li id="e239" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">在70%-80%的利用率水平上，系统也没有足够积极地扩展(问题2)。因此，我们经历了更长时间的限制写入，导致整体性能更差。</li></ol><h2 id="befd" class="mq lo hu bd lp mr ms mt lt mu mv mw lx js mx my lz jw mz na mb ka nb nc md nd dt translated">假设1:1分钟破裂后的缩放</h2><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nj"><img src="../Images/7d5671a2d3e410665ad9a5a02a02341c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WPjOtf9v0TT0O4Cu5M1s1Q.png"/></div></div></figure><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff no"><img src="../Images/2fd2db02d741cab4c92a833f87d5a17e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IkcDryggYcWJRueakLkzaA.png"/></div></div></figure><p id="87c8" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">一些观察结果:</p><ol class=""><li id="aff8" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ml kt ku kv dt translated">总体而言，性能有所提高，尤其是在30%-60%的利用率水平上。</li><li id="a416" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ml kt ku kv dt translated">在70%-80%的利用率水平上，我们仍然会看到问题2的影响—扩展不够积极。因此，受限制的写操作仍然有一条长长的尾巴。</li></ol><h2 id="46bd" class="mq lo hu bd lp mr ms mt lt mu mv mw lx js mx my lz jw mz na mb ka nb nc md nd dt translated">假设2:违反实际请求计数1分钟后进行缩放</h2><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nj"><img src="../Images/3335f5b24aa842b1dcc000d2352ab69d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r33Dlr1E9HlknxP5XvGRgw.png"/></div></div></figure><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff nh"><img src="../Images/3a92a06f33eb238b737acee46c25ee8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_r6weAZR5RsrgF5XvrrLGw.png"/></div></div></figure><p id="0221" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">与我们在<em class="ne">钟形曲线</em>流量模式中观察到的情况类似，这种实施方式在处理所有测试的利用率级别的流量突发峰值方面明显更好。</p><p id="12dc" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">即使在80%的利用率水平下(这实际上并没有给你留下太多的空间)，也有94%的写操作成功(相比之下，控制组记录的是73%)。虽然仍然有大量的节流事件，但与vanilla DynamoDB自动缩放记录的500k+计数相比，这是有利的。</p><h1 id="64dd" class="ln lo hu bd lp lq lr ls lt lu lv lw lx ja ly jb lz jd ma je mb jg mc jh md me dt translated">结论</h1><p id="9737" class="pw-post-body-paragraph jj jk hu jl b jm mf iv jo jp mg iy jr js mh ju jv jw mi jy jz ka mj kc kd ke hn dt translated">我喜欢DynamoDB，我想使用它的开箱即用的自动伸缩功能，但它并不完全符合我目前的期望。我希望AWS的人正在阅读这篇文章，这篇文章提供了足够的证据(正如你从下面的数据中看到的),它可以通过相对较小的变化得到极大的改善。</p><figure class="kg kh ki kj fq kk fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff np"><img src="../Images/09da60fa682cfb137b7229f6dc6823aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JI5Mnuf84BtifjlCsU53Cw.png"/></div></div></figure><p id="02e7" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">你可以随意玩这个演示，所有的代码都可以在<a class="ae kf" href="https://github.com/theburningmonk/better-dynamodb-scaling" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><div class="nq nr fm fo ns nt"><a href="https://github.com/theburningmonk/better-dynamodb-scaling" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab ej"><div class="nv ab nw cl cj nx"><h2 class="bd hv fv z el ny eo ep nz er et ht dt translated">燃烧monk/better-dynamodb-scaling</h2><div class="oa l"><h3 class="bd b fv z el ny eo ep nz er et ek translated">更好的-dynamodb-缩放-使dynamo db的自动缩放动作发生得更快</h3></div><div class="ob l"><p class="bd b gc z el ny eo ep nz er et ek translated">github.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh lc nt"/></div></div></a></div></div><div class="ab cl oi oj hc ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="hn ho hp hq hr"><p id="0963" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">喜欢你正在读的东西吗？查看我的视频课程<a class="ae kf" href="https://bit.ly/prod-ready-serverless" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hv">生产就绪无服务器</strong> </a>，学习如何在生产中运行无服务器应用。</p><p id="072d" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我们将讨论的主题包括:</p><ul class=""><li id="0ffa" class="kn ko hu jl b jm jn jp jq js kp jw kq ka kr ke ks kt ku kv dt translated">使用API网关和Cognito进行身份验证和授权</li><li id="4f2f" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">在本地测试和运行功能</li><li id="28bc" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">项目组织策略</li><li id="16b4" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">CI/CD</li><li id="d586" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">集中伐木</li><li id="e72b" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">监视</li><li id="a85b" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">X射线分布式跟踪</li><li id="5115" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">跟踪相关id</li><li id="5cf3" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">性能和成本优化</li><li id="c88e" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">错误处理</li><li id="0e03" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">配置管理</li><li id="723e" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">金丝雀部署</li><li id="81f2" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">VPC</li><li id="8aec" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">安全</li><li id="a7db" class="kn ko hu jl b jm kw jp kx js ky jw kz ka la ke ks kt ku kv dt translated">Lambda、Kinesis和API网关的最佳实践</li></ul><p id="9465" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">并包括在最近的AWS re:Invent大会上宣布的所有最新变化！</p><div class="nq nr fm fo ns nt"><a href="https://bit.ly/prod-ready-serverless" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab ej"><div class="nv ab nw cl cj nx"><h2 class="bd hv fv z el ny eo ep nz er et ht dt translated">生产就绪无服务器</h2><div class="oa l"><h3 class="bd b fv z el ny eo ep nz er et ek translated">看到了。动手吧。学着点！生产就绪无服务器:运营最佳实践向您介绍领先的模式和…</h3></div><div class="ob l"><p class="bd b gc z el ny eo ep nz er et ek translated">bit.ly</p></div></div><div class="oc l"><div class="op l oe of og oc oh lc nt"/></div></div></a></div></div></div>    
</body>
</html>