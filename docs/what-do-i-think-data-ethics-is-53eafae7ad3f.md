# 我认为数据伦理是什么？

> 原文：<https://medium.com/hackernoon/what-do-i-think-data-ethics-is-53eafae7ad3f>

![](img/3b62b6770ebe30f7090bbd2969c68848.png)

[https://techcrunch.com/2016/11/12/data-ethics-the-new-competitive-advantage/](https://techcrunch.com/2016/11/12/data-ethics-the-new-competitive-advantage/)

# 背景

我已经花了相当多的时间阅读了关于伦理、数据、人工智能、算法、自动化等各种不同的观点，但我还没有探索到底什么是我认为的数据伦理。我还没有一个明确的想法。

我是在做 [Udacity 深度学习纳米学位](https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101)的时候逐渐接触到这个领域的。“深度学习”是机器学习的一种形式，它有多层通过权重连接的计算“神经元”。通过一个学习过程，模型在成百上千个权重中调整其权重。随着时间的推移，模型“学会”更准确地将输入映射到输出。挺神奇的！如果你看一下 [ArXiv](https://arxiv.org/list/cs/new) ，你可以看到每天*在这个领域持续的——势不可挡的——进步！*

神经网络不容易理解，也不容易编程。正是在这个弄清楚如何创建这些模型的过程中，我意识到我不知道*为什么*模型能够将图像转换成正确的标签。我理解它用来获得输入的更好表示的过程——反向传播[——这是有意义的。然而，如果你问我一张图片的某个方面是如何或为什么与某个标签最相关，那么我只能耸耸肩。](https://en.wikipedia.org/wiki/Backpropagation)

也就是说，有一些技术[可以更好地可视化这些深度学习](http://yosinski.com/deepvis)[模型中正在发生的事情，这有助于了解正在发生的事情；但是我仍然认为这还不够——特别是当这些模型中的一个被用来影响一个人生活的结果的时候。](https://hackernoon.com/tagged/learning)

我在课程论坛上问了无数的问题，但得到的回答都不是很令人满意。随着课程转向更深奥的模型，如[循环神经网络](https://en.wikipedia.org/wiki/Recurrent_neural_network)和[对抗网络](https://en.wikipedia.org/wiki/Generative_adversarial_networks)，我不得不抽出时间考虑我实际上在看什么。我想要一个[的叙述](https://www.linkedin.com/pulse/coding-literature-paul-hunt)到*向我解释*这些模型是关于什么的——我们为什么要这么做？它们解决什么问题？什么*是*的问题？

我的下一个逻辑跳跃是考虑不仅仅是深度神经网络的含义，而是整个人工智能领域——以各种形式。现在，我并不接受有意识的机器或任何东西的想法…我只是在谈论“智能”，它允许计算机模型在人类无法比拟的规模上识别数据模式。仅此而已！围绕自主机器人的讨论虽然有趣，但并不是我真正关心的问题。

因此，我不再试图理解这些神经网络的技术细节——即 Python 代码，或[tensor flow](https://www.tensorflow.org/)API——而是开始关注社会影响。

# 数据管道

我认为数据是有生命的东西。它只是*在那里*在大规模数据库中收集，并通过 API 存储或公开。在许多情况下，它只是人们使用各种在线平台收集的副产品。它是元数据，它是事务性数据，它缺乏上下文。然后某个人——或者某个组织——整理数据，并[以一种适合在深度学习模型中使用的方式对其进行转化](https://en.wikipedia.org/wiki/Data_wrangling)。本质上，这个问题需要以一种可以通过权重和激活函数来操作的方式被“数字化”。该模型然后吐出更多的数据——现在有了一些背景。这些数据为决策提供信息，导致其他一些自动化过程，甚至可以通过模型进行反馈，以改善其学习。

然而，在从输入到输出，再到商业决策的过程中，需要许多人为干预。一个人(在下面我也指‘人’)需要决定如何将一个业务问题转换成适合模型的形式；一个人需要运行代码，以系统的方式将数据转换成模型；一个人需要‘训练’模型；然后，一个人需要在更广泛的商业背景下适应决策模型；一个人需要对模型的输出采取行动。在这些步骤中的任何一步，都可能会出现意想不到的错误或偏差。

本质上，有很多地方需要退后一步，关注实际发生的事情。我们当然不能想当然地认为模型会产生可靠或准确的输出。我们可以*希望*上面的模型和所有过程都是精心制定的…但是我们怎么能确定呢？

# 政府机关彼此之间的相互制衡

考虑到所有这些，我想我可以说我对数据伦理的理解是，我们需要一种[结构化方法](https://standards.ieee.org/develop/indconn/ec/autonomous_systems.html)来收集、使用数据并做出决策。我认为我们需要一种方法来检查和反复检查我们的假设，并有一个过程来保持我们的价值观——而不是简单地将我们的责任委托给一个算法。我们需要负责任。

由于该领域发展如此迅速，这些模型的影响范围只会越来越大。当我们考虑收集大量数据并需要做出“严肃”决策的所有地方时，例如移民、医疗保健和教育，我们肯定希望获得计算机的优势，但不能以不了解正在发生的事情为代价。*假设*一个模型的输出是正确的并不那么简单……而且相信我们可以构建一个包罗万象的模型来处理现实的混乱，这无疑是乐观的。

我想参与这个领域的标准和最佳实践的开发。我不希望事情在这个领域有自己的生命——一种由错误信息或缺乏理解而产生的惯性。但这些对我来说都是还在成型的想法。

[![](img/50ef4044ecd4e250b5d50f368b775d38.png)](http://bit.ly/HackernoonFB)[![](img/979d9a46439d5aebbdcdca574e21dc81.png)](https://goo.gl/k7XYbx)[![](img/2930ba6bd2c12218fdbbf7e02c8746ff.png)](https://goo.gl/4ofytp)

> [黑客中午](http://bit.ly/Hackernoon)是黑客如何开始他们的下午。我们是 [@AMI](http://bit.ly/atAMIatAMI) 家庭的一员。我们现在[接受投稿](http://bit.ly/hackernoonsubmission)并乐意[讨论广告&赞助](mailto:partners@amipublications.com)机会。
> 
> 如果你喜欢这个故事，我们推荐你阅读我们的[最新科技故事](http://bit.ly/hackernoonlatestt)和[趋势科技故事](https://hackernoon.com/trending)。直到下一次，不要把世界的现实想当然！

![](img/be0ca55ba73a573dce11effb2ee80d56.png)