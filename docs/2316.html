<html>
<head>
<title>Use your eyes and Deep Learning to command your computer — A.I. Odyssey part. 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用你的眼睛和深度学习来指挥你的电脑——人工智能奥德赛部分。2</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/talk-to-you-computer-with-you-eyes-and-deep-learning-a-i-odyssey-part-2-7d3405ab8be1?source=collection_archive---------4-----------------------#2017-01-19">https://medium.com/hackernoon/talk-to-you-computer-with-you-eyes-and-deep-learning-a-i-odyssey-part-2-7d3405ab8be1?source=collection_archive---------4-----------------------#2017-01-19</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><figure class="ht hu fm fo hv hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff hs"><img src="../Images/2bb91be5ea1c3a244a2ff3dd619b8697.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*6hKDvXF8rb_hIfQifdRP6Q.gif"/></div></div><figcaption class="id ie fg fe ff if ig bd b be z ek">What we’re going to build!</figcaption></figure><div class=""/><p id="e430" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">这一集:人脸检测，循环神经网络和更多。<br/> <em class="ke">确保检查出</em> <strong class="ji ik"> <em class="ke"> </em> </strong> <a class="ae kf" rel="noopener" href="/@juliendespois/finding-the-genre-of-a-song-with-deep-learning-da8f59a61194#.r28dkpg2e"> <strong class="ji ik"> <em class="ke">部分。1</em></strong></a><strong class="ji ik"><em class="ke"/></strong><em class="ke">太！</em></p><blockquote class="kg kh ki"><p id="5606" class="jg jh ke ji b jj jk jl jm jn jo jp jq kj js jt ju kk jw jx jy kl ka kb kc kd hn dt translated"><strong class="ji ik"> <em class="ij">如果你喜欢人工智能，</em> </strong> <a class="ae kf" href="http://eepurl.com/cATXvT" rel="noopener ugc nofollow" target="_blank"> <strong class="ji ik"> <em class="ij">订阅时事通讯</em> </strong> </a> <strong class="ji ik"> <em class="ij">接收文章更新等等！</em> </strong></p></blockquote><p id="01cb" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">你有没有发现自己在吃东西，却没有空闲的手来改变电影的音量？还是屏幕的亮度？我们将看到如何使用最先进的人工智能技术来解决这个问题，通过眼睛运动向计算机发送命令！</p><p id="6669" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated"><strong class="ji ik"> <em class="ke">注:</em> </strong> <em class="ke">看完这些，我邀请你去读一下</em> <a class="ae kf" rel="noopener" href="/@juliendespois/a-i-odyssey-part-2-implementation-details-f126f18bd320#.t4gpenon3"> <em class="ke">后续的帖子</em> </a> <em class="ke">专用于实现细节。</em></p></div><div class="ab cl km kn hc ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hn ho hp hq hr"><h1 id="6d99" class="kt ku ij bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq dt translated">介绍</h1><h2 id="b0b4" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">我们想要什么</h2><p id="324b" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">这个项目的目标是用我们的眼睛在我们的电脑上触发动作。这是一个非常普遍的问题，所以我们需要指定<em class="ke">我们想要实现什么</em>。</p><p id="776e" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">例如，我们可以检测眼睛何时看向某个特定的角落，然后据此进行工作。然而，这是非常有限的，并不真正灵活，而且它需要我们硬编码的角落组合。相反，我们将使用<strong class="ji ik">递归神经网络</strong>来学习识别完整的眼球运动。</p><h2 id="290b" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">数据</h2><p id="8aa4" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">我们不会使用外部数据集，<em class="ke">我们将制作自己的</em>。这具有使用相同的源和处理来训练模型和进行预测的优点。</p><p id="8748" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">毫无疑问，从我们的眼睛中提取信息的最有效的方法是使用专用的特写镜头摄像机。有了这样的硬件，我们可以直接追踪瞳孔的中心，做各种新奇的事情。</p><p id="98f2" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我不想使用外部摄像头，所以我决定使用笔记本电脑上的好的<em class="ke">旧的720p网络摄像头</em>。</p><h2 id="680a" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">管道</h2><p id="529f" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">在我们直接跳到技术方面之前，让我们回顾一下这个过程的步骤。这是我想到的管道:</p><ul class=""><li id="ca86" class="mk ml ij ji b jj jk jn jo jr mm jv mn jz mo kd mp mq mr ms dt translated">用网络摄像头拍照，找到眼睛</li><li id="1a8d" class="mk ml ij ji b jj mt jn mu jr mv jv mw jz mx kd mp mq mr ms dt translated">对图像进行预处理，提取重要特征<em class="ke">(你说神经网络？)</em></li><li id="3bf1" class="mk ml ij ji b jj mt jn mu jr mv jv mw jz mx kd mp mq mr ms dt translated">保持最近几帧提取特征的运行历史</li><li id="0e10" class="mk ml ij ji b jj mt jn mu jr mv jv mw jz mx kd mp mq mr ms dt translated">基于历史预测当前的眼球运动</li></ul><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff my"><img src="../Images/9a89397745469fe6343d63d64f63b4e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d24jbD_j3iTOys3lpgrcnA.png"/></div></div><figcaption class="id ie fg fe ff if ig bd b be z ek">The pipeline we will use to process the images</figcaption></figure><p id="6b51" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我们将通过这些步骤来看看我们如何使这个工作。</p><p id="6db2" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated"><strong class="ji ik"> <em class="ke">言归正传！</em> </strong></p><h1 id="10c0" class="kt ku ij bd kv kw nd ky kz la ne lc ld le nf lg lh li ng lk ll lm nh lo lp lq dt translated">得到眼睛的照片</h1><h2 id="128a" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">寻找眼睛</h2><p id="e969" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">直接从网络摄像头，我们开始下降采样图像，并将其转换为灰度(颜色通道是非常多余的)。这将使接下来的步骤更快，并有助于我们的模型实时运行。</p><p id="e2a6" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">对于探测部分，我们将使用<a class="ae kf" href="http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html" rel="noopener ugc nofollow" target="_blank">哈尔级联</a>，因为它们速度极快。通过一些调整，我们可以得到一些非常好的结果，但是试图直接检测眼睛会导致许多假阳性。为了摆脱这些，<strong class="ji ik">我们并不试图在图像中寻找眼睛</strong>，而是在图像中寻找人脸，然后<strong class="ji ik">在人脸中寻找眼睛</strong>。</p><p id="59e6" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">一旦我们有了双眼的边界框，我们就可以从最初的全尺寸网络摄像头快照中提取图像，这样我们就不会丢失任何信息。</p><h2 id="655b" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">数据预处理</h2><p id="9538" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">一旦我们找到了两只眼睛，我们需要为我们的数据集处理它们。要做到这一点，我们可以简单地将两者调整为固定的大小——正方形，24px——并使用<a class="ae kf" href="https://en.wikipedia.org/wiki/Histogram_equalization" rel="noopener ugc nofollow" target="_blank">直方图归一化</a>来消除阴影。</p><p id="110a" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">然后我们可以直接使用标准化的图片作为输入，但是我们有机会在这里做更多的工作。我们不使用眼睛图像，而是计算当前<em class="ke">帧</em>和前一帧<em class="ke">中眼睛之间的<strong class="ji ik">差异</strong>。这是一种非常有效的运动编码方式，这也是我们最终所需要的。</em></p><p id="925c" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated"><em class="ke">* *注意，对于下面除GIF以外的所有图，我将用眼睛图片来表示眼睛差异，因为差异在屏幕上看起来很糟糕。** </em></p><figure class="mz na nb nc fq hw fe ff paragraph-image"><div class="fe ff ni"><img src="../Images/67df0704d177d5342b72b0ab6ecf7dda.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*aFi9V0T8TBsIGL7uRGUGTQ.gif"/></div><figcaption class="id ie fg fe ff if ig bd b be z ek">Comparison between normalized frames and frame differences</figcaption></figure><p id="a6cc" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">现在我们已经处理了两只眼睛，我们可以选择<strong class="ji ik">将它们分别</strong>作为同一类的两个代表，<strong class="ji ik">或者将它们一起使用，就像它们是一个单一的图像*。我选择了后者，因为即使眼睛应该遵循完全相同的运动，拥有两个输入将使模型更加健壮。</strong></p><p id="34e8" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我们要做的比简单地把图像拼接在一起更聪明一些。</p><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff nj"><img src="../Images/14e2c547cc65dac3e8a294fd23cef1b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GJXjJiKrL5pHI74QBPZeiA.png"/></div></div><figcaption class="id ie fg fe ff if ig bd b be z ek">Paring both eyes together</figcaption></figure><h1 id="49c4" class="kt ku ij bd kv kw nd ky kz la ne lc ld le nf lg lh li ng lk ll lm nh lo lp lq dt translated">创建数据集</h1><h2 id="ff93" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated"><strong class="ak"> <em class="nk">录音</em> </strong></h2><p id="b5e4" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">我已经记录了两个独立运动的50个样本(一个看起来像“<strong class="ji ik"> gamma </strong>”，另一个看起来像“<strong class="ji ik"> Z </strong>”)。我试图改变样本的位置、比例和速度，以帮助模型进行归纳。我还添加了50个“<strong class="ji ik">闲置</strong>”的例子，其中包含了大致通用的无模式眼球运动以及静止帧。</p><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff nl"><img src="../Images/5d1b7ba95625df738dde814ed972d709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NC08lUA9yc2l6gfThiAEsA.png"/></div></div><figcaption class="id ie fg fe ff if ig bd b be z ek">Motion examples — ‘gamma’, ‘mount’, ‘Z’, ‘idle’</figcaption></figure><p id="ac58" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">不幸的是，<strong class="ji ik"> 150个样本对于这样的任务</strong>来说太少了，所以我们需要<strong class="ji ik">用新的样本来扩充</strong>数据集。</p><h2 id="98a9" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">数据扩充</h2><p id="8c56" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">我们可以做的第一件事是固定一个任意长度的<em class="ke">序列——100帧。从那里，我们可以<strong class="ji ik">减慢较短的样本</strong>和<strong class="ji ik">加速较长的样本。这是可能的，因为速度并不能定义运动。</strong></em></p><p id="a0c4" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">此外，因为短于100帧的序列<strong class="ji ik">应在100帧窗口中的任何时间</strong>在<strong class="ji ik">被检测，我们可以添加<em class="ke">填充的</em>示例<em class="ke">。</em></strong></p><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff nm"><img src="../Images/5150de3cdc14fbdbbe3369fab1a24bdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zsHiWwhxNpVk7JokQc-1gA.png"/></div></div><figcaption class="id ie fg fe ff if ig bd b be z ek">Sliding window padding for samples shorter than 100 frames</figcaption></figure><p id="f659" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">利用这些技术，我们可以将数据集扩充到大约1000–2000个示例。</p><h2 id="5ce2" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated"><strong class="ak">最终数据集</strong></h2><p id="b855" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">让我们后退一步，试着理解我们的数据。我们已经记录了一些带有相应标签的样品。这些样本中的每一个都是一系列两个24px宽的正方形图像。</p><p id="4595" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated"><em class="ke">注意，我们每只眼睛都有一个数据集。</em></p><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff nn"><img src="../Images/3ca4c122d9c9449b7e11b9a4203fafd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V79zM50fERJN-3dCjskXHw.png"/></div></div><figcaption class="id ie fg fe ff if ig bd b be z ek">Tensor description of the dataset</figcaption></figure><h1 id="a4f4" class="kt ku ij bd kv kw nd ky kz la ne lc ld le nf lg lh li ng lk ll lm nh lo lp lq dt translated">模型</h1><p id="4988" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">现在我们有了数据集，我们需要建立正确的模型来从这些数据中学习和归纳。我们可以把它的规格写成如下:</p><blockquote class="kg kh ki"><p id="1170" class="jg jh ke ji b jj jk jl jm jn jo jp jq kj js jt ju kk jw jx jy kl ka kb kc kd hn dt translated">我们的模型应该能够在每个时间步从两幅图像中提取信息，结合这些特征来预测眼睛执行的运动。</p></blockquote><p id="9199" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">如此复杂的系统需要使用强大的人工智能模型— <strong class="ji ik">神经网络</strong>。让我们看看如何建立一个满足我们需要的。神经网络层就像乐高积木，我们只需选择<strong class="ji ik">正确的砖块</strong>并将它们放在<strong class="ji ik">正确的位置</strong>。</p><h2 id="caa3" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">视觉特征—卷积神经网络</h2><p id="8e0c" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">为了从图像中提取信息，我们需要<a class="ae kf" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank"> <em class="ke">卷积层</em> </a>。这些特别擅长处理图像以挤出视觉特征。<em class="ke">(嘶！我们已经在</em> <a class="ae kf" rel="noopener" href="/@juliendespois/finding-the-genre-of-a-song-with-deep-learning-da8f59a61194#.r28dkpg2e"> <em class="ke">部分看到了这一点。1 </em> </a> <em class="ke"> ) </em></p><p id="0b34" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我们需要分别对待每只眼睛，然后通过一个<em class="ke">全连通层</em>来合并特征。由此产生的卷积神经网络(<em class="ke"> CNN </em>)将学习从一双双眼睛中提取相关知识。</p><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff no"><img src="../Images/50f54567b1b4f77bbac4e48e128e798d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ht8w9NHHyC2kR4EGhCUYeA.png"/></div></div><figcaption class="id ie fg fe ff if ig bd b be z ek">Convolutional Neural Network — Two parallel convolutional layers extract visual features, which are then merged</figcaption></figure><h2 id="4a71" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">时间特征—递归神经网络</h2><p id="c30e" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">现在我们有了图像的简单表示，我们需要一些东西来顺序处理它们。为此，我们将使用一个<a class="ae kf" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="noopener ugc nofollow" target="_blank"> <em class="ke">轮回层</em></a>——即<a class="ae kf" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"> <em class="ke">长短期记忆</em> </a>细胞。LSTM使用在当前时间步<strong class="ji ik">提取的特征</strong>和它自己的先前状态来更新它的<em class="ke">状态</em>。</p><p id="176e" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">最后，当我们已经处理了整个图像序列时，LSTM的状态然后被馈送到<em class="ke"> softmax分类器</em>以预测每个运动的概率。</p><h2 id="6f2c" class="lr ku ij bd kv ls lt lu kz lv lw lx ld jr ly lz lh jv ma mb ll jz mc md lp me dt translated">全模型</h2><p id="43e2" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">看看我们最终的神经网络，它将一系列图像对作为输入，并输出每个运动的概率。这里<strong class="ji ik">至关重要的</strong>是，我们在一个单独的部件中建立模型，因此它可以通过<em class="ke">反向传播</em>进行端到端的<strong class="ji ik">训练。</strong></p><blockquote class="kg kh ki"><p id="bfd1" class="jg jh ke ji b jj jk jl jm jn jo jp jq kj js jt ju kk jw jx jy kl ka kb kc kd hn dt translated">想象一下，我们可以说这是一个双重深度卷积LSTM递归神经网络，但没有人这么说。</p></blockquote><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff np"><img src="../Images/cf3e6573c44f481bccb2c9c717b78f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c2yZfYd4weCmHumj-SDdUQ.png"/></div></div></figure></div><div class="ab cl km kn hc ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hn ho hp hq hr"><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff np"><img src="../Images/9799471ec70ce4fb7511b1b862a6fd2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oSmOslY8hXMc6hQbqOSzEQ.png"/></div></div><figcaption class="id ie fg fe ff if ig bd b be z ek">The CNN extracts visual features from the input, which are processed at each step by the LSTM</figcaption></figure><h1 id="e3f9" class="kt ku ij bd kv kw nd ky kz la ne lc ld le nf lg lh li ng lk ll lm nh lo lp lq dt translated">结果</h1><p id="19c1" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">经过训练的模型在测试集上达到了<strong class="ji ik"> 85+% </strong> <strong class="ji ik">的准确率</strong>。考虑到增强之前的训练集非常小，这是非常好的。有了更多的时间<em class="ke">和投入，</em>我可以每节课记录至少100-200个例子，也许3-4个动作而不是2个(<em class="ke">+空闲</em>)。这肯定会提高性能。</p><p id="ed96" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">唯一剩下的步骤是实时使用分类器，调整它以避免误报，并实现逻辑来触发操作(改变音量，打开应用程序，运行宏等)。).更多信息请见<a class="ae kf" rel="noopener" href="/@juliendespois/a-i-odyssey-part-2-implementation-details-f126f18bd320#.9h95p31fs">后续文章</a>。</p><h1 id="a9c5" class="kt ku ij bd kv kw nd ky kz la ne lc ld le nf lg lh li ng lk ll lm nh lo lp lq dt translated">结论</h1><p id="6f57" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">在这篇文章中，我们已经看到了如何使用<em class="ke"> HAAR cascades </em>来找到图片上的眼睛，如何清理图像，以及如何使用<em class="ke">图像差异</em>来帮助与运动相关的项目。</p><p id="8a90" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我们还看到了如何人工增加数据集的大小，以及如何通过组装<em class="ke">卷积</em>、<em class="ke">全连接</em>和<em class="ke">递归</em>层，使用深度神经网络来拟合数据集。</p><p id="45df" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我希望你喜欢这个项目，我很高兴听到你的反馈！</p><blockquote class="kg kh ki"><p id="b7de" class="jg jh ke ji b jj jk jl jm jn jo jp jq kj js jt ju kk jw jx jy kl ka kb kc kd hn dt translated"><strong class="ji ik"> <em class="ij">如果你喜欢人工智能，</em> </strong> <a class="ae kf" href="http://eepurl.com/cATXvT" rel="noopener ugc nofollow" target="_blank"> <strong class="ji ik"> <em class="ij">订阅时事通讯</em> </strong> </a> <strong class="ji ik"> <em class="ij">接收文章和更多更新！</em>T13】</strong></p></blockquote><h1 id="479b" class="kt ku ij bd kv kw nd ky kz la ne lc ld le nf lg lh li ng lk ll lm nh lo lp lq dt translated">附加条款—代码和实施细节</h1><p id="2aa8" class="pw-post-body-paragraph jg jh ij ji b jj mf jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz mj kb kc kd hn dt translated">如果你感兴趣，我会更详细地介绍这个项目的实施选择和问题(模型选择，眼球追踪等)。)<a class="ae kf" rel="noopener" href="/@juliendespois/a-i-odyssey-part-2-implementation-details-f126f18bd320#.yt5mfeyx5">此处</a>。</p><p id="e9dd" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">你可以玩那边的代码:</p><div class="ht hu fm fo hv nq"><a href="https://github.com/despoisj/DeepEyeControl" rel="noopener  ugc nofollow" target="_blank"><div class="nr ab ej"><div class="ns ab nt cl cj nu"><h2 class="bd ik fv z el nv eo ep nw er et ii dt translated">GitHub-despisj/DeepEyeControl:用眼睛触发电脑上的快捷键</h2><div class="nx l"><h3 class="bd b fv z el nv eo ep nw er et ek translated">用眼睛触发电脑上的快捷键。阅读介质要求安装:创建文件夹…</h3></div><div class="ny l"><p class="bd b gc z el nv eo ep nw er et ek translated">github.com</p></div></div><div class="nz l"><div class="oa l ob oc od nz oe ib nq"/></div></div></a></div><p id="53ab" class="pw-post-body-paragraph jg jh ij ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">感谢阅读这篇文章，敬请关注！</p><div class="mz na nb nc fq ab cb"><figure class="of hw og oh oi oj ok paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="of hw og oh oi oj ok paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="of hw og oh oi oj ok paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="kg kh ki"><p id="f922" class="jg jh ke ji b jj jk jl jm jn jo jp jq kj js jt ju kk jw jx jy kl ka kb kc kd hn dt translated"><a class="ae kf" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是AMI家庭的一员。我们现在<a class="ae kf" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae kf" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="jg jh ke ji b jj jk jl jm jn jo jp jq kj js jt ju kk jw jx jy kl ka kb kc kd hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae kf" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae kf" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="mz na nb nc fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff ol"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></div></figure></div></div>    
</body>
</html>