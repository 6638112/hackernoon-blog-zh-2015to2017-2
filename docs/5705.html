<html>
<head>
<title>Adversarial Examples and their implications - Deep Learning bits #3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对立的例子及其含义-深度学习比特#3</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/the-implications-of-adversarial-examples-deep-learning-bits-3-4086108287c7?source=collection_archive---------6-----------------------#2017-08-11">https://medium.com/hackernoon/the-implications-of-adversarial-examples-deep-learning-bits-3-4086108287c7?source=collection_archive---------6-----------------------#2017-08-11</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="e7ae" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">特色</em>:对抗的例子，深度学习的未来，安全和攻击</p><p id="0c3e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在“<em class="jp">深度学习比特</em>系列中，我们将<strong class="it hv">而非</strong>看到如何像我们在<a class="ae jq" rel="noopener" href="/@juliendespois/talk-to-you-computer-with-you-eyes-and-deep-learning-a-i-odyssey-part-2-7d3405ab8be1"><strong class="it hv"><em class="jp">a . I . Odyssey</em></strong></a><strong class="it hv"><em class="jp"/></strong>系列<strong class="it hv"> <em class="jp">中所做的那样，利用深度学习解决复杂问题。</em> </strong>我们更愿意看看与深度学习相关的不同<strong class="it hv">技术</strong>或<strong class="it hv">概念</strong>。</p></div><div class="ab cl jr js hc jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="hn ho hp hq hr"><h1 id="d10e" class="jy jz hu bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv dt translated">介绍</h1><p id="1e13" class="pw-post-body-paragraph ir is hu it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hn dt translated">在本文中，我们将讨论<strong class="it hv"> <em class="jp">对立示例</em> </strong>和<strong class="it hv"> <em class="jp"> </em> </strong>讨论它们对深度学习和安全的影响<em class="jp">。</em>不可与<em class="jp">对抗训练、</em> <strong class="it hv"> </strong>混淆，后者是训练神经网络的框架，如<a class="ae jq" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> <em class="jp">生成对抗网络</em> </a> <em class="jp">中所用。</em></p><h2 id="2ff4" class="lb jz hu bd ka lc ld le ke lf lg lh ki jc li lj km jg lk ll kq jk lm ln ku lo dt translated">什么是对立的例子？</h2><p id="5de6" class="pw-post-body-paragraph ir is hu it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hn dt translated">对立的例子是<strong class="it hv"> <em class="jp">手工输入</em> </strong>导致神经网络以<strong class="it hv">高置信度</strong>预测<strong class="it hv">错误类别</strong>。</p><p id="06fc" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">通常，当图像<strong class="it hv"> * </strong>属于<em class="jp">质量差</em>(裁切不良、模糊不清等)时，会出现神经网络错误。)或包含<em class="jp">多个类别</em>(背景中的汽车等。).这是<strong class="it hv">而不是</strong>对立的例子，看起来像普通的图像。</p><p id="cdd8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp"> * </em> </strong> <em class="jp">在这篇文章中，我们将关注图像，因为它们提供了有趣的视觉支持，但请记住，这也可以应用于其他输入，如声音。</em></p><figure class="lq lr ls lt fq lu fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff lp"><img src="../Images/7a44be9085d9521eae879d25ad1467c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_mxv1rHqPn8iUsHKTw6lLw.png"/></div></div><figcaption class="mb mc fg fe ff md me bd b be z ek">Three different types of errors, along with predicted class</figcaption></figure><p id="1344" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">虽然前两个错误可以理解，但第三个图像<strong class="it hv">肯定</strong>看起来像一个寺庙，我们可以认为任何经过适当训练的神经网络<strong class="it hv">都应该</strong> <strong class="it hv">能够做出正确的预测</strong>。</p><p id="ea3b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp">那这里到底怎么回事？</em>T75】</strong></p><p id="9b8f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对抗性例子的特殊性在于它们不出现在自然数据中，<strong class="it hv">它们是</strong> <strong class="it hv">精心制作的</strong>。针对神经网络的<em class="jp">对抗性攻击</em>是一个过程，在这个过程中，有人稍微修改一张图像，使其<strong class="it hv">欺骗网络</strong>。目标是<strong class="it hv">最小化对原始图像的扰动</strong>，同时获得目标类的<strong class="it hv">高置信度</strong>。</p><figure class="lq lr ls lt fq lu fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff mf"><img src="../Images/3d1837ddaa55b4f733d7a8fbf7b3c00b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uwAos6ZGW0SYqipwn2DpAw.png"/></div></div><figcaption class="mb mc fg fe ff md me bd b be z ek">Creation of an adversarial example to target the <strong class="bd mg">Ostrich</strong> class</figcaption></figure><h2 id="fafd" class="lb jz hu bd ka lc ld le ke lf lg lh ki jc li lj km jg lk ll kq jk lm ln ku lo dt translated">这是怎么做到的？</h2><p id="7c2c" class="pw-post-body-paragraph ir is hu it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hn dt translated">对抗性例子的<a class="ae jq" href="https://arxiv.org/abs/1412.6572" rel="noopener ugc nofollow" target="_blank">代</a>是一个巨大的主题，新技术正在被发现，以创建<strong class="it hv">更快</strong>、<a class="ae jq" href="https://blog.openai.com/adversarial-example-research/" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv">更鲁棒</strong> </a>扰动和<strong class="it hv">最小</strong>图像失真。</p><p id="a142" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们不会纠缠于<em class="jp">这些是如何产生的，而是关注它们的<strong class="it hv">含义。</strong>但一个通用的原理和简单的方法是，取原始图像，通过神经网络运行，使用<a class="ae jq" href="http://neuralnetworksanddeeplearning.com/chap2.html" rel="noopener ugc nofollow" target="_blank"> <em class="jp">反向传播算法</em> </a>找出<a class="ae jq" href="http://karpathy.github.io/2015/03/30/breaking-convnets/" rel="noopener ugc nofollow" target="_blank">图像的<strong class="it hv">像素</strong>应该如何修改</a>以达到<strong class="it hv">目标</strong>类。</em></p><h2 id="9b6c" class="lb jz hu bd ka lc ld le ke lf lg lh ki jc li lj km jg lk ll kq jk lm ln ku lo dt translated">这真的是件大事吗？</h2><p id="8214" class="pw-post-body-paragraph ir is hu it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hn dt translated">当我们看到对立的例子时，我们通常会想到的第一件事是它们是不可接受的。由于人类可以不费吹灰之力地对它们进行正确分类，我们直觉地认为任何好的模型都可以做到这一点。这揭示了我们对神经网络的内在<strong class="it hv">期望</strong>:我们想要<strong class="it hv">人类</strong>或<strong class="it hv">超人</strong>的性能。</p><figure class="lq lr ls lt fq lu fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff mh"><img src="../Images/78e4e0a3f14605ded31e1671661306dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z0CPjk96nNlrPsBmUoyFCw.png"/></div></div><figcaption class="mb mc fg fe ff md me bd b be z ek">“If a model fails to classify this as a Temple, then it’s <strong class="bd mg">necessarily</strong> <strong class="bd mg">bad</strong>” — Or is it?</figcaption></figure><blockquote class="mi mj mk"><p id="c133" class="ir is jp it b iu iv iw ix iy iz ja jb ml jd je jf mm jh ji jj mn jl jm jn jo hn dt translated">让我们退后一分钟，想想这意味着什么。</p></blockquote><p id="fa06" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在一项给定的任务中，例如识别无人驾驶车辆中的路标，我们不会用计算机来代替人类，除非它至少和人类一样好。</p><p id="449e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们经常忘记的是，拥有一个比人类更好的模型并不意味着对失败案例有任何要求。最后，如果人类有<strong class="it hv"> 96% </strong>的准确率，有<strong class="it hv"> 98% </strong>的神经网络，那么机器认为<em class="jp">容易</em>的例子真的重要吗？</p><p id="13ce" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这个问题的答案是<strong class="it hv">是</strong>…AAA和<strong class="it hv">否</strong>。</p><p id="d16d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">尽管看到<em class="jp">最先进的</em>模型在看起来微不足道的例子上失败<strong class="it hv">感到沮丧和反直觉</strong>，但这并不代表<strong class="it hv">根本问题。</strong>我们关心的是模型有多强大，多可靠。我们必须承认，我们的大脑和深度学习的工作方式不同，因此不会产生相同的结果。</p><figure class="lq lr ls lt fq lu fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff mo"><img src="../Images/8833508a16ea1bcbb34e29dc10078535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TJXTUEK8BFaWGMRlIoguzg.png"/></div></div><figcaption class="mb mc fg fe ff md me bd b be z ek">“Do we care whether the exemples the machine missed are never missed by a human?”</figcaption></figure><p id="a1a4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">然而，<strong class="it hv"><em class="jp"/></strong>重要的是，对抗性攻击代表了对基于人工智能的系统的安全威胁。</p><h2 id="d876" class="lb jz hu bd ka lc ld le ke lf lg lh ki jc li lj km jg lk ll kq jk lm ln ku lo dt translated">我们如何恶意利用对立的例子？</h2><p id="0bbb" class="pw-post-body-paragraph ir is hu it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hn dt translated">如果有人得到了底层模型，许多类型的深度学习驱动的系统可能会严重遭受敌对攻击。这里有一些例子。</p><ul class=""><li id="8a3a" class="mp mq hu it b iu iv iy iz jc mr jg ms jk mt jo mu mv mw mx dt translated">上传绕过安全过滤器的图像</li><li id="d306" class="mp mq hu it b iu my iy mz jc na jg nb jk nc jo mu mv mw mx dt translated">创建不会被谷歌的“我不是机器人”系统标记的机器人</li></ul><p id="8dde" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">那是给虚拟世界的。然而，对现实生活中的<strong class="it hv"/><strong class="it hv">物体</strong>实施这样的攻击明显<strong class="it hv">更难</strong>，因为拍摄物体照片时会涉及到所有的变换，但<a class="ae jq" href="https://blog.openai.com/robust-adversarial-inputs/" rel="noopener ugc nofollow" target="_blank">仍有可能</a>。</p><figure class="lq lr ls lt fq lu"><div class="bz el l di"><div class="nd ne l"/></div><figcaption class="mb mc fg fe ff md me bd b be z ek">Robust Adversarial Example in the wild by <a class="ae jq" href="https://blog.openai.com/robust-adversarial-inputs/" rel="noopener ugc nofollow" target="_blank">OpenAI</a> — The red bar indicates the most probable class for the image. Here the cat is classified as a desktop computer</figcaption></figure><p id="40da" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">考虑到这一点，你可以想象:</p><ul class=""><li id="8783" class="mp mq hu it b iu iv iy iz jc mr jg ms jk mt jo mu mv mw mx dt translated">戴上<a class="ae jq" href="https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf" rel="noopener ugc nofollow" target="_blank">特制眼镜</a>窃取他人身份</li><li id="abf0" class="mp mq hu it b iu my iy mz jc na jg nb jk nc jo mu mv mw mx dt translated">通过<a class="ae jq" href="https://arxiv.org/pdf/1707.08945.pdf" rel="noopener ugc nofollow" target="_blank">改变交通标志</a>误导自动驾驶汽车</li><li id="f6ef" class="mp mq hu it b iu my iy mz jc na jg nb jk nc jo mu mv mw mx dt translated">伪装武器以避免视频检测</li><li id="2d9e" class="mp mq hu it b iu my iy mz jc na jg nb jk nc jo mu mv mw mx dt translated">绕过音频或指纹识别</li></ul><figure class="lq lr ls lt fq lu fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff nf"><img src="../Images/2f7d40e56fb8d0c3604f97cccb244fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5RzFIIxALKZR5aGoFe0AhA.png"/></div></div><figcaption class="mb mc fg fe ff md me bd b be z ek">Impersonating Mila Jovovich with custom glasses</figcaption></figure><h2 id="b9df" class="lb jz hu bd ka lc ld le ke lf lg lh ki jc li lj km jg lk ll kq jk lm ln ku lo dt translated">对此我们能做些什么？</h2><p id="5819" class="pw-post-body-paragraph ir is hu it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hn dt translated">我们可以做一些事情来缓解这个问题。首先我们可以考虑保持模型的私密性。然而，这个<strong class="it hv">方案</strong>有两大缺陷。</p><p id="9c49" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">首先</strong>，理想情况下，安全系统应该遵循<a class="ae jq" href="https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle" rel="noopener ugc nofollow" target="_blank"> Kerckhoffs-Shannon原则</a> : <em class="jp">“我们应该在假设敌人会立即完全熟悉系统的情况下设计系统”。</em>这意味着我们<strong class="it hv">不应该依赖</strong>模特的隐私，因为总有一天会被<strong class="it hv">泄露* </strong>。</p><p id="af02" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">然后</strong>，一些关于<a class="ae jq" href="https://arxiv.org/abs/1707.05572v1" rel="noopener ugc nofollow" target="_blank">通用</a> / <strong class="it hv">独立于模型的</strong>对抗性攻击的论文已经发表，无论使用哪种模型都可能对特定的任务起作用。</p><p id="0c7a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp"> * </em> </strong> <em class="jp">注:这就是所有数据库都加密的原因。仔细想想，如果你认为你的数据库永远不会被黑客攻击，那就没有“必要”加密它。</em></p></div><div class="ab cl jr js hc jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="hn ho hp hq hr"><p id="98d1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">从好的一面来看，像帕塞瓦尔网络或防御蒸馏这样的技术正在被开发，以使神经网络更能抵御恶意攻击。我们还可以使用 <em class="jp">正常</em>图像和<em class="jp">对抗性</em> <em class="jp">示例</em>来训练模型，以帮助网络忽略扰动。</p><figure class="lq lr ls lt fq lu fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff ng"><img src="../Images/e31ac7fb8bb1538ec3eccdc930a85bef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y6aQqXawFFZ0mAB73dNugw.png"/></div></div><figcaption class="mb mc fg fe ff md me bd b be z ek">Extrapolation of OpenAI’s remark on transformations and perturbations magnitude</figcaption></figure><p id="a91a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">此外，OpenAI的一个团队注意到，当你想让对抗性攻击对许多变换(<em class="jp">旋转</em>、<em class="jp">透视</em>等)具有鲁棒性时，找到<strong class="it hv">小扰动</strong>变得越来越难<strong class="it hv">。).<em class="jp">我们可以想象</em>某个模型可以达到这样一个点，在这个点上<strong class="it hv">没有扰动</strong>，对所有的变换<strong class="it hv">和</strong>都有弹性，不可检测。我们<em class="jp">可以</em>然后将敌对的例子标记为<strong class="it hv">异常</strong>，因此对于这个任务来说<strong class="it hv">安全</strong>免受敌对攻击，但是这可能很难实现(例如需要<strong class="it hv">多个摄像机</strong>等等)。).</strong></p><h1 id="7730" class="jy jz hu bd ka kb nh kd ke kf ni kh ki kj nj kl km kn nk kp kq kr nl kt ku kv dt translated"><strong class="ak">结论</strong></h1><p id="e6fa" class="pw-post-body-paragraph ir is hu it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hn dt translated">总之，对立的例子是深度学习研究的一个非常有趣的领域，每天都有<strong class="it hv">进展</strong>来实现安全的深度学习系统。最重要的是，研究团队同时扮演<strong class="it hv">警察</strong>和<strong class="it hv">强盗</strong>，试图<strong class="it hv">建立/破坏</strong>神经网络分类器。</p><p id="52a0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">截至今天，对抗性攻击开始对基于深度学习的系统构成威胁。然而，很少有系统盲目地依赖神经网络来进行重要的验证，而对抗性攻击<strong class="it hv">不够通用/强大</strong>，除了研究团队之外，无法大规模应用。</p><p id="8f49" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">在未来的几年里</strong>，越来越多针对神经网络的攻击将成为可能，随着<strong class="it hv">对攻击者越来越有趣的奖励</strong>希望到那时，我们将已经开发出强大的防御技术，使<strong class="it hv">免受此类攻击</strong>。</p></div><div class="ab cl jr js hc jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="hn ho hp hq hr"><p id="b34c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">感谢</strong>阅读这篇帖子！欢迎<em class="jp">分享</em> it和<em class="jp">关注</em>我如果你喜欢AI相关的东西！</p></div></div>    
</body>
</html>