<html>
<head>
<title>Visualizing parts of Convolutional Neural Networks using Keras and Cats</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras和Cats可视化部分卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59?source=collection_archive---------0-----------------------#2017-01-23">https://medium.com/hackernoon/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59?source=collection_archive---------0-----------------------#2017-01-23</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="e7ec" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">众所周知，卷积神经网络(CNN或ConvNets)是过去几年深度学习领域许多重大突破的来源，但对大多数人来说，它们相当不直观。我一直想分解ConvNet的各个部分，看看每个阶段后的图像是什么样的，在这篇文章中我就是这么做的！</p><h2 id="af43" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">CNN高层</h2><p id="7abb" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">首先，ConvNets擅长什么？ConvNets主要用于在图像中寻找模式。你通过对图像进行卷积并寻找模式来做到这一点。在CNN的前几层，网络可以识别线条和拐角，但我们可以通过我们的神经网络传递这些模式，并随着我们的深入开始识别更复杂的特征。这一特性使得CNN非常擅长识别图像中的物体。</p><h1 id="75d3" class="kp jq hu bd jr kq kr ks jv kt ku kv jz kw kx ky kc kz la lb kf lc ld le ki lf dt translated">什么是CNN？</h1><p id="eb87" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">CNN是一种神经网络，通常包含几种类型的层，其中一种是<strong class="it hv">卷积层</strong>，以及<strong class="it hv">汇聚层</strong>，和<strong class="it hv">激活层</strong>。</p><h2 id="3ec7" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">卷积层</h2><p id="4217" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">为了理解CNN是什么，你需要理解卷积是如何工作的。想象一下，你有一个5x5数值矩阵的图像，你拿一个3x3的矩阵，在图像周围滑动那个3x3的窗口。在3x3访问的每个位置，将3x3窗口的值乘以图像中当前被窗口覆盖的值。这将产生一个数字，表示图像窗口中的所有值。为了清楚起见，这里有一个漂亮的gif:</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff lg"><img src="../Images/0e7de8a67e0c197106c87d417e45b499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*ZCjPUFrB6eHPRi4eyP6aaA.gif"/></div></figure><p id="3016" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如您所见，特征矩阵中的每一项都对应于图像的一部分。请注意，核矩阵的值是gif的角上的红色数字。</p><p id="6a93" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在图像上移动的“窗口”被称为<strong class="it hv">内核</strong>。内核通常是方形的，对于小型图像来说，3x3是相当常见的内核大小。窗户每次移动的距离称为<strong class="it hv">步距</strong>。另外值得注意的是，当执行卷积时，图像有时会在周长周围填充零，这会抑制图像边缘周围卷积的值(通常照片的中心更重要)。</p><p id="b701" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">卷积层的目标是<strong class="it hv">滤波。</strong>当我们在图像上移动时，我们会有效地检查图像中该部分的模式。这是因为<strong class="it hv">滤波器、</strong>表示为向量的权重堆栈，它们与卷积输出的值相乘。当训练一幅图像时，这些权重会发生变化，因此当需要评估一幅图像时，如果它认为它看到的是以前见过的模式，这些权重会返回高值。来自各种过滤器的高权重的组合让网络预测图像的内容。这就是为什么在CNN架构图中，卷积步骤用方框表示，而不是矩形；第三维表示过滤器。</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff lo"><img src="../Images/5f05b9e32a1c617afe68179c55cbad77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SkcQSh0NlFylFS5I8GTbGg.jpeg"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">Architecture of AlexNet</figcaption></figure><h2 id="8fe2" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">需要注意的事项:</h2><ul class=""><li id="6c3a" class="lx ly hu it b iu kk iy kl jc lz jg ma jk mb jo mc md me mf dt translated">卷积的输出(在宽度和高度上)小于原始图像</li><li id="b72f" class="lx ly hu it b iu mg iy mh jc mi jg mj jk mk jo mc md me mf dt translated">在内核和内核下的图像窗口之间应用线性函数</li><li id="de62" class="lx ly hu it b iu mg iy mh jc mi jg mj jk mk jo mc md me mf dt translated">过滤器中的权重是通过查看大量图像来学习的</li></ul><h2 id="7db2" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">池层</h2><p id="ddd5" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">池的工作非常像卷积，我们用一个<strong class="it hv">内核</strong>在图像上移动内核，唯一的区别是应用于内核的函数和图像窗口不是线性的。</p><p id="8fed" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">最大池</strong>和<strong class="it hv">平均池</strong>是最常见的池功能。最大池取内核当前覆盖的映像窗口中的最大值，而平均池取窗口中所有值的平均值。</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff ml"><img src="../Images/c7b974cc0b66dffc5ffb901447f43951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Feiexqhmvh9xMGVVJweXhg.gif"/></div></div></figure><h2 id="44e7" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">激活层</h2><p id="d76c" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">激活层的工作方式与其他神经网络完全一样，一个值通过一个函数传递，该函数将该值压缩到一个范围内。这里有一堆常见的:</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff mm"><img src="../Images/6598c695a41ddf57915ef645e25f5e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*rIiBaH5IMVPaE5BM-n7VZw.png"/></div></figure><p id="9d36" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">CNN中最常用的激活功能是relu(整流线性单元)。人们喜欢relus的原因有很多，但一个很大的原因是因为它们执行起来非常便宜，如果数字是负数:0，否则:数字。便宜使得训练网络更快。</p><h2 id="9c94" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">概述</h2><ul class=""><li id="7fd1" class="lx ly hu it b iu kk iy kl jc lz jg ma jk mb jo mc md me mf dt translated">CNN中三种主要类型的层:<strong class="it hv">卷积、汇集、激活</strong></li><li id="5464" class="lx ly hu it b iu mg iy mh jc mi jg mj jk mk jo mc md me mf dt translated"><strong class="it hv">卷积层</strong>将图像窗口乘以内核值，并使用梯度下降随时间优化内核权重</li><li id="db01" class="lx ly hu it b iu mg iy mh jc mi jg mj jk mk jo mc md me mf dt translated"><strong class="it hv">池层</strong>使用单个值描述图像的窗口，该值是该窗口的最大值或平均值</li><li id="46b6" class="lx ly hu it b iu mg iy mh jc mi jg mj jk mk jo mc md me mf dt translated"><strong class="it hv">激活层</strong>将值压缩到一个范围内，通常为[0，1]或[-1，1]</li></ul><h1 id="6921" class="kp jq hu bd jr kq kr ks jv kt ku kv jz kw kx ky kc kz la lb kf lc ld le ki lf dt translated">CNN看起来像什么？</h1><p id="68bc" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">在我们进入CNN之前，先了解一点背景。90年代Yann LeCun首次成功应用了ConvNets，他发明了一种叫做LeNet的东西，可以用来阅读手写数字。自那以后，计算技术的进步和强大的GPU让研究人员变得更加雄心勃勃。2010年，斯坦福视觉实验室发布了ImageNet。 Image net是1400万张图片的数据集，带有详细描述图片内容的标签。它已经成为研究界比较CNN模型的标准之一，当前最好的模型将成功检测94%以上图像中的对象。不时有人进来打破imagenet上的最高分，这是一件大事。2014年是GoogLeNet和VGGNet，之前是ZF网。CNN应用于imagenet的第一个可行的例子是2012年的AlexNet，在此之前，研究人员试图使用传统的计算机视觉技术，但AlexNet在这一点上超过了其他任何东西约15%。</p><p id="f706" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">不管怎样，让我们看看LeNet:</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff mo"><img src="../Images/882e85280f5f9027bb41a08d88b91d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Ut7fQHswfO2zZngh6BYfg.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">LeNet architecture</figcaption></figure><p id="5abe" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">该图未显示激活功能，但架构如下:</p><p id="74ed" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">输入图像→conv player→Relu→max pooling→conv player→Relu→max pooling→隐藏层→Softmax(激活)→输出层</p><h1 id="26b0" class="kp jq hu bd jr kq kr ks jv kt ku kv jz kw kx ky kc kz la lb kf lc ld le ki lf dt translated">去找猫！</h1><p id="324d" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">这是一只猫的图像:</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff mp"><img src="../Images/c40d3e5a54ae162fef57a113330c0698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OfbX5Lahe8Y6NiTF_98PZg.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">That’s a good looking cat</figcaption></figure><p id="6ee6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们的猫的图片有320像素的高度，400像素的宽度，和3个颜色通道(RGB)。</p><h2 id="c3bc" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">卷积层</h2><p id="c2ba" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">那么一层卷积之后他是什么样子的呢？</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff mq"><img src="../Images/3ba513ca52d4fbace653b5b506dee322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s3MMrbrwtxsmj5g6KBGtHQ.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">1 convcat</figcaption></figure><p id="b113" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这是一只内核大小为3x3的猫，有3个滤镜(如果我们有3个以上的滤镜层，我们就不能绘制猫的2d图像。众所周知，高维度的猫很难对付。).</p><p id="9494" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">正如你所看到的，这只猫真的很吵，因为我们所有的权重都是随机初始化的，我们还没有训练网络。哦，它们都在彼此之上，所以即使每一层都有细节，我们也看不到。但是我们可以分辨出猫的一些区域，比如眼睛和背景的颜色是一样的。如果我们将内核大小增加到10x10会怎么样？</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff mr"><img src="../Images/60de6230ced557c8ba7abd81ad692a26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*OZqJFAj5f_ogyB8ap0arrQ.png"/></div></figure><p id="b941" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">正如我们所见，由于内核太大，我们丢失了一些细节。还要注意图像的形状稍微小一点，因为内核更大，而且数学控制着一切。</p><p id="fc11" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果我们把它缩小一点，这样我们可以更好地看到颜色通道，会发生什么？</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff ms"><img src="../Images/0a034055f8270f46fcf7bddea5e04253.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d3pDD4GW-QMW3anEECJ4uQ.png"/></div></div></figure><p id="c1a1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">好多了！现在我们可以看到我们的过滤器看到的一些东西。看起来红色是真的喜欢黑色的鼻子和眼睛，蓝色是挖掘出猫轮廓的浅灰色。我们可以开始看到该层如何捕捉照片中一些更重要的细节。</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff mt"><img src="../Images/248e842b37e9da3c8866549cf4cf7675.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*DetoY0gDYIl1wlZ6IQeWaw.png"/></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">3x3 Kernel convcat</figcaption></figure><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff mu"><img src="../Images/b002d60fbfc241463f0347c8d6b2c0ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*Np-4OzKgaJx9k3fs2HBLog.png"/></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">Original</figcaption></figure><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff mv"><img src="../Images/ff30788a536a93c3896dea0e8c986617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*sYBiCrRBDf34NA2RaOu_gg.png"/></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">15x15 pixel kernel size</figcaption></figure><p id="5842" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果我们增加内核的大小，现在我们得到的细节更少了，但图像也比其他两个小得多。</p><h2 id="eb2f" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">添加激活层</h2><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff mw"><img src="../Images/b8a9ca32e8b62ffbd7829e14175a4885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wG80EEng5lITSmZA9r0wiA.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">\reluCat</figcaption></figure><p id="66d5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们通过添加一个relu去掉了许多不蓝色。</p><h2 id="5c0a" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">添加池层</h2><p id="4ca7" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">我们添加了一个池层(去掉了激活，使它更容易显示)</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff mx"><img src="../Images/bdac73ba36bf5a7f593168cced32fc1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7GkHhws29t93C2Cij9eKww.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">2x2 pool size</figcaption></figure><p id="a3c2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">不出所料，这只猫块头更大，但我们可以走得更大！</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff my"><img src="../Images/c9dae77cffb4dfc3ce4c858ceabc2acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*vGKntKeFoXIVA8ufLRW4-Q.png"/></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">PoolCat with a 5x5 pool size. All your poolz belong to us</figcaption></figure><p id="84ef" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">请注意，现在的图像大约是原来的三分之一大小。</p><h2 id="1a74" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">激活和最大池化</h2><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff mz"><img src="../Images/7d9903de59aae7d27a5ebcc2eb4087d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*SJ_LOBbMbRljR7P3TtYSgQ.png"/></div></figure><h2 id="21e8" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">LeNet猫</h2><p id="fdd6" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">如果我们让猫通过LeNet的卷积和池部分，它们看起来会是什么样子？</p><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff na"><img src="../Images/9bf136213324feadf979b2a841a1f469.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*2094MXgD18PlWFsS1t6MEA.png"/></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">1 filter for each conv layer</figcaption></figure><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff nb"><img src="../Images/16ca9edd57bc1d9abbd68a99c6d0a272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*-Rbz-Ws6hFkHBKtgIcDp2w.png"/></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">3 filters in first conv layer, 1 in second conv later</figcaption></figure><figure class="lh li lj lk fq ll fe ff paragraph-image"><div class="fe ff nc"><img src="../Images/0745860ffb37484e5e5baae1f9b5e39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*HbEXy3o1b_yScMt1PdN2iw.png"/></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">3 filter layers in each convolution</figcaption></figure><h1 id="fb9d" class="kp jq hu bd jr kq kr ks jv kt ku kv jz kw kx ky kc kz la lb kf lc ld le ki lf dt translated">结论</h1><p id="1486" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated">ConvNets功能强大，因为它们能够提取图像的核心特征，并使用这些特征来识别包含类似特征的图像。即使有了我们的两层CNN，我们也可以开始看到网络对猫的胡须、鼻子和眼睛等部位给予了很多关注。例如，这些类型的特征将允许CNN区分猫和鸟。</p><p id="a299" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">CNN非常强大，虽然这些可视化并不完美，但我希望它们能帮助像我这样仍在学习如何更好地推理CNN的人。</p><p id="051b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所有代码都在Github上:<a class="ae mn" href="https://github.com/erikreppel/visualizing_cnns" rel="noopener ugc nofollow" target="_blank">https://github.com/erikreppel/visualizing_cnns</a></p><p id="d569" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在Twitter上关注我，我是@ <a class="ae mn" href="https://twitter.com/programmer" rel="noopener ugc nofollow" target="_blank">程序员</a>(是的，说真的)。</p><h2 id="375f" class="jp jq hu bd jr js jt ju jv jw jx jy jz jc ka kb kc jg kd ke kf jk kg kh ki kj dt translated">更多资源</h2><p id="8095" class="pw-post-body-paragraph ir is hu it b iu kk iw ix iy kl ja jb jc km je jf jg kn ji jj jk ko jm jn jo hn dt translated"><a class="ae mn" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">安德烈·卡帕西的cs231n </a></p><p id="e520" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">文森特·杜默林和弗朗切斯科·维辛的深度学习卷积算法指南</p><div class="lh li lj lk fq ab cb"><figure class="nd ll ne nf ng nh ni paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="nd ll ne nf ng nh ni paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="nd ll ne nf ng nh ni paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="nj nk nl"><p id="f922" class="ir is nm it b iu iv iw ix iy iz ja jb nn jd je jf no jh ji jj np jl jm jn jo hn dt translated"><a class="ae mn" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae mn" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae mn" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae mn" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="ir is nm it b iu iv iw ix iy iz ja jb nn jd je jf no jh ji jj np jl jm jn jo hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae mn" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae mn" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="lh li lj lk fq ll fe ff paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="fe ff nq"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></div></figure></div></div>    
</body>
</html>