<html>
<head>
<title>Reading the VGG Network Paper and Implementing It From Scratch with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阅读VGG网络论文并使用Keras从头开始实施</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/learning-keras-by-implementing-vgg16-from-scratch-d036733f2d5?source=collection_archive---------3-----------------------#2017-03-27">https://medium.com/hackernoon/learning-keras-by-implementing-vgg16-from-scratch-d036733f2d5?source=collection_archive---------3-----------------------#2017-03-27</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/81f84b000439dccc38037b181655a59a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hcbMop1Lroimnh8XlqaHAA.jpeg"/></div></div></figure><p id="8390" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">Keras有数百个代码示例。仅仅复制和粘贴代码而不知道实际发生了什么是很常见的。在本教程中，您将实现一些非常简单的东西，但有几个学习好处:您将通过阅读VGG的原始论文，从零开始用Keras实现VGG网络。</p><p id="5fb4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我用“VGG”这个词来描述VGG(牛津大学视觉几何组)为2014年国际视觉几何中心设计的建筑。</p><p id="58d1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">那么，实现已经实现的东西有什么意义呢？</p><p id="91b3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">重点是学习。通过完成本指南，您将:</p><ul class=""><li id="217d" class="kb kc hu je b jf jg jj jk jn kd jr ke jv kf jz kg kh ki kj dt translated">了解更多关于VGG的建筑；</li><li id="9a64" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">了解有关卷积神经网络的更多信息；</li><li id="6b1b" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">了解有关如何在Keras中实现网络的更多信息；</li><li id="a288" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">通过阅读一篇科学论文并实施其中的一部分来了解更多的科学方法。</li></ul><h2 id="07ed" class="kp kq hu bd kr ks kt ku kv kw kx ky kz jn la lb lc jr ld le lf jv lg lh li lj dt translated">为什么从VGG开始？</h2><ul class=""><li id="658a" class="kb kc hu je b jf lk jj ll jn lm jr ln jv lo jz kg kh ki kj dt translated">很容易实现；</li><li id="a746" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">它在ILSVRC-2014 (ImageNet竞赛)上取得了优异的成绩；</li><li id="9c43" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">这纸读起来很好；</li><li id="14f5" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">它有一个Keras实现，所以你可以比较你的代码。</li></ul><h1 id="7e80" class="lp kq hu bd kr lq lr ls kv lt lu lv kz lw lx ly lc lz ma mb lf mc md me li mf dt translated">目标受众</h1><p id="2522" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">刚接触深度学习并且从未用Keras实现过任何网络的人。</p><h1 id="1a89" class="lp kq hu bd kr lq lr ls kv lt lu lv kz lw lx ly lc lz ma mb lf mc md me li mf dt translated"><strong class="ak">先决条件</strong></h1><p id="0ea1" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">基本的Python和基本的卷积神经网络知识。我推荐你阅读<a class="ae mj" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank">斯坦福的CS231n:视觉识别的卷积神经网络笔记</a>。</p><h1 id="d43e" class="lp kq hu bd kr lq lr ls kv lt lu lv kz lw lx ly lc lz ma mb lf mc md me li mf dt translated"><strong class="ak">练习0 </strong></h1><p id="2afc" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">略读<a class="ae mj" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">《VGG》网络论文:<em class="ka">用于大规模图像识别的极深度卷积网络</em> </a>。更好地了解结果和网络架构。根据结果，选择要实施的配置。</p><h1 id="096a" class="lp kq hu bd kr lq lr ls kv lt lu lv kz lw lx ly lc lz ma mb lf mc md me li mf dt translated"><strong class="ak">练习1 </strong></h1><p id="41d4" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">学习网络架构。考虑以下超参数:卷积滤波器(感受野)大小、步幅和填充。另外，检查使用了哪个激活功能。如果您不确定这些术语的含义，请查阅CS231n课堂笔记。不要忘记检查输入数据的大小。</p><p id="00c9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">计算每层必须学习的参数数量。将每一层的参数相加，得到可学习参数的总数。【CS231n的这些卷积网络笔记能帮上大忙。不要忘记对偏见进行总结。另外，计算每层输出的形状(宽度、高度、深度)。用铅笔和纸！在这个练习中，画画很有帮助。</p><p id="984e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">您可以在纸上找到关于参数数量以及如何计算它们的信息。</p><h1 id="0a46" class="lp kq hu bd kr lq lr ls kv lt lu lv kz lw lx ly lc lz ma mb lf mc md me li mf dt translated"><strong class="ak">练习2 </strong></h1><p id="a903" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">阅读Keras文档的<a class="ae mj" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank">第一页</a>和<a class="ae mj" href="https://keras.io/getting-started/sequential-model-guide" rel="noopener ugc nofollow" target="_blank"> <em class="ka">开始使用Keras顺序模型</em> </a>。在首次试用之前，请跳过示例部分*。回到纸上，更加专注地阅读。关注架构配置。开始编写您的网络架构。你需要浏览Keras文档的图层部分。</p><p id="3ec8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="ka"> *注意:我只是建议你跳过例子部分，这样你就不会从VGG电视网得到“剧透”。我们总是建议您阅读这些示例，因为您可能会从这些示例中学到比其他文档更多的东西。</em></p><p id="0d2e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">提示:</p><ul class=""><li id="fb48" class="kb kc hu je b jf jg jj jk jn kd jr ke jv kf jz kg kh ki kj dt translated">阅读论文的第2部分(ConvNet配置)。</li><li id="02a9" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">别忘了Keras包括:<br/>比如你要用<code class="eh mk ml mm mn b">keras.layers.pooling.MaxPooling2D</code>，导入为:<code class="eh mk ml mm mn b">from keras.layers.pooling import MaxPooling2D</code>。这将使代码更具可读性。</li><li id="4d89" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">如果遇到困难，可以看看Keras文档中的例子。</li></ul><h1 id="7cff" class="lp kq hu bd kr lq lr ls kv lt lu lv kz lw lx ly lc lz ma mb lf mc md me li mf dt translated"><strong class="ak">练习3 </strong></h1><p id="bba0" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">将您的结果与VGG 的<a class="ae mj" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank"> Keras实现进行比较。检查您的网络的参数数量是否与Keras的相同。你可以使用<code class="eh mk ml mm mn b">model.summary()</code>来显示你的网络中每一层的参数数量和输出形状。</a></p><h1 id="aa90" class="lp kq hu bd kr lq lr ls kv lt lu lv kz lw lx ly lc lz ma mb lf mc md me li mf dt translated">获得解决方案</h1><p id="71a3" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">对于这一部分，我将更多地关注获得解决方案的过程，而不是解决方案本身。</p><h2 id="5203" class="kp kq hu bd kr ks kt ku kv kw kx ky kz jn la lb lc jr ld le lf jv lg lh li lj dt translated">练习0</h2><p id="c86f" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">对于第一个练习，我做了每次开始阅读论文的第一件事:阅读摘要，阅读结论，然后浏览寻找有趣的结果(通常是表格和图表)。</p><p id="0a80" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">表3和表4中显示的结果表明，最佳网络配置是D和e。这些配置的体系结构如表1所示。请注意，您不需要阅读整篇文章来查找这些信息，因为您需要的一切(目前)都可以通过快速浏览图像和表格来轻松找到。</p><p id="0855" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我决定实现配置D，因为它实际上具有与配置E相同的性能，但架构更简单(16个而不是19个convnets)。</p><figure class="mp mq mr ms fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mo"><img src="../Images/93e345e1896bc3381b9261b85a38412f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FRd9fDM1TXThW2V8ylL7VQ.png"/></div></div></figure><h2 id="9a1d" class="kp kq hu bd kr ks kt ku kv kw kx ky kz jn la lb lc jr ld le lf jv lg lh li lj dt translated">练习1</h2><p id="2fb1" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">我们想了解网络架构。从我们的第一个练习中，我们知道不同的配置如表1所示。在表格描述中，我们可以了解到<code class="eh mk ml mm mn b">conv3–64</code>是一个卷积层，感受野大小为3x3，64个通道(滤波器):</p><blockquote class="mt mu mv"><p id="d275" class="jc jd ka je b jf jg jh ji jj jk jl jm mw jo jp jq mx js jt ju my jw jx jy jz hn dt translated">卷积层参数被表示为“channels⟩的conv⟨receptive场size⟩-⟨number”</p></blockquote><p id="ed16" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">然而，该表没有说明任何关于卷积填充和步幅的信息。为了找到这些，我们再一次浏览论文。</p><figure class="mp mq mr ms fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mz"><img src="../Images/2b54efd6b8e80e925213746edf81cf73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DwsWBmGCI7qL9ei7n_SdXA.png"/></div></div><figcaption class="na nb fg fe ff nc nd bd b be z ek">Taking notes on the paper help you organize your ideas better. It does matter if you print the paper and use a pen or if you do it digitally, but always take notes.</figcaption></figure><p id="bd84" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在我们知道了网络架构的一切:</p><ul class=""><li id="f55e" class="kb kc hu je b jf jg jj jk jn kd jr ke jv kf jz kg kh ki kj dt translated">输入尺寸:224 x 224</li><li id="5af8" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">感受野大小为3×3；</li><li id="613b" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">卷积步距是1个像素；</li><li id="0c04" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">填充是1(对于3×3的感受野),所以我们保持相同的空间分辨率；</li><li id="46c0" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">最大池是2×2，步长为2个像素；</li><li id="c00c" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">有两个完全连接的层，每个层有4096个单元；</li><li id="9cc6" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">最后一层是具有1000个单元的softmax分类层(代表1000个ImageNet类)；</li><li id="4d0f" class="kb kc hu je b jf kk jj kl jn km jr kn jv ko jz kg kh ki kj dt translated">激活功能是ReLU</li></ul><p id="34e5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们现在可以计算可学习参数的数量。</p><p id="4c68" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">您可以在第2.3节(讨论)中找到此信息。</p><p id="b0fa" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于第一卷积层，网络必须沿着输入深度(3)学习64个大小为3×3的滤波器。加上64个滤波器每一个都有偏差，所以参数总数是<code class="eh mk ml mm mn b">64*3*3*3 + 64 = 1792</code>。您可以对其他卷积层应用相同的逻辑。</p><p id="0d8a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">层输出的深度将是其卷积滤波器的数量。填充被选择为1个像素，因此空间分辨率通过卷积层得以保持。因此，空间分辨率将仅在汇集层发生变化。所以，第一个卷积层的输出将是<code class="eh mk ml mm mn b">224 x 224 x 64</code>。</p><p id="2b12" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">池层不学习任何东西，所以我们有0个可学习的参数。为了计算池层的输出形状，我们必须考虑窗口的大小和步幅。由于窗口为2 x 2，跨距为2，因此图层每2 x 2个像素输出一个像素，并跳跃2个像素进行下一次计算(不会发生重叠)，因此空间分辨率在每个池图层中除以2。深度保持不变。</p><p id="1a0d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">为了计算全连接层中的参数数量，我们必须将前一层中的单元数量乘以当前层中的单元数量。按照前面几段介绍的逻辑，可以看到最后一个卷积层的单元数将是<code class="eh mk ml mm mn b">7x7x512</code>。因此，对于配置d，第一个全连接层中的参数总数将是<code class="eh mk ml mm mn b">7x7x512x4096 + 4096 = 102764544</code></p><p id="b256" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果可以将参数总数与纸上的结果进行比较(表2):</p><figure class="mp mq mr ms fq iv fe ff paragraph-image"><div class="fe ff ne"><img src="../Images/4644d8980e9389e2566761b9fd53b78e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*cY2yGoETl0jBrtky8PGysg.png"/></div></figure><h2 id="d66a" class="kp kq hu bd kr ks kt ku kv kw kx ky kz jn la lb lc jr ld le lf jv lg lh li lj dt translated">练习2</h2><p id="0378" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">在Keras文档的第一页，您会发现您需要创建一个<code class="eh mk ml mm mn b">Sequential</code>模型:</p><pre class="mp mq mr ms fq nf mn ng nh aw ni dt"><span id="42e0" class="kp kq hu mn b fv nj nk l nl nm">from keras.models import Sequential<br/>model = Sequential()</span></pre><p id="f968" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">并用<code class="eh mk ml mm mn b">model.add()</code>添加图层。另一种方法是将一个层列表传递给<code class="eh mk ml mm mn b">Sequential</code>构造函数(我使用了这种方法)。</p><p id="ae7d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最难的部分是为每一层定义精确的参数。这可以通过查看文档来完成:<code class="eh mk ml mm mn b"><a class="ae mj" href="https://keras.io/layers/convolutional/" rel="noopener ugc nofollow" target="_blank">Convolutional</a></code>、<code class="eh mk ml mm mn b"><a class="ae mj" href="https://keras.io/layers/pooling/" rel="noopener ugc nofollow" target="_blank">Pooling</a></code>和<code class="eh mk ml mm mn b"><a class="ae mj" href="https://keras.io/layers/core/" rel="noopener ugc nofollow" target="_blank">Core</a></code>层。</p><p id="f42d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们首先定义我们将使用哪些层。由于VGG网络处理图像，我们将使用<code class="eh mk ml mm mn b"><a class="ae mj" href="https://keras.io/layers/convolutional/#conv2d" rel="noopener ugc nofollow" target="_blank">Conv2D</a></code>和<code class="eh mk ml mm mn b"><a class="ae mj" href="https://keras.io/layers/pooling/#maxpooling2d" rel="noopener ugc nofollow" target="_blank">MaxPooling2D</a></code>。阅读关于这些层类型的全部文档很重要。</p><p id="0b34" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于<code class="eh mk ml mm mn b">Conv2D</code>层，我们首先要注意的是:</p><blockquote class="mt mu mv"><p id="5e38" class="jc jd ka je b jf jg jh ji jj jk jl jm mw jo jp jq mx js jt ju my jw jx jy jz hn dt translated">当使用该层作为模型中的第一层时，提供关键字参数<code class="eh mk ml mm mn b">input_shape</code>(整数元组，不包括样本轴)，例如<code class="eh mk ml mm mn b">data_format="channels_last"</code>中的128x128 RGB图片的<code class="eh mk ml mm mn b">input_shape=(128, 128, 3)</code>。</p></blockquote><p id="0f26" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">因此，我们必须定义图像的<code class="eh mk ml mm mn b">input_shape</code>。从练习2中，我们注意到输入大小是<code class="eh mk ml mm mn b">224x224</code>。我们正在处理彩色图像，所以我们输入的深度是3。</p><p id="2df6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">通过阅读<code class="eh mk ml mm mn b">Conv2D</code>参数，我们了解了如何定义内核的大小、步幅、填充和激活函数。</p><p id="fdba" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">需要注意的一个重要参数是<code class="eh mk ml mm mn b">data_format</code>。它用于定义Keras中数据流的顺序。因为我不想为Keras中的每个程序设置这个参数，所以我编辑了<code class="eh mk ml mm mn b">~/keras/keras.json</code>来设置一个默认值:</p><pre class="mp mq mr ms fq nf mn ng nh aw ni dt"><span id="ed13" class="kp kq hu mn b fv nj nk l nl nm">{<br/>    "image_data_format": "channels_last"<br/>    # (...) other configs<br/>}</span></pre><p id="8490" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们需要使用的参数有<code class="eh mk ml mm mn b">filters</code>、<code class="eh mk ml mm mn b">kernel_size</code>、<code class="eh mk ml mm mn b">strides</code>、<code class="eh mk ml mm mn b">padding</code>和<code class="eh mk ml mm mn b">activation</code>。如果您打算稍后训练模型，其他一些参数可能是有用的，例如<code class="eh mk ml mm mn b">kernel_initializer</code>。</p><p id="fd99" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">设置过滤器，内核大小和步幅是微不足道的。设置激活功能需要您进入<a class="ae mj" href="https://keras.io/activations/" rel="noopener ugc nofollow" target="_blank">激活文档</a>。</p><p id="3622" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><code class="eh mk ml mm mn b">padding</code> : <code class="eh mk ml mm mn b">valid</code>或<code class="eh mk ml mm mn b">same</code>有两种选择。不清楚它们是什么意思，所以我不得不谷歌一下。我发现<a class="ae mj" href="https://github.com/fchollet/keras/issues/1984" rel="noopener ugc nofollow" target="_blank">这个</a>和<a class="ae mj" href="http://datascience.stackexchange.com/questions/11840/border-mode-for-convolutional-layers-in-keras" rel="noopener ugc nofollow" target="_blank">这个</a>。另一种方法是直接查看<a class="ae mj" href="https://github.com/fchollet/keras/blob/5cef75219abc339b64e35f221775692d3cf04b84/keras/utils/conv_utils.py#L89-L115" rel="noopener ugc nofollow" target="_blank"> Keras实现</a>。</p><blockquote class="mt mu mv"><p id="23ea" class="jc jd ka je b jf jg jh ji jj jk jl jm mw jo jp jq mx js jt ju my jw jx jy jz hn dt translated">当边界模式为“有效”时，您得到的输出小于输入，因为卷积仅在输入和滤波器完全重叠时计算。</p><p id="2b75" class="jc jd ka je b jf jg jh ji jj jk jl jm mw jo jp jq mx js jt ju my jw jx jy jz hn dt translated">使用“相同”边界模式，您将获得与输入“相同”大小的输出。这意味着过滤器必须超出输入范围“过滤器大小/ 2”，输入范围之外的区域通常用零填充。</p></blockquote><p id="da1b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">所以，我们希望填充设置为<code class="eh mk ml mm mn b">same</code>。</p><p id="aad2" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于<code class="eh mk ml mm mn b">MaxPooling2D</code>层，我们需要设置步幅、池大小和填充。因为我们想要零填充，所以我们只使用<code class="eh mk ml mm mn b">padding="valid"</code>。由于<code class="eh mk ml mm mn b">valid</code>是<code class="eh mk ml mm mn b">padding</code>的默认值，我们可以省略这个参数(但是请注意，Keras API变化很大，因此这可能会导致Keras未来版本的架构发生变化)。</p><p id="31ca" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在我们调用全连接(<code class="eh mk ml mm mn b">Dense</code>层)之前，我们需要展平最后一个卷积网络的输出。这将会重塑到1D的convnet的3D输出。</p><p id="d569" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最后，对于<code class="eh mk ml mm mn b">Dense</code>层，我们只需要设置单元数和激活函数。</p><p id="fc95" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最后的代码非常简洁:</p><figure class="mp mq mr ms fq iv"><div class="bz el l di"><div class="nn no l"/></div></figure><p id="9531" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">请注意，我没有包括脱落层，也没有设置权重初始值，因为我们仍然对训练步骤不感兴趣。</p><p id="f6c4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你可以在这里找到Keras对VGG的实现。</p><h2 id="df25" class="kp kq hu bd kr ks kt ku kv kw kx ky kz jn la lb lc jr ld le lf jv lg lh li lj dt translated">练习3</h2><p id="b6d1" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">您可以通过运行以下命令来检查VGG16或VGG19架构:</p><pre class="mp mq mr ms fq nf mn ng nh aw ni dt"><span id="edac" class="kp kq hu mn b fv nj nk l nl nm">from keras.applications import VGG16, VGG19<br/>VGG16.summary()<br/>VGG19.summary()</span></pre><h1 id="bfc8" class="lp kq hu bd kr lq lr ls kv lt lu lv kz lw lx ly lc lz ma mb lf mc md me li mf dt translated">超出</h1><p id="1aa1" class="pw-post-body-paragraph jc jd hu je b jf lk jh ji jj ll jl jm jn mg jp jq jr mh jt ju jv mi jx jy jz hn dt translated">一个有趣的下一步是训练VGG16。然而，训练ImageNet是更复杂的任务。VGG文件指出:</p><blockquote class="mt mu mv"><p id="6645" class="jc jd ka je b jf jg jh ji jj jk jl jm mw jo jp jq mx js jt ju my jw jx jy jz hn dt translated">在配备了四个NVIDIA Titan Black GPUs的系统上，根据架构的不同，训练单个网络需要2-3周的时间。</p></blockquote><p id="7af2" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">即使你有几千美元的设备，那也是很长的时间。</p><p id="ad98" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">尽管如此，一个有趣的练习将是尝试看看你将如何再现训练和测试设置的一些有趣的方面，例如包括丢弃层、设置优化器、编译模型、玩预处理等。</p><p id="f1c3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你也可以尝试使用预先训练好的重量在VGG顶部进行微调。我打算很快创建一个关于这个主题的教程。</p><p id="d52c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">另外，您可以阅读<a class="ae mj" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank"> Inception network </a>并尝试实现它。</p><div class="mp mq mr ms fq ab cb"><figure class="np iv nq nr ns nt nu paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="np iv nq nr ns nt nu paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="np iv nq nr ns nt nu paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="mt mu mv"><p id="f922" class="jc jd ka je b jf jg jh ji jj jk jl jm mw jo jp jq mx js jt ju my jw jx jy jz hn dt translated"><a class="ae mj" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae mj" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae mj" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae mj" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="jc jd ka je b jf jg jh ji jj jk jl jm mw jo jp jq mx js jt ju my jw jx jy jz hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae mj" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae mj" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="mp mq mr ms fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nv"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></div></figure></div></div>    
</body>
</html>