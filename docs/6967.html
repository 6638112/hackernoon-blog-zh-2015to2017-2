<html>
<head>
<title>Training an Architectural Classifier — II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练建筑分类器— II</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/training-an-architectural-classifier-ii-bf29eca3cfa6?source=collection_archive---------25-----------------------#2017-10-11">https://medium.com/hackernoon/training-an-architectural-classifier-ii-bf29eca3cfa6?source=collection_archive---------25-----------------------#2017-10-11</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="9b03" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">Softmax回归</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/2c8a43e84672c593835fbb5f4fcf2b35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OgXQZCAyz3WO-yAA70Ubg.png"/></div></div></figure><p id="9023" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><em class="kr">这是5篇文章系列的第2部分:</em></p><ol class=""><li id="a045" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq kx ky kz la dt translated"><a class="ae lb" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-5f1b4f512368"> <em class="kr">训练一个架构分类器:动机</em> </a></li><li id="4d9f" class="ks kt hu jx b jy lc kb ld ke le ki lf km lg kq kx ky kz la dt translated"><a class="ae lb" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-ii-bf29eca3cfa6"> <em class="kr">训练一个架构分类器:Softmax回归</em> </a></li><li id="8d2c" class="ks kt hu jx b jy lc kb ld ke le ki lf km lg kq kx ky kz la dt translated"><a class="ae lb" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iii-84dd5f3cf51c"> <em class="kr">训练一个架构分类器:深度神经网络</em> </a></li><li id="b116" class="ks kt hu jx b jy lc kb ld ke le ki lf km lg kq kx ky kz la dt translated"><a class="ae lb" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iv-4f76bc6844bc"> <em class="kr">训练一个架构分类器:卷积网络</em> </a></li><li id="6317" class="ks kt hu jx b jy lc kb ld ke le ki lf km lg kq kx ky kz la dt translated"><a class="ae lb" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-v-fe82e83e94ec"> <em class="kr">训练一个架构分类器:迁移学习</em> </a></li></ol><p id="b996" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><em class="kr">这个项目的一个个人目标是随着深入的</em> <a class="ae lb" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank"> <em class="kr">学习</em> </a> <em class="kr">框架而变得越来越有质量，所以尽管sklearn之类的可能有一个逻辑回归模块，但我将在TensorFlow中更多地手动完成这项工作。你还会看到tf.slim和Keras。</em></p><p id="e2ff" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt lh translated"><span class="l li lj lk bm ll lm ln lo lp di">我们</span>认为最好从一个<strong class="jx hv">更简单、更容易解释的模型</strong>开始，只有在<a class="ae lb" href="https://hackernoon.com/tagged/nessecary" rel="noopener ugc nofollow" target="_blank">必要时</a>才增加复杂性，我将从尝试简单的逻辑/softmax回归开始。简而言之，逻辑回归的目标是通过获取输入图像，将其所有特征(本例中为像素)乘以一组正或负权重，然后添加一点偏差来进行预测。</p><p id="7012" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这对于任何有一些数学经验的人来说应该很熟悉，这是一条线的方程:<a class="ae lb" href="http://mathworld.wolfram.com/LinearEquation.html" rel="noopener ugc nofollow" target="_blank"> y=mx+b </a>，除了在这种情况下，我们的线存在于非常高维的空间中(m、x和b是高维矩阵，而不是你在学校中使用的标量)。当你考虑到我们试图做的是通过空间画一条线，或<a class="ae lb" href="https://en.wikipedia.org/wiki/Hyperplane" rel="noopener ugc nofollow" target="_blank">超平面</a>，可以将一个类别的图像与另一个类别的图像分开时，这就有了一些直观的意义。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff lq"><img src="../Images/89a5f25003f35c6af4408b57987e5a13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*gPzJ5mhwdBO52TID9rcCcw@2x.png"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">The basic formula for making a prediction — or drawing a line.</figcaption></figure><p id="66a5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这些权重表示像素在某一类别中对整体图像做出积极或消极贡献的学习可能性。因此，像素值乘以学习的权重，给出了对最终结果的一种“投票”。使用softmax函数，这些投票然后被转换成图像属于给定类别的概率。虽然我互换使用了术语逻辑和softmax，但这是逻辑和softmax回归之间的主要区别，softmax将完成逻辑所做的事情，但跨越多个类。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff lv"><img src="../Images/6d28e9c79e8ca3f200fa7d2761612a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*vz9WitVXiK3KM28n9JgTgw@2x.png"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">softmax function, converts linear inputs to probabilities</figcaption></figure><p id="402e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">权重通过称为<em class="kr">梯度下降</em>和<em class="kr">反向传播</em>的迭代过程来学习，由此误差被归因于每次预测的特定权重，该权重被向上或向下修改，然后再次尝试。在这种情况下，我们使用一种称为交叉熵的误差度量，它收集真实类别乘以预测类别的负对数的乘积的平均值。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff lw"><img src="../Images/11dcae9ea31d563cfe935c159c159a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfdTMu438ihi0Dft9eTklA@2x.png"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">cross-entropy loss, collects the incorrect predictions into a single metric</figcaption></figure><p id="d871" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这是一个简单的模型，所以我将让笔记本来完成这里的其余部分:</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lx ly l"/></div></figure><p id="d113" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">总之，我们可以做得更好。即使经过更长时间的训练，最好的情况准确率大约是<strong class="jx hv"> 57% </strong>。这是超过5000个时期的精确度的张量图:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff lz"><img src="../Images/ad0c15d165b5b9c3c29e7f039683a7a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4cy36IGk3jWPiozSNVgEQ.png"/></div></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek">Accuracy over training epochs. Blue: training accuracy, Purple: validation accuracy</figcaption></figure><p id="aeed" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">即使在训练数据上，该模型的准确性也远低于人类的准确性，这表明该模型可能不够复杂，无法从提供给它的大量特征中提取有意义的信息。训练和验证准确性之间的巨大差异也表明模型<strong class="jx hv">过度适应</strong>它<em class="kr">能够</em>提取的信息。</p><p id="2aea" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">那么如果我们把这个单神经元分类器扩展成深度神经网络呢？这将在我的下一篇文章中发表:</p><p id="df76" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><a class="ae lb" rel="noopener" href="/@mcculloughrt/training-an-architectural-classifier-iii-84dd5f3cf51c">接下来:架构分类器——深度神经网络</a></p><p id="d1fb" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><a class="ae lb" href="https://upscri.be/hackernoon/" rel="noopener ugc nofollow" target="_blank">https://upscri.be/hackernoon/</a></p></div></div>    
</body>
</html>