<html>
<head>
<title>Getting to Know TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解张量流</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/machine-learning-with-tensorflow-8873fdee2b68?source=collection_archive---------1-----------------------#2016-11-08">https://medium.com/hackernoon/machine-learning-with-tensorflow-8873fdee2b68?source=collection_archive---------1-----------------------#2016-11-08</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="eaf2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">本文摘自</em> <a class="ae jq" href="https://manning.com/books/machine-learning-with-tensorflow?a_aid=TensorFlow&amp;a_bid=042443a4" rel="noopener ugc nofollow" target="_blank"> <em class="jp">用TensorFlow进行机器学习</em> </a> <em class="jp">。</em></p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff jr"><img src="../Images/7500a5251b34e952754b0a307753ee57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*xvNZGOmKHEUKO9lqnjDB9g.png"/></div></figure><p id="81c5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt jz translated">在进入<a class="ae jq" href="https://hackernoon.com/tagged/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a> <a class="ae jq" href="https://hackernoon.com/tagged/algorithms" rel="noopener ugc nofollow" target="_blank">算法</a>之前，你应该先熟悉如何使用这些工具。本文涵盖了TensorFlow的一些基本优势，让您相信它是机器学习库的首选。</p><p id="026a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">作为一个思想实验，让我们想象一下，当我们在没有方便的计算库的情况下编写Python代码时会发生什么。这就像使用一部新的智能手机而不安装任何额外的应用程序一样。手机仍然工作，但如果你有正确的应用程序，你会更有效率。</p><blockquote class="ki kj kk"><p id="ddb5" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated"><strong class="it hv">考虑以下情况… </strong> <em class="hu">你是一名跟踪销售流程的企业主。你想计算你销售产品的收入。您的库存包括100种不同的产品，您用一个名为</em> prices <em class="hu">的向量来表示每种价格。另一个大小为100的向量称为</em> amounts <em class="hu">表示每个商品的库存数量。您可以编写清单1所示的Python代码来计算销售所有产品的收入。请记住，这段代码没有导入任何库。</em></p></blockquote><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="ko kp l"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek"><strong class="ak">Listing 1. Computing the inner product of two vectors without using any library</strong></figcaption></figure><p id="3cb3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">仅仅是计算两个向量的内积(也称为<em class="jp">点积</em>)就有很多代码。想象一下更复杂的事情需要多少代码，比如解线性方程或计算两个向量之间的距离。</p><p id="fa1a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">通过安装TensorFlow库，您还安装了一个著名的健壮的Python库NumPy，它有助于Python中的数学操作。使用Python而不使用它的库(例如NumPy和TensorFlow)就像使用没有自动对焦的相机一样:你获得了更多的灵活性，但是你很容易犯粗心的错误。在机器学习中犯错误已经很容易了，所以让我们保持相机自动对焦，并使用TensorFlow来帮助自动化一些繁琐的软件开发。</p><p id="2089" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">清单2展示了如何使用NumPy简洁地编写相同的内积。</p><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="ko kp l"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek"><strong class="ak">Listing 2. Computing the inner product using NumPy</strong></figcaption></figure><p id="9d99" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Python是一种简洁的语言。幸运的是，这意味着你不会看到一页又一页的神秘代码。另一方面，Python语言的简洁性意味着每一行代码背后都发生了很多事情，您应该在工作中仔细熟悉这些事情。</p><blockquote class="ki kj kk"><p id="d4d0" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated"><strong class="it hv">顺便说一下……</strong>关于Python和TensorFlow的c++ API的各种函数的详细文档可在https://www.tensorflow.org/api_docs/index.html<a class="ae jq" href="https://www.tensorflow.org/api_docs/index.html" rel="noopener ugc nofollow" target="_blank">获得</a>。</p></blockquote><p id="6d3b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">本文旨在使用TensorFlow进行计算，因为机器学习依赖于数学公式。浏览完示例和代码清单后，您将能够使用TensorFlow完成一些任意任务，比如计算大数据的统计数据。这里的重点将完全是关于如何使用TensorFlow，而不是一般的机器学习。</p><p id="1e27" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">机器学习算法需要大量的数学运算。通常，一个算法归结为一个简单函数的组合，迭代直到收敛。当然，您可以使用任何标准的编程语言来执行这些计算，但是可管理和高性能代码的秘密在于使用编写良好的库。</p><p id="6097" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">听起来是个温和的开始，对吧？<strong class="it hv">事不宜迟，让我们编写第一个张量流代码吧！</strong></p><h1 id="e2bc" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated"><strong class="ak"> <em class="ls">保证张量流工作</em> </strong></h1><p id="b3f1" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt jz translated">首先，我们需要确保一切正常运行。检查你汽车的油位，修理你地下室的保险丝，确保你的信用余额为零。</p><p id="f75b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">开玩笑，我说的是TensorFlow。</p><p id="9158" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">继续为我们的第一段代码创建一个名为<em class="jp"> test.py </em>的新文件。通过运行以下脚本导入TensorFlow:</p><pre class="js jt ju jv fq ly lz ma mb aw mc dt"><span id="134c" class="md kv hu lz b fv me mf l mg mh">import tensorflow as tf</span></pre><p id="eb76" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这个单一的进口准备TensorFlow为您的投标。<strong class="it hv"> </strong>如果Python解释器没有抱怨，那么我们就准备开始使用TensorFlow了！</p><blockquote class="ki kj kk"><p id="ada4" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated"><strong class="it hv">有技术难度？</strong>在这一步出现错误的一个常见原因是，如果您安装了GPU版本，库无法搜索CUDA驱动程序。记住，如果你用CUDA编译库，你需要用CUDA的路径更新你的环境变量。查看TensorFlow上的CUDA说明。(详见<a class="ae jq" href="https://www.tensorflow.org/versions/master/get_started/os_setup.html#optional-linux-enable-gpu-support" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/versions/master/get _ started/OS _ setup . html # optional-Linux-enable-GPU-support</a>)。</p></blockquote><h2 id="de80" class="md kv hu bd kw mi mj mk la ml mm mn le jc mo mp li jg mq mr lm jk ms mt lq mu dt translated"><strong class="ak">坚持张量流惯例</strong></h2><p id="61c9" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt translated">TensorFlow库通常用<em class="jp"> tf </em>限定名导入。一般来说，用<em class="jp"> tf </em>限定TensorFlow是一个与其他开发者和开源TensorFlow项目保持一致的好主意。您可以选择不对其进行限定或更改限定名，但是在您自己的项目中成功重用他人的TensorFlow代码片段将是一个复杂的过程。</p><h2 id="4ae5" class="md kv hu bd kw mi mj mk la ml mm mn le jc mo mp li jg mq mr lm jk ms mt lq mu dt translated"><strong class="ak"> <em class="ls">代表张量</em> </strong></h2><p id="ffbb" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt translated">现在我们知道了如何将TensorFlow导入到Python源文件中，让我们开始使用它吧！描述现实世界中的物体的一种简便方法是列出它的属性或特征。例如，您可以通过颜色、型号、发动机类型和里程数来描述汽车。一些特征的有序列表被称为<em class="jp">特征向量</em>，这正是我们将在TensorFlow代码中表示的内容。</p><p id="2818" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">特征向量是机器学习中最有用的设备之一，因为它们简单(它们是数字列表)。每个数据项通常由一个特征向量组成，一个好的数据集即使没有几千个特征向量，也有几千个。毫无疑问，你经常会同时处理多个向量。一个<em class="jp">矩阵</em>简洁地表示一个向量列表，其中矩阵的每一列都是一个特征向量。</p><p id="3b23" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在TensorFlow中表示矩阵的语法是向量的向量，每个向量的长度都相同。图1是一个两行三列的矩阵的例子，比如[[1，2，3]，[4，5，6]]。注意，这是一个包含两个元素的向量，每个元素对应于矩阵的一行。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mv"><img src="../Images/b6ca20efa639202586f2f6c6a5fc8845.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*KfxD28aLzP1Svj80NZeyPA.png"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek">Figure 1. The matrix in the lower half of the diagram is a visualization from its compact code notation in the upper half of the diagram. This form of notation is a common paradigm in most scientific computing libraries.</figcaption></figure><p id="c255" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们通过指定矩阵的行和列索引来访问矩阵中的元素。例如，第一行和第一列表示第一个左上角的元素。有时使用两个以上的索引会很方便，例如在彩色图像中不仅通过像素的行和列，还通过其红/绿/蓝通道来引用像素时。<em class="jp">张量</em>是通过任意数量的索引来指定元素的矩阵的推广。</p><blockquote class="ki kj kk"><p id="a1ff" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated"><strong class="it hv">张量的例子… </strong>假设一所小学强制给学生分配座位。你是校长，而且你记不住名字。幸运的是，每个教室都有一个座位网格，你可以很容易地根据学生的行列索引给他们起绰号。</p><p id="36f0" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated">有多个教室，不能说“早上好4，10！继续努力。”您还需要指定教室，“您好，4，10来自教室2。”与一个矩阵只需要两个指数来指定一个元素不同，这个学校的学生需要三个数。它们都是三阶张量的一部分！</p></blockquote><p id="163a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">张量的语法甚至是嵌套的向量。例如，一个2乘3乘2的张量是[[[1，2]，[3，4]，[5，6]]，[[7，8]，[9，10]，[11，12]]，可以认为是两个矩阵，大小都是3乘2。因此，我们说这个张量的秩为3。一般来说，张量的秩是指定一个元素所需的指数数。TensorFlow中的机器学习算法作用于张量，理解如何使用它们很重要。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mw"><img src="../Images/6a1a16dfcf0b08bd1bf1cf35a979826f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*bcVHGX66iW8A72i5aaD4bw.png"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek">Figure 2. This tensor can be thought of as multiple matrices stacked on top of each other. To specify an element, you must indicate the row and column, as well as which matrix is being accessed. Therefore, the rank of this tensor is three.</figcaption></figure><p id="6891" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">很容易迷失在表示张量的许多方法中。直观地说，清单3中接下来的三行代码都试图表示相同的2乘2矩阵。这个矩阵代表两个二维的特征向量。例如，它可以表示两个人对两部电影的评价。每个人，由矩阵的行索引，分配一个数字来描述他或她对电影的评论，由列索引。运行代码，查看如何在TensorFlow中生成矩阵。</p><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="ko kp l"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek"><strong class="ak">Listing 3. Different ways to represent tensors</strong></figcaption></figure><p id="5a75" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">第一个变量(<em class="jp"> m1 </em>)是一个列表，第二个变量(<em class="jp"> m2 </em>)是NumPy库中的一个<em class="jp"> ndarray </em>，最后一个变量(<em class="jp"> m3 </em>)是TensorFlow的<em class="jp">张量</em>对象。TensorFlow中的所有操作符，比如<em class="jp"> neg </em>，都是设计用来操作张量对象的。一个方便的函数是<em class="jp">TF . convert _ to _ tensor(…)</em>，我们可以在任何地方使用它来确保我们处理的是张量，而不是其他类型的张量。TensorFlow库中的大多数函数已经执行了该功能(冗余)，即使您忘记了。使用<em class="jp">TF . convert _ to _ tensor(…)</em>是可选的，但我在这里展示它是因为它有助于揭开整个库中正在处理的隐式类型系统。前面提到的清单3三次产生以下输出:</p><pre class="js jt ju jv fq ly lz ma mb aw mc dt"><span id="1d67" class="md kv hu lz b fv me mf l mg mh">&lt;class ‘tensorflow.python.framework.ops.Tensor’&gt;</span></pre><p id="bfdf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们再来看看在代码中定义张量。导入TensorFlow库后，我们可以使用清单4中的常量操作符。</p><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="ko kp l"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek"><strong class="ak">Listing 4. Creating tensors</strong></figcaption></figure><p id="fa60" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">运行清单4会产生以下输出:</p><pre class="js jt ju jv fq ly lz ma mb aw mc dt"><span id="10f0" class="md kv hu lz b fv me mf l mg mh">Tensor( “Const:0”,<br/>        shape=TensorShape([Dimension(1), <br/>                           Dimension(2)]),<br/>        dtype=float32 )</span><span id="8d11" class="md kv hu lz b fv mx mf l mg mh">Tensor( “Const_1:0”,<br/>        shape=TensorShape([Dimension(2), <br/>                           Dimension(1)]),<br/>        dtype=int32 )</span><span id="322e" class="md kv hu lz b fv mx mf l mg mh">Tensor( “Const_2:0”,<br/>         shape=TensorShape([Dimension(2), <br/>                            Dimension(3), <br/>                            Dimension(2)]),<br/>         dtype=int32 )</span></pre><p id="6d4e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">从输出中可以看到，每个张量都由名副其实的<em class="jp">张量</em>对象表示。每个<em class="jp">张量</em>对象都有一个唯一的标签(<em class="jp">名称</em>)、一个维度(<em class="jp">形状</em>)来定义其结构，以及数据类型(<em class="jp">数据类型</em>)来指定我们将操作的值的种类。因为我们没有明确提供名称，所以库自动生成了它们:“Const:0”、“Const_1:0”和“Const_2:0”。</p><h2 id="fa5c" class="md kv hu bd kw mi mj mk la ml mm mn le jc mo mp li jg mq mr lm jk ms mt lq mu dt translated"><strong class="ak">张量类型</strong></h2><p id="11ff" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt translated">注意<em class="jp">矩阵1 </em>的每个元素都以小数点结尾。小数点告诉Python元素的数据类型不是整数，而是浮点数。我们可以传入显式的<em class="jp"> dtype </em>值。与NumPy数组非常相似，张量采用的数据类型指定了我们将在张量中操作的值的种类。</p><p id="9a6d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">TensorFlow还为一些简单的张量提供了一些方便的构造函数。例如，<em class="jp"> tf.zeros(shape) </em>创建一个张量，其所有值在特定形状的零处初始化。类似地，<em class="jp"> tf.ones(shape) </em>创建一个特定形状的张量，所有值初始化为1。shape参数是一个类型为<em class="jp"> int32 </em>(整数列表)的一维(1D)张量，描述了张量的维数。</p><h1 id="94ab" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated"><strong class="ak"> <em class="ls">创建操作符</em> </strong></h1><p id="d3c3" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt jz translated">现在我们已经有了一些可以使用的初始张量，我们可以应用更多有趣的运算符，比如加法或乘法。考虑一个矩阵中的每一行，代表与另一个人之间的货币交易(正值)和货币交易(负值)。否定矩阵是表示对方资金流向的交易历史的一种方式。让我们从简单开始，对清单4中的<em class="jp">矩阵1 </em>张量运行求反运算。对矩阵求负会将正数变成相同大小的负数，反之亦然。</p><p id="afab" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">否定是最简单的运算之一。如清单5所示，求反只接受一个张量作为输入，并生成一个每个元素都被求反的张量——现在，尝试自己运行代码。如果你掌握了如何定义否定，它将提供一个垫脚石，把这个技巧推广到所有其他张量流运算。</p><blockquote class="ki kj kk"><p id="62a5" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated"><strong class="it hv">先不说… </strong> <em class="hu">定义</em>一个运算，比如否定，不同于<em class="hu">运行</em>它。</p></blockquote><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="ko kp l"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek"><strong class="ak">Listing 5 Using the negation operator</strong></figcaption></figure><p id="88e8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">清单5生成以下输出:</p><pre class="js jt ju jv fq ly lz ma mb aw mc dt"><span id="8ebe" class="md kv hu lz b fv me mf l mg mh">Tensor(“Neg:0”, shape=(1, 2), dtype=int32)</span></pre><h2 id="22a6" class="md kv hu bd kw mi mj mk la ml mm mn le jc mo mp li jg mq mr lm jk ms mt lq mu dt translated"><strong class="ak">有用的张量流算子</strong></h2><p id="712e" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt translated">官方文档仔细地列出了所有可用的数学运算:<a class="ae jq" href="https://www.tensorflow.org/api_docs/Python/math_ops.html" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/Python/math_ops.html</a>。</p><p id="cb8e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">常用运算符的一些具体示例包括:</p><pre class="js jt ju jv fq ly lz ma mb aw mc dt"><span id="b300" class="md kv hu lz b fv me mf l mg mh">tf.add(x, y) <br/>Add two tensors of the same type, x + y</span><span id="26d3" class="md kv hu lz b fv mx mf l mg mh">tf.sub(x, y) <br/>Subtract tensors of the same type, x — y</span><span id="db46" class="md kv hu lz b fv mx mf l mg mh">tf.mul(x, y) <br/>Multiply two tensors element-wise</span><span id="c019" class="md kv hu lz b fv mx mf l mg mh">tf.pow(x, y) <br/>Take the element-wise power of x to y</span><span id="bbd4" class="md kv hu lz b fv mx mf l mg mh">tf.exp(x) <br/>Equivalent to pow(e, x), where e is Euler’s number (2.718…)</span><span id="326e" class="md kv hu lz b fv mx mf l mg mh">tf.sqrt(x) <br/>Equivalent to pow(x, 0.5)</span><span id="2826" class="md kv hu lz b fv mx mf l mg mh">tf.div(x, y) <br/>Take the element-wise division of x and y</span><span id="376e" class="md kv hu lz b fv mx mf l mg mh">tf.truediv(x, y) <br/>Same as tf.div, except casts the arguments as a float</span><span id="f700" class="md kv hu lz b fv mx mf l mg mh">tf.floordiv(x, y) <br/>Same as truediv, except rounds down the final answer into an integer</span><span id="eedb" class="md kv hu lz b fv mx mf l mg mh">tf.mod(x, y) <br/>Takes the element-wise remainder from division</span></pre><blockquote class="ki kj kk"><p id="56ab" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated"><strong class="it hv">练习… </strong>使用我们学过的张量流运算符生成高斯分布(也称为正态分布)。参见图3中的提示。作为参考，你可以在网上找到正态分布的概率密度:<a class="ae jq" href="https://en.wikipedia.org/wiki/Normal_distribution." rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Normal_distribution.</a></p></blockquote><p id="ff55" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">大多数数学表达式如“*”、“-”、“+”等。是它们的张量流等价的快捷方式。高斯函数包括许多运算，使用如下的简写符号会更清楚:</p><pre class="js jt ju jv fq ly lz ma mb aw mc dt"><span id="2153" class="md kv hu lz b fv me mf l mg mh">from math import pi</span><span id="60b6" class="md kv hu lz b fv mx mf l mg mh">mean = 1.0<br/>sigma = 0.0</span><span id="2259" class="md kv hu lz b fv mx mf l mg mh">(tf.exp(tf.neg(tf.pow(x — mean, 2.0) /<br/>               (2.0 * tf.pow(sigma, 2.0) ))) *<br/>(1.0 / (sigma * tf.sqrt(2.0 * pi) )))</span></pre><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="fe ff my"><img src="../Images/16e19a4d1afec9861e8fdbbf0180cebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bv4rtLWR5Dh1pz7VV-4mPQ.png"/></div></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek">Figure 3. The graph represents the operations needed to produce a Gaussian distribution. The links between the nodes represent how data flows from one operation to the next. The operations themselves are simple, but complexity arises in how they intertwine.</figcaption></figure><p id="b4f5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如你所见，张量流算法很容易可视化。它们可以用流程图来描述。流程图的技术术语(更正确的术语)是<em class="jp">图</em>。流程图中的每个箭头被称为图的<em class="jp">边</em>。此外，流程图的每个状态被称为一个<em class="jp">节点</em>。</p><h1 id="9b92" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated"><strong class="ak"> <em class="ls">执行带会话的运算符</em> </strong></h1><p id="7d6e" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt jz translated"><span class="l ka kb kc bm kd ke kf kg kh di"/>会话是软件系统的环境，描述代码行应该如何运行。在TensorFlow中，会话设置硬件设备(如CPU和GPU)如何相互通信。这样，你就可以设计你的机器学习算法，而不用担心对它运行的硬件进行微观管理。当然，您可以稍后配置会话来更改其行为，而无需更改一行机器学习代码。</p><p id="913a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">要执行操作并检索其计算值，TensorFlow需要一个会话。只有注册的会话可以填充张量对象的值。为此，您必须使用<em class="jp"> tf创建一个会话类。Session() </em>并告诉它运行一个操作符(清单6)。结果将是一个值，您可以在以后用于进一步的计算。</p><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="ko kp l"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek">Listing 6. Using a session</figcaption></figure><p id="84d9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">恭喜你！您刚刚编写了第一个完整的张量流代码。虽然它所做的只是对一个矩阵求反以产生[[-1，-2]]，但核心开销和框架与TensorFlow中的其他一切都是一样的。</p><h2 id="7dde" class="md kv hu bd kw mi mj mk la ml mm mn le jc mo mp li jg mq mr lm jk ms mt lq mu dt translated"><strong class="ak"> <em class="ls">会话配置</em> </strong></h2><p id="4e42" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt translated">您还可以将选项传递给tf.Session。例如，TensorFlow会根据可用的设备，自动确定将GPU或CPU设备分配给操作的最佳方式。在创建会话时，我们可以传递一个额外的选项，<em class="jp">log _ device _ placements = True</em>，如清单7所示。</p><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="ko kp l"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek">Listing 7. Logging a session</figcaption></figure><p id="a191" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这将输出关于每个操作的会话中使用了哪些CPU/GPU设备的信息。例如，运行清单6会产生如下所示的输出跟踪，以显示哪个设备用于运行求反操作:</p><pre class="js jt ju jv fq ly lz ma mb aw mc dt"><span id="abcd" class="md kv hu lz b fv me mf l mg mh">Neg: /job:localhost/replica:0/task:0/cpu:0</span></pre><p id="065d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">会话在TensorFlow代码中是必不可少的。你需要召集一次会议来真正“运行”数学。图4描绘了TensorFlow上的不同组件如何与机器学习管道进行交互。会话不仅运行图形操作，还可以将占位符、变量和常量作为输入。到目前为止，我们已经使用了常量，但是在后面的章节中，我们将开始使用变量和占位符。下面是这三种价值观的简要概述。</p><ul class=""><li id="3c33" class="nd ne hu it b iu iv iy iz jc nf jg ng jk nh jo ni nj nk nl dt translated"><strong class="it hv">占位符</strong>:一个未赋值的值，但是无论会话在哪里运行都会被初始化。</li><li id="d78f" class="nd ne hu it b iu nm iy nn jc no jg np jk nq jo ni nj nk nl dt translated"><strong class="it hv">变量:</strong>可以变化的值，机器学习模型的这样一个参数。</li><li id="95a5" class="nd ne hu it b iu nm iy nn jc no jg np jk nq jo ni nj nk nl dt translated"><strong class="it hv">常量:</strong>不变的值，如超参数或设置。</li></ul><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff nr"><img src="../Images/c4a5d38ba91c3d83feab00e4f53c3617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*2mI_CfSOhyl0if-o-d7O4A.png"/></div><figcaption class="kq kr fg fe ff ks kt bd b be z ek">Figure 4. The session dictates how the hardware will be used to most efficiently process the graph. When the session starts, it assigns the CPU and GPU devices to each of the nodes. After processing, the session outputs data in a usable format, such as a NumPy array. A session optionally may be fed placeholders, variables, and constants.</figcaption></figure><h1 id="67f1" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated"><strong class="ak"> <em class="ls">渴望更多？</em>T29】</strong></h1><p id="7a07" class="pw-post-body-paragraph ir is hu it b iu lt iw ix iy lu ja jb jc lv je jf jg lw ji jj jk lx jm jn jo hn dt translated">到此为止，我希望你已经成功地熟悉了TensorFlow的一些基本工作原理。如果这篇文章让你渴望更多美味的TensorFlow花絮，请前往<strong class="it hv">下载使用TensorFlow </strong> 进行机器学习的 <a class="ae jq" href="https://www.manning.com/books/machine-learning-with-tensorflow?a_aid=TensorFlow&amp;a_bid=042443a4" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv">的第一章，并查看这个<a class="ae jq" href="http://www.slideshare.net/ManningBooks/machine-learning-with-tensorflow" rel="noopener ugc nofollow" target="_blank">幻灯片演示</a>以了解更多信息(以及一个<strong class="it hv">折扣代码</strong>)。</strong></a></p><div class="js jt ju jv fq ab cb"><figure class="ns jw nt nu nv nw nx paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="ns jw nt nu nv nw nx paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="ns jw nt nu nv nw nx paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="ki kj kk"><p id="f922" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated"><a class="ae jq" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是阿妹家庭的一员。我们现在<a class="ae jq" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae jq" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="ir is jp it b iu iv iw ix iy iz ja jb kl jd je jf km jh ji jj kn jl jm jn jo hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae jq" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae jq" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="js jt ju jv fq jw fe ff paragraph-image"><a href="https://goo.gl/Ahtev1"><div class="fe ff ny"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></a></figure><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="nz kp l"/></div></figure></div></div>    
</body>
</html>