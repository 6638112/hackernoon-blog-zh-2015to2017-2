# 为什么机器学习需要这么多训练数据？

> 原文：<https://medium.com/hackernoon/why-does-machine-learning-require-so-much-training-data-cc839cd62fa5>

![](img/6c368fe607b30b0ef7c750365d290f83.png)

在过去十年左右的时间里，人工智能的世界一直被模式识别的问题所困扰——问任何一个崭露头角的工程师“给我一个算法，在一个环境 *Y* 中找到 *X* ，并期望听到这样的话，“给我环境 *Y* 中的 *T* 例子，我将如此准确地预测 *X* ”。

最近在人工智能技术上的进步使未来的企业家们相信计算机可以变魔术。

看了这个视频后，我想我们有什么资格说不。除此之外，最近在 CVPR 17 海报会议上的漫步足以令人信服，学术界正在通过解决以前难以想象和令人瞠目结舌的问题来测试这些技术的实力。这些算法成功地通过了测试。

一台基本的计算机实际上是一个处理二进制电压的非常愚蠢的实体，因此可以安全地假设它不会变魔术，因此严重依赖智能算法和调整来解决上述问题。

这给我们带来了一个重要的问题，

# 我怎样才能让电脑解决我的问题？

自计算机诞生以来，这个问题的答案已经经历了许多范式转变，当前的方法正是我们这位崭露头角的工程师所提到的:构建“智能算法”，并向计算机提供“足够多”的真实环境示例(训练数据)，以便当计算机看到“类似数据”时，它知道该做什么。随着“智能算法”业务被全世界的计算机科学家所关注，一个可能仍然困扰着新兴创业公司的难题是“*多少数据实际上是足够的？*”。

在回答这个问题之前，我们先试着理解为什么这甚至是一个问题。为什么我们不能拥有无限的数据，只专注于解决问题？原因是收集的每个数据都有一个与之相关的$值，因为数据通常是手动收集的，所以人们必须接受培训并为数据收集的[繁琐工作得到补偿，所以如果我可以使用 *T* 训练样本，我将不会收集 10 个*X*T*T*训练样本。这就把我们带回了主要问题:这个 *T* 对我的问题来说是多少钱，我能用较小的 *T* 做什么？这个问题的答案主要取决于两个因素:](https://playment.io/data-collection)

*   我的产品出错的灾难性有多大？
*   我的产品的输入可以有多多样化？

虽然每个人都想拿出一个完美的产品，但现实世界中的 ML 产品很少是完美的。不同的产品具有不同的误差容限，因此它们总是有可能出错。例如，预测哪支球队将赢得足球比赛的应用程序比球门线技术具有更高的容忍度来评估是否进球。

无论是什么类型的产品，没有人喜欢出错的产品，如果你的业务围绕客户满意度，99.0 %的准确率比 98.95 %的准确率更重要，所以每个新的培训点都很重要。想象一下，在你的[自动驾驶汽车](https://playment.io/adas/?utm_source=hackernoon&utm_content=how_much_training_data)中，左/右预测的准确度降低 0.0001 %，你绝对不会想到减少你的训练数据。

就像公司想要没有错误的产品一样，他们也想要可以在这个世界上任何环境下工作的产品。“一种为检测非洲人脸而开发的人脸检测算法，在 2050 年外星人到来时，也应该能检测到外星人的脸”。为了达到如此高的标准，该算法需要呈现每一种输入可能性，因此它学习改进“相似数据”的概念。

深度学习架构最近的增长是必要的，因为我们的世界是复杂的。为了构建可靠的东西来处理它的所有微妙之处，我们需要尽可能多地训练我们的产品。为了说明深度架构对训练数据大小的影响，让我们分析人脸检测/识别的问题。

著名的哈尔分类器或基于 SVM 的面部检测器可以在几千个样本上训练，以获得最佳性能。相比之下，用于检测和识别人脸的 [FaceNet](https://github.com/davidsandberg/facenet) 架构在超过 40 万个训练数据样本上进行训练，它已经有效地“解决”了闭集人脸识别问题。然而，在计算机视觉领域，检测人脸是一个相对简单的问题，更复杂的 ML(语言翻译，自动驾驶数据)问题只会需要越来越多的数据才能“解决”。如果苹果能够获得无限的训练，SIRI 就能像识别我的美国同事的口音一样识别我的印度口音了。

收集训练数据的成本激励科学家寻找手动数据注释的替代方法。最前沿的两种方法是迁移学习和合成数据生成。使用大量数据训练一个狗检测器，并以此为起点检测猫，就是迁移学习的一个简单例子。在讨论迁移时需要理解的一个重要方面是，它可以利用无监督学习的力量，这意味着训练数据不需要注释(这是非常容易收集的)。可以构建算法从这些未标记的数据中学习重要的特征，并最终用有限的训练数据进行调整。合成数据可以被认为是基于启发式的计算机生成的数据，以最好地模拟环境。这个方向的重要性由苹果最近的作品得到了证实，该作品获得了 2017 年 CVPR 最佳论文奖。这些方法仍处于早期发展阶段。只有时间才能证明我们是否能完全取代[人工注释](https://blog.playment.io/training-data-for-computer-vision/utm_source=hackernoon&utm_medium=referral&utm_content=how_much_training_data)。

增加收集更多训练数据的必要性的两个不可避免的方面是人为错误和数据保存期限。尽管现代最大似然算法对训练数据中的噪声具有鲁棒性，但在几乎所有情况下，人为错误最终都会减少有效的训练规模。除此之外，使用传感器(相机、麦克风)收集的数据受到这样一个事实的影响，即现在最先进的数据收集在几年后可能不够用——想象一下使用 5 年前获得的像素化图像对 ImageNet 图像进行分类。

不可否认，训练数据的数量和质量现在是一个热门话题，人们正在探索不同的技术来解决这个问题。几年后，我们可能会更清楚地了解多少[训练数据](https://playment.io/utm_source=hackernoon&utm_medium=referral&utm_content=how_much_training_data)足以解决一个问题。但是现在可以肯定的结论是“越多越好”。

*最初发表于* [*Playment 博客*](https://blog.playment.io/training-data-machine-learning/?utm_source=hackernon&utm_content=how_much_trainingdata&utm_medium=referral) *。*