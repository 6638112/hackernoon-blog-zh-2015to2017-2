<html>
<head>
<title>How to log in Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何登录Apache Spark</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/how-to-log-in-apache-spark-f4204fad78a?source=collection_archive---------0-----------------------#2016-02-24">https://medium.com/hackernoon/how-to-log-in-apache-spark-f4204fad78a?source=collection_archive---------0-----------------------#2016-02-24</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="0773" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">任何应用程序的一个重要部分是我们整合到其中的底层日志系统。日志不仅用于调试和跟踪，还用于商业智能。在我们的应用程序中构建一个健壮的日志记录系统，可以作为我们正在解决的业务问题的一个很好的见解。</p><h1 id="a501" class="jp jq hu bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km dt translated">Apache Spark中的Log4j</h1><p id="7748" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated">Spark使用<strong class="it hv"> <em class="ks"> log4j </em> </strong>作为自己日志记录的标准库。Spark内部发生的一切都会记录到shell控制台和配置的底层存储中。Spark还为应用编写者提供了一个模板，因此我们可以使用相同的<strong class="it hv"> <em class="ks"> log4j </em> </strong>库来添加我们想要的任何<em class="ks">消息</em>到Spark中现有的和适当的登录实现中。</p><h1 id="ecb9" class="jp jq hu bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km dt translated">配置Log4j</h1><p id="3fea" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated">在<strong class="it hv"><em class="ks">SPARK _ HOME/conf</em></strong>文件夹下，有一个<strong class="it hv"><em class="ks">log4j . properties . template</em></strong>文件，它是我们自己的<em class="ks">日志</em>系统的起点。</p><p id="f942" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">基于这个文件，我们创建了<strong class="it hv"><em class="ks">log4j . properties</em></strong>文件，放在同一个目录下。</p><p id="5e5f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"><em class="ks">log4j . properties</em></strong>看起来如下:</p><figure class="kt ku kv kw fq kx"><div class="bz el l di"><div class="ky kz l"/></div></figure><p id="6571" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">基本上，我们希望隐藏Spark生成的所有日志，这样我们就不必在shell中处理它们。我们将它们重定向到文件系统中进行记录。另一方面，我们希望将我们自己的日志记录在shell和一个单独的文件中，这样它们就不会与来自Spark的日志混淆。从这里开始，我们将把<em class="ks"> Splunk </em>指向我们自己的日志所在的文件，在本例中是<strong class="it hv"><em class="ks">/var/log/sparku . log .</em></strong></p><p id="386c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这个(<strong class="it hv"><em class="ks">log4j . properties</em></strong>)文件是在应用程序启动时由Spark提取的，因此除了将它放在上述位置之外，我们不需要做任何事情。</p><h1 id="4b1e" class="jp jq hu bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km dt translated">写我们自己的日志</h1><p id="0a6a" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated">现在我们已经配置了Spark管理日志所需的组件，我们只需要开始在我们的应用程序中写日志。</p><p id="6fcd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了展示这是如何做到的，让我们编写一个小应用程序来帮助我们进行演示。</p><p id="ec8e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们的应用程序:</p><figure class="kt ku kv kw fq kx"><div class="bz el l di"><div class="ky kz l"/></div></figure><p id="f2f7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">运行这个Spark应用程序将证明我们的日志系统是有效的。我们将能够看到<strong class="it hv"> <em class="ks"> Hello demo </em> </strong>和<strong class="it hv"><em class="ks">I done</em></strong>消息是如何被记录到shell和文件系统中的，而Spark日志只会被记录到文件系统中。</p><p id="26ca" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">到目前为止，一切似乎都很容易，然而有一个问题我们还没有提到。</p><p id="4f3b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">类<strong class="it hv"><em class="ks">org . Apache . log4j . logger</em></strong>不是<em class="ks">可序列化的</em>，这意味着我们不能在对Spark API的某些部分进行操作时在<em class="ks">闭包</em>中使用它。</p><p id="af38" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">例如，如果我们在应用程序中:</p><figure class="kt ku kv kw fq kx"><div class="bz el l di"><div class="ky kz l"/></div></figure><p id="0586" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在Spark上运行时，这将失败。Spark抱怨说<em class="ks">日志</em>对象不是<em class="ks">可序列化的</em>，所以它不能通过网络发送给Spark workers。</p><p id="ed87" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这个问题其实很好解决。让我们创建一个类，它在进行大量日志记录的同时对数据集做一些事情。</p><figure class="kt ku kv kw fq kx"><div class="bz el l di"><div class="ky kz l"/></div></figure><p id="9a60" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="ks">映射器</em>接收一个<em class="ks">RDD【Int】</em>并返回一个<em class="ks">RDD【String】</em>，它还记录它正在映射的值。在这种情况下，请注意<em class="ks">日志</em>对象是如何被标记为<strong class="it hv"> <em class="ks"> @transient </em> </strong>的，这使得序列化系统可以忽略<em class="ks">日志</em>对象。现在，<em class="ks"> Mapper </em>正在被序列化并发送给每个worker，但是当worker需要日志对象时，它会被解析，这解决了我们的问题。</p><p id="c28c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">另一个解决方案是将<em class="ks">日志</em>对象包装成一个<em class="ks">对象</em>构造<em class="ks"> </em>并到处使用。我们宁愿在我们要使用的类中有<em class="ks"> log </em>,但是替代方法也是有效的。</p><p id="b6a5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">此时，我们的整个应用程序如下所示:</p><figure class="kt ku kv kw fq kx"><div class="bz el l di"><div class="ky kz l"/></div></figure><h1 id="88b7" class="jp jq hu bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km dt translated">结论</h1><p id="d6f0" class="pw-post-body-paragraph ir is hu it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hn dt translated">我们的日志现在显示在shell中，也存储在它们自己的文件中。Spark日志在shell中被隐藏起来，并被记录到它们自己的文件中。我们还解决了在尝试登录不同的workers时出现的序列化问题。</p><p id="ecc1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们现在可以基于我们自己的Spark日志来构建更健壮的BI系统，就像我们今天处理其他非分布式系统和应用程序一样。商业智能对我们来说非常重要，拥有正确的见解总是件好事。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><p id="78ce" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你觉得这篇文章有用，请推荐它，这样其他人也能从中受益。</p><p id="e0af" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="ks">阅读下一条:</em></p><p id="ddad" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae lh" rel="noopener" href="/@anicolaspp/how-to-log-in-apache-spark-a-functional-approach-e48ffbbd935b?source=linkShare-4d3a2d851128-1469361893"> <em class="ks">如何登录Apache Spark，功能方法</em> </a></p><blockquote class="li lj lk"><p id="6d2c" class="ir is ks it b iu iv iw ix iy iz ja jb ll jd je jf lm jh ji jj ln jl jm jn jo hn dt translated"><a class="ae lh" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae lh" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae lh" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>并乐意<a class="ae lh" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="dca4" class="ir is ks it b iu iv iw ix iy iz ja jb ll jd je jf lm jh ji jj ln jl jm jn jo hn dt translated">要了解更多信息，<a class="ae lh" href="https://goo.gl/4ofytp" rel="noopener ugc nofollow" target="_blank">请阅读我们的“关于”页面</a> , <a class="ae lh" href="http://bit.ly/HackernoonFB" rel="noopener ugc nofollow" target="_blank">喜欢/在脸书给我们发消息</a>，或者简单地，<a class="ae lh" href="https://goo.gl/k7XYbx" rel="noopener ugc nofollow" target="_blank">发推文/DM @HackerNoon。</a></p><p id="708a" class="ir is ks it b iu iv iw ix iy iz ja jb ll jd je jf lm jh ji jj ln jl jm jn jo hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae lh" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae lh" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote></div></div>    
</body>
</html>