<html>
<head>
<title>DeepMind’s Relational Reasoning Networks — Demystified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DeepMind的关系推理网络——去神秘化</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/deepmind-relational-networks-demystified-b593e408b643?source=collection_archive---------1-----------------------#2017-07-03">https://medium.com/hackernoon/deepmind-relational-networks-demystified-b593e408b643?source=collection_archive---------1-----------------------#2017-07-03</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div class="fe ff ir"><img src="../Images/3d0a45a61f1c8746719a6e814594a655.png" data-original-src="https://miro.medium.com/v2/resize:fit:160/format:webp/1*4CWM6vRBH8SGLd5ii7zahA.jpeg"/></div></figure><blockquote class="iy iz ja"><p id="8d49" class="jb jc jd je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这篇文章获得了<a class="ae ka" href="http://www.kdnuggets.com/2017/08/deepmind-relational-reasoning-networksdemystified.html" rel="noopener ugc nofollow" target="_blank"> KDNuggets银奖</a>，也是2017年8月<a class="ae ka" href="http://www.kdnuggets.com/2017/09/top-stories-2017-aug.html" rel="noopener ugc nofollow" target="_blank">最具病毒的帖子</a></p></blockquote><p id="035e" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt ke translated">每次DeepMind发表一篇新论文，都会有媒体疯狂报道。你经常会读到一些误导性的短语。例如，其关于关系推理网络的新论文有<a class="ae ka" href="https://futurism.com/deepmind-develops-a-neural-network-that-can-make-sense-of-objects-around-it/" rel="noopener ugc nofollow" target="_blank"> futurism </a>这样报道</p><blockquote class="iy iz ja"><p id="fee6" class="jb jc jd je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">DeepMind开发了一个神经网络，可以理解周围的物体。</p></blockquote><p id="6367" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">这不仅是误导，而且也让日常生活中的非博士人士感到害怕。在这篇文章中，我将浏览这篇文章，试图用简单的术语解释这个新的架构。</p><p id="33d7" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">原文<a class="ae ka" href="https://arxiv.org/pdf/1706.01427.pdf" rel="noopener ugc nofollow" target="_blank">可以在这里</a>找到。</p><p id="95b5" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated"><em class="jd">本文假设关于</em> <strong class="je hv"> <em class="jd">神经网络</em> </strong> <em class="jd">的一些基础知识。</em></p><h1 id="f44b" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated">这篇文章的结构</h1><p id="3306" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">我会尽可能遵循论文的结构。我将在材料中加入我自己的想法。</p><h1 id="74a5" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated">什么是关系推理？</h1><p id="f5d9" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">最简单的形式，关系推理就是<a class="ae ka" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank">学习</a>理解不同对象(想法)之间的关系。这被认为是智力的基本特征。作者提供了一个有用的信息图表来解释它是什么</p><figure class="lr ls lt lu fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff lq"><img src="../Images/5a14fb8a8f25f338f6cf3638916541f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oHiIMzo5XCW0mny-NGeYtw.png"/></div></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek"><em class="md">Figure1.0 The model has to look at objects of different shape/size/color, and be able to answer questions that are related between multiple such objects.</em></figcaption></figure><h1 id="7a94" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated">关系网络</h1><p id="043d" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">作者提出了一种神经<a class="ae ka" href="https://hackernoon.com/tagged/network" rel="noopener ugc nofollow" target="_blank">网络</a>，它被制作成固有地捕捉关系(例如，卷积神经网络被制作成捕捉图像的属性)。他们展示了一个这样定义的架构:</p><figure class="lr ls lt lu fq iv fe ff paragraph-image"><div class="fe ff me"><img src="../Images/06e054d980f32662c329b54830205a0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*ZLhUDYDAqjvxGpP46mKNlA.png"/></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek"><em class="md">Equation1.0 Definition of Relational Networks</em></figcaption></figure><h2 id="eb67" class="mf ko hu bd kp mg mh mi kt mj mk ml kx kb mm mn lb kc mo mp lf kd mq mr lj ms dt translated">解释</h2><p id="a5a4" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">o的关系网络(<em class="jd"> O是你要学习的对象的集合</em>的关系)是一个函数<em class="jd"> fɸ.</em></p><p id="a14b" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated"><em class="jd"> gθ </em>是另一个接受两个对象的函数:o <em class="jd"> i </em>和o <em class="jd"> j </em>。<em class="jd"> gθ </em>的输出就是我们关注的‘关系’。</p><p id="25cd" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">σI，j的意思是，对所有可能的物体对计算gθ，然后求和。</p><h1 id="4232" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated">神经网络和功能</h1><p id="a1a5" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">当学习神经网络、反向传播等时，很容易忘记这一点。但是神经网络实际上是一个<strong class="je hv">单一的数学函数</strong>！因此，我在等式1.0中描述的函数是一个神经网络！。更准确地说，有两个神经网络:</p><ol class=""><li id="8106" class="mt mu hu je b jf jg jj jk kb mv kc mw kd mx jz my mz na nb dt translated"><em class="jd"> gθ，</em>计算一对对象之间的关系</li><li id="0b2a" class="mt mu hu je b jf nc jj nd kb ne kc nf kd ng jz my mz na nb dt translated"><em class="jd"> fɸ，</em>，取所有<em class="jd"> gθ，</em>之和，计算模型的最终输出</li></ol><p id="459b" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">在最简单的情况下，<em class="jd"> gθ </em>和<em class="jd"> fɸ </em>都是多层感知器。</p><h1 id="f0fe" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated">关系神经网络是灵活的</h1><p id="75d6" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">作者将关系神经网络呈现为一个模块。它可以接受编码对象并从中学习关系，但更重要的是，它们可以插入卷积神经网络和长短期记忆网络(LSTM)。</p><p id="10a7" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">卷积网络可以用来学习使用图像的对象。这使得它对应用程序更有用，因为在图像上推理比在用户定义的对象数组上推理更有用。</p><p id="4082" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">LSTMs连同单词嵌入可用于理解模型被询问的查询的含义。这也是更有用的，因为模型现在可以接受一个英语句子，而不是编码的数组。</p><p id="39da" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">作者提出了一种结合关系网络、卷积网络和LSTMs来构建能够学习对象之间关系的端到端神经网络的方法。</p><figure class="lr ls lt lu fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff nh"><img src="../Images/394452149c250b4cd73028e78eca4d93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fzkj-lSVmCGkptOwfbwUnA.png"/></div></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek"><em class="md">Figure 2.0 An end to end relational reasoning neural network.</em></figcaption></figure><h1 id="d509" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated"><strong class="ak">图2.0说明</strong></h1><p id="d1ff" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">图像通过一个标准的卷积神经网络(CNN)，它可以在<em class="jd"> k </em>过滤器中提取图像的特征。关系网络的“对象”是网格中每个点的特征向量。例如，一个“对象”是黄色矢量。</p><p id="976d" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">该问题通过LSTM传递，后者产生该问题的特征向量。这大致就是那个问题的‘思路’。</p><p id="6108" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">这稍微修改了原来的等式1.0。它增加了另一个术语</p><figure class="lr ls lt lu fq iv fe ff paragraph-image"><div class="fe ff ni"><img src="../Images/fe69b5069f699f55a6fc7ed20b558507.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*r0LoC7taRHVHq9s7UPT_Fw.png"/></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek">Equation1.0 Relational Network conditioned using LSTM</figcaption></figure><p id="5d61" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">注意等式1.0中多出来的<em class="jd"> q </em>。那个<em class="jd"> q </em>是LSTM的最终状态。这些关系现在由<em class="jd">使用<em class="jd"> q </em>来限定</em>。</p><p id="97c2" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">之后，来自CNN的“对象”和来自LSTM的向量被用于训练关系网络。每个对象对与来自LSTM的问题向量一起被提取，并且这些被用作<em class="jd"> gθ( </em>这是一个神经网络<em class="jd">)的输入。</em></p><p id="2aec" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">然后将gθ的输出相加，并用作fɸ(which另一个神经网络的输入。然后fɸ选择了这个问题的答案。</p><h1 id="5855" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated">基准</h1><p id="0dba" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">作者在几个数据集上证明了该模型的有效性。我将介绍其中一个(在我看来也是最值得注意的)——CLEVR数据集。</p><p id="b3e2" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">CLEVR数据集由不同形状、大小和颜色的对象图像组成。模型被问到关于这些图像的问题，例如:</p><blockquote class="iy iz ja"><p id="b71c" class="jb jc jd je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">立方体和圆柱体是同一种材料吗？</p></blockquote><figure class="lr ls lt lu fq iv fe ff paragraph-image"><div class="fe ff nj"><img src="../Images/3676bb3206384cd015806056e4bd8b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*UiK1oBh10jbTRmnQa9t0vQ.png"/></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek"><em class="md">Figure 3.0</em> The types of objects(top),and the positioning scheme (centre&amp;bottom)</figcaption></figure><p id="8fdd" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">作者指出，在准确性方面，其他系统远远落后于他们自己的模型。这是因为关系网络旨在捕捉关系。</p><p id="4a06" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">他们的模型达到了前所未有的96%以上的准确率，相比之下只有75%(使用堆叠注意力模型)</p><figure class="lr ls lt lu fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff nk"><img src="../Images/d58d43ee387daa7c2682b3271c59139a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S7y3r_1kv-nJfTZd-LxK9A.png"/></div></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek">Figure3.1 Comparison between different architectures on the CLEVR dataset using pixels(i.e. not matrix encoded)</figcaption></figure><h1 id="6227" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated">结论</h1><p id="8c93" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">关系网络非常擅长学习关系。他们以数据高效的方式这样做。它们也很灵活，可以在使用CNN和/或LSTMs时作为解决方案的一部分。</p><p id="e4ee" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">这篇文章是关于揭穿由非常大的出版物引起的“人工智能已经接管”的炒作，并给出一些关于当前艺术状态的观点。</p><h1 id="d7e2" class="kn ko hu bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk dt translated">附言</h1><p id="99b2" class="pw-post-body-paragraph jb jc hu je b jf ll jh ji jj lm jl jm kb ln jp jq kc lo jt ju kd lp jx jy jz hn dt translated">如果你注意到任何错误，或者想要任何修改，请通过回复让我知道。欢迎你的建议。</p><p id="08b5" class="pw-post-body-paragraph jb jc hu je b jf jg jh ji jj jk jl jm kb jo jp jq kc js jt ju kd jw jx jy jz hn dt translated">如果你喜欢这篇文章，请点击❤按钮推荐给其他人。</p><div class="lr ls lt lu fq ab cb"><figure class="nl iv nm nn no np nq paragraph-image"><a href="http://bit.ly/HackernoonFB"><img src="../Images/50ef4044ecd4e250b5d50f368b775d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0hqOaABQ7XGPT-OYNgiUBg.png"/></a></figure><figure class="nl iv nm nn no np nq paragraph-image"><a href="https://goo.gl/k7XYbx"><img src="../Images/979d9a46439d5aebbdcdca574e21dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Vgw1jkA6hgnvwzTsfMlnpg.png"/></a></figure><figure class="nl iv nm nn no np nq paragraph-image"><a href="https://goo.gl/4ofytp"><img src="../Images/2930ba6bd2c12218fdbbf7e02c8746ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gKBpq1ruUi0FVK2UM_I4tQ.png"/></a></figure></div><blockquote class="iy iz ja"><p id="f922" class="jb jc jd je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="http://bit.ly/Hackernoon" rel="noopener ugc nofollow" target="_blank">黑客中午</a>是黑客如何开始他们的下午。我们是<a class="ae ka" href="http://bit.ly/atAMIatAMI" rel="noopener ugc nofollow" target="_blank"> @AMI </a>家庭的一员。我们现在<a class="ae ka" href="http://bit.ly/hackernoonsubmission" rel="noopener ugc nofollow" target="_blank">接受投稿</a>，并乐意<a class="ae ka" href="mailto:partners@amipublications.com" rel="noopener ugc nofollow" target="_blank">讨论广告&amp;赞助</a>机会。</p><p id="708a" class="jb jc jd je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你喜欢这个故事，我们推荐你阅读我们的<a class="ae ka" href="http://bit.ly/hackernoonlatestt" rel="noopener ugc nofollow" target="_blank">最新科技故事</a>和<a class="ae ka" href="https://hackernoon.com/trending" rel="noopener ugc nofollow" target="_blank">趋势科技故事</a>。直到下一次，不要把世界的现实想当然！</p></blockquote><figure class="lr ls lt lu fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff nr"><img src="../Images/be0ca55ba73a573dce11effb2ee80d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35tCjoPcvq6LbB3I6Wegqw.jpeg"/></div></div></figure><figure class="lr ls lt lu fq iv"><div class="bz el l di"><div class="ns nt l"/></div></figure></div></div>    
</body>
</html>