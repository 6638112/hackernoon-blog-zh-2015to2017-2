<html>
<head>
<title>Using AI to Super Compress Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能超级压缩图像</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/using-ai-to-super-compress-images-5a948cf09489?source=collection_archive---------2-----------------------#2017-08-08">https://medium.com/hackernoon/using-ai-to-super-compress-images-5a948cf09489?source=collection_archive---------2-----------------------#2017-08-08</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="7b86" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt jp translated">像神经网络这样的数据驱动算法已经风靡全球。他们最近的激增是由几个因素造成的，包括廉价而强大的硬件，以及大量的数据。当涉及到像图像识别、自然语言理解等“认知”任务时，神经网络是当前最先进的。，但他们不必局限于这样的任务。在这篇文章中，我将讨论一种使用神经网络来压缩图像的方法，从而以相当快的速度实现图像压缩的艺术表现。</p><p id="4f41" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jy">本文基于</em> <a class="ae jz" href="https://arxiv.org/pdf/1708.00838v1.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="jy">一种基于卷积神经网络</em> </a>的端到端压缩框架</p><p id="aed5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">本文假设对神经网络有所了解，包括<strong class="it hv">卷积</strong>和<strong class="it hv">损失函数</strong>。</p><h1 id="ab45" class="ka kb hu bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">什么是图像压缩？</h1><p id="bed3" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">图像压缩是转换图像以使其占用更少空间的过程。简单地存储图像会占用大量空间，因此有一些编解码器，如JPEG和PNG，旨在减小原始图像的大小。</p><h2 id="1213" class="ld kb hu bd kc le lf lg kg lh li lj kk jc lk ll ko jg lm ln ks jk lo lp kw lq dt translated">有损压缩与无损压缩</h2><p id="18cf" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">图像压缩有两种:<strong class="it hv">无损</strong>和<strong class="it hv">有损。</strong>顾名思义，在无损压缩中，可以恢复原始图像的所有数据，而在有损压缩中，一些数据会在转换过程中丢失。</p><p id="2f61" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">例如，JPG是一种有损算法，而PNG是一种无损算法</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff lr"><img src="../Images/435c1abf9b7099008dcdbd606370f4b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_2FGlnjWYX2o3XjBOFkO1A.jpeg"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Figure 1.0: Comparison between lossless and lossy compression</figcaption></figure><p id="76c5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">请注意右边的图像有许多块状的artifiacts。这就是信息丢失的方式。颜色相似的邻近像素被压缩为一个区域，这样可以节省空间，但也会丢失关于实际像素的信息。当然，JGEG、PNG等编解码器使用的实际算法要复杂得多，但这是有损压缩的一个很好的直观示例。Losless很好，但它最终会占用大量磁盘空间。</p><p id="59fd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有更好的方法来压缩图像而不会丢失太多信息，但它们非常慢，并且许多方法使用迭代方法，这意味着它们不能在多个CPU核心或GPU上并行运行。这使得它们在日常使用中非常不实用。</p><h1 id="4580" class="ka kb hu bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">进入卷积神经网络</h1><p id="5129" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">如果有什么需要计算并且可以近似，就扔一个神经<a class="ae jz" href="https://hackernoon.com/tagged/network" rel="noopener ugc nofollow" target="_blank">网络</a>过去。作者使用了一个相当标准的卷积神经网络来提高图像压缩。他们的方法不仅可以与“更好的方法”相媲美(如果不是更好的话)，还可以利用并行计算，从而大幅提高速度。</p><p id="9b0d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">背后的原因是卷积神经网络(CNN)非常擅长从图像中提取空间信息，然后以更紧凑的形式表示(例如，只存储图像的“重要”位)。作者希望利用CNN的这种能力来更好地呈现图像。</p><h1 id="5f95" class="ka kb hu bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">建筑</h1><p id="82ad" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">作者提出了一个双重网络。第一个网络，它将获取图像并生成一个紧凑的表示(ComCNN)。该网络的输出将由标准编解码器(例如JPEG)处理。通过编解码器后，图像将被传递到第二个网络，该网络将“修复”来自编解码器的图像，尝试恢复原始图像。作者称之为重建CNN (RecCNN)。这两个网络都是迭代训练的，类似于GAN。</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff mh"><img src="../Images/e67bc7aee2acc99a2c2b879567a82f61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*agEnOLiulLoo0uBaPtU2qw.png"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Figure 2.0 : ComCNN The compact representation is passed on to a standard codec</figcaption></figure><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff mi"><img src="../Images/0e02ca3ebc89cf0d132b549061ea77fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjEWG34irHO7ZxllDGHqKQ.png"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Figure 2.1 RecCNN. The output from ComCNN is upscaled and passed to RecCNN, which will attempt to learn a residual</figcaption></figure><p id="6bc5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">编解码器的输出被放大，然后传递给RecCNN。RecCNN将尝试输出看起来尽可能与原始图像相似的图像。</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff mj"><img src="../Images/2f5c66a4560de0a723f6385c44f7ee90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PehqKUEcLYjD80CN7rgR3A.png"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Figure 2.2. End to end framework to compress images. Co(.) represents an image compression algorithm. The authors used JPEG , JPEG2000, and BPG.</figcaption></figure><h1 id="2d8b" class="ka kb hu bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">残余是什么？</h1><p id="66a4" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">残差可以被认为是“改善”编解码器解码的图像的后处理步骤。神经网络拥有大量关于世界的“信息”，可以做出关于“修复”什么的认知决策。这个想法是基于剩余<a class="ae jz" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank">学习</a>，你可以在这里深入阅读<a class="ae jz" href="https://arxiv.org/pdf/1708.00838v1.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="7f51" class="ka kb hu bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">损失函数</h1><p id="ae8e" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">因为有两个网络，所以使用两个损失函数。第一个，对美国有线电视新闻网来说，标为L1的定义是:</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff mk"><img src="../Images/d9ced122bfb9c9d011be41981c0bca33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktpr0kJByj2oMyxfhFCeoA.jpeg"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Equation 1.0 Loss function for ComCNN</figcaption></figure><h2 id="105e" class="ld kb hu bd kc le lf lg kg lh li lj kk jc lk ll ko jg lm ln ks jk lo lp kw lq dt translated">说明</h2><p id="3dd3" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">这个等式可能看起来很复杂，但它实际上是标准(均方误差)<strong class="it hv"> MSE </strong>。|| s表示它们所包含的向量的“范数”。</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff mk"><img src="../Images/e567f78799dc0d3ff96aa28256a622a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WakRwweEtvR2X4ZC6eeHsA.jpeg"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Equation 1.1</figcaption></figure><p id="4eed" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Cr表示ComCNN的输出。θ表示ComCNN的可训练参数，Xk表示输入图像</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff mk"><img src="../Images/e25150a5a3f8e1b2e456807f201e0f24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CWfXtkK8gVclu7kfn6a12Q.jpeg"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Equestion 1.2</figcaption></figure><p id="76ec" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Re()表示RecCNN。这个等式只是将等式1.1的值传递给RecCNN。θ hat表示RecCNN的可训练参数(hat表示参数是固定的)</p><h2 id="ee29" class="ld kb hu bd kc le lf lg kg lh li lj kk jc lk ll ko jg lm ln ks jk lo lp kw lq dt translated">直观定义</h2><p id="b68d" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">等式1.0将使ComCNN修改其权重，使得在由RecCNN重新创建之后，最终图像将看起来尽可能接近真实的输入图像。</p></div><div class="ab cl ml mm hc mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hn ho hp hq hr"><p id="5957" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">RecCNN的第二个损失函数定义为:</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff ms"><img src="../Images/a85e4ebd218efe2099fc1dba4a433a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G2mTO9Lsq-2yP4hvGbomyQ.jpeg"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Equation 2.0</figcaption></figure><h2 id="3f78" class="ld kb hu bd kc le lf lg kg lh li lj kk jc lk ll ko jg lm ln ks jk lo lp kw lq dt translated">说明</h2><p id="c14c" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">同样，该函数可能看起来复杂，但它是一个最标准的神经网络损失函数(MSE)。</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff mk"><img src="../Images/43940109345b4ec1c8de9611ba9ba72f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d10Z6unOLhlJA1g7jH9TCQ.jpeg"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Equation 2.1</figcaption></figure><p id="d535" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Co()表示编解码器的输出。x表示ComCNN的输出。θ2表示RecCNN的可训练参数。res()只是代表网络已经学习到的残差。它只是RecCNN的输出。值得注意的是，RecCNN是在Co()和输入图像之间的差异上训练的，而不是直接来自输入图像。</p><h2 id="dc29" class="ld kb hu bd kc le lf lg kg lh li lj kk jc lk ll ko jg lm ln ks jk lo lp kw lq dt translated">直观定义</h2><p id="730a" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">等式2.0将使RecCNN修改其权重，使得其输出看起来尽可能接近原始图像。</p><h1 id="b804" class="ka kb hu bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">培训计划</h1><p id="50d7" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">模型被迭代训练，类似于<a class="ae jz" href="https://hackernoon.com/can-creative-adversarial-network-explained-1e31aea1dfe8" rel="noopener ugc nofollow" target="_blank"> GANs </a>被训练的方式。一个模型的权重固定，而另一个模型的权重更新，然后另一个模型的权重固定，而第一个模型被训练。</p><h1 id="3a3a" class="ka kb hu bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">基准</h1><p id="10e2" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">作者将他们的方法与现有方法进行了比较，包括简单的编解码器。他们的方法比其他方法执行得更好，同时在有能力的硬件上使用时保持高速。作者尝试只使用其中一个网络，他们注意到性能有所下降。</p><figure class="ls lt lu lv fq lw fe ff paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="fe ff mt"><img src="../Images/594cd88aa61c93252c1c7db3b74b4d86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*seKtS_kWYE7Y44yNZAckWg.png"/></div></div><figcaption class="md me fg fe ff mf mg bd b be z ek">Figure3.0 SSIM(Structural Similarity index) Comparison. Higher values indicate better similarity to original. The authors’ work are in bold.</figcaption></figure><h1 id="009e" class="ka kb hu bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">结论</h1><p id="bb51" class="pw-post-body-paragraph ir is hu it b iu ky iw ix iy kz ja jb jc la je jf jg lb ji jj jk lc jm jn jo hn dt translated">我们研究了一种应用深度学习压缩图像的新方法。我们讨论了除了图像分类和语言处理等“常见”任务之外，将神经网络用于其他任务的可能性。这种方法不仅是最好的，而且可以以更快的速度处理图像。</p></div><div class="ab cl ml mm hc mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hn ho hp hq hr"><p id="4899" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你发现这篇文章的用途，请❤或👏🏻为了它。它对我来说意味着一切。如果您有任何改进、建议，或者希望我报道您认为有趣的出版物，请随时回复本文！。</p><figure class="ls lt lu lv fq lw"><div class="bz el l di"><div class="mu mv l"/></div></figure></div></div>    
</body>
</html>