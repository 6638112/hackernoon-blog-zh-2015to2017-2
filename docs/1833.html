<html>
<head>
<title>Effective Parallel Computing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有效的并行计算</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/effective-parallel-computing-bc8832114b7b?source=collection_archive---------5-----------------------#2016-12-12">https://medium.com/hackernoon/effective-parallel-computing-bc8832114b7b?source=collection_archive---------5-----------------------#2016-12-12</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><blockquote class="ir"><p id="5210" class="is it hu bd iu iv iw ix iy iz ja jb ek translated">“十多年来，先知们一直在说……单台计算机已经达到了极限，只有通过多台计算机的互连才能取得真正重大的进步。”—<strong class="ak">1967年的吉恩·阿姆达尔</strong></p></blockquote><p id="4ad9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jb hn dt translated">这句话是49年前说的！因此，近半个世纪以来，人们已经意识到串行计算不会给我们带来任何好处。</p><p id="7a38" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">所以序列号就像70年代的衣服，是的，那时候很好，但现在不是了，看在上帝的份上！</p><p id="4979" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">直到最近还没有很多应用程序使用并行处理，事实上他们并不需要它。是电子游戏激发了GPU(当着你父母的面！).</p><p id="2f28" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">现在，随着机器<a class="ae ke" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank">学习</a>的引入，对于GPU来说，没有比这更有用的应用了。为什么？</p><p id="6db6" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">机器学习有效地一遍又一遍地应用相同的计算步骤，数百万或数十亿次！这些任务本质上并不复杂，但仍然需要一些时间。<a class="ae ke" href="https://hackernoon.com/tagged/minimising" rel="noopener ugc nofollow" target="_blank">最小化</a>那段时间很艰难。幸运的是，这些计算是相互独立的。</p><p id="4cc5" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">现在与通常有4个物理核心或8个虚拟核心的CPU相比(你可能会选择E7 Xeons，但你必须是一个百万富翁！)，像Nvidia 1080这样的GPU有2560个核心！同样的价格超过160倍！</p><p id="3928" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">那么我们怎么做才能加快速度呢？我们并行运行几千次计算！</p><p id="e078" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">示例:</p><p id="2a11" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">一个男孩受到了惩罚，他不得不写“我再也不在上课时睡觉了”一百万次，也就是一百万次(这个老师会很可怕！).</p><p id="f6a2" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">一般来说，他花14秒写一行，如果他加快速度，他可能在10秒内完成。现在写100万次，他会要求:</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="82b0" class="ko kp hu kk b fv kq kr l ks kt">10 * 1,000,000 sec = 166667 mins = 2777 hours = 116 days = 4 months</span></pre><p id="74d0" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">所以他会连续写4个月！没有意义！</p><p id="63eb" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">现在如果他可以让1000个人帮他写同样的东西，但是每个人花20秒写一个句子:</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="aeb0" class="ko kp hu kk b fv kq kr l ks kt">(20 * 1,000,000) / 1,000 secs = 167 mins = 2.777 hours</span></pre><p id="1d87" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">尽管每个人都以一半的速度写作，但速度的提升是疯狂的！</p><p id="727f" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">差不多4个月的工作量，3个小时之内就做完了！！</p><figure class="kf kg kh ki fq ku"><div class="bz el l di"><div class="kv kw l"/></div></figure><h2 id="238e" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated"><strong class="ak">怎么发生的，深入！</strong></h2><p id="4ec0" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated"><strong class="je hv">第一个GPU vs CPU </strong></p><p id="04d2" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">GPU:</p><ol class=""><li id="fac8" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb ma mb mc md dt translated">高流通量</li><li id="9fb0" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">不太复杂的计算</li><li id="2f85" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">工作不太灵活</li><li id="bfdd" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">以低得多的时钟速度计时</li></ol><p id="6add" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">CPU:</p><ol class=""><li id="faed" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb ma mb mc md dt translated">低延迟</li><li id="1c75" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">非常复杂的计算</li><li id="5a70" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">在工作方面非常灵活</li><li id="b1e5" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">以更高的时钟速度计时</li></ol><p id="1ad0" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">现在GPU就像一群努力工作的实习生，他们不能做出非常关键的决定，但如果有工作，他们会全力以赴。</p><blockquote class="mj mk ml"><p id="f393" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated">所以GPU的行为就像一个协处理器，而不像主处理器。在主从计算方面，GPU是从属于CPU的命令。</p></blockquote><p id="52b7" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">现在，让我们更深入地了解这些步骤:</p><ol class=""><li id="73ad" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb ma mb mc md dt translated">CPU在设备上启动内核(内核是一个串行代码，是原始代码的一小部分。)</li><li id="4715" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">CPU在GPU上分配内存</li><li id="fbe1" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">CPU将输入数据复制到GPU</li><li id="672a" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">CPU启动GPU上的内核来处理输入数据</li><li id="aa23" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">CPU将输出结果复制到自身</li></ol><p id="fd8a" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">那么我们如何在GPU中定义并行性呢</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="d258" class="ko kp hu kk b fv kq kr l ks kt">GPU Parallelism = No. of blocks * Threads per block</span></pre><p id="de2f" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">典型的内核调用是什么样子的？</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="dd4b" class="ko kp hu kk b fv kq kr l ks kt">&lt;&lt; Grid of Blocks , Block of Threads , Shared Memory per Block &gt;&gt;</span></pre><blockquote class="mj mk ml"><p id="7147" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated">调用SyncThread时，它会一直等待，直到同一个块中的所有线程都执行完。等待其他线程完成的指令称为隐式障碍。</p></blockquote></div><div class="ab cl mq mr hc ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hn ho hp hq hr"><h1 id="be09" class="mx kp hu bd kx my mz na lb nb nc nd lf ne nf ng li nh ni nj ll nk nl nm lo nn dt translated">计算</h1><p id="c6b5" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated"><strong class="je hv"> <em class="mm">使计算成为可能的基本指令是什么，它们是如何实现的？</em>T3】</strong></p><p id="8674" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">从基础开始:</p><h2 id="3332" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">向量运算</h2><p id="1cf5" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">向量运算对向量(一维或多维)的相应元素执行逐个元素的运算。如果操作数具有相同的大小，那么第一个操作数中的每个元素都与第二个操作数中相同位置的元素匹配。如果操作数具有兼容的大小，那么每个输入都会根据需要隐式扩展，以匹配另一个输入的大小。</p><p id="ce71" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">示例:添加两个不同大小的向量</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="1834" class="ko kp hu kk b fv kq kr l ks kt">[ [1,2] , [3,4] ] + [5,6] &lt;- Will give an Error</span></pre><p id="1d6d" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">所以我们展开第二个矩阵</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="5c0e" class="ko kp hu kk b fv kq kr l ks kt">[ [1 , 2] , [3 , 4] ] + [ [5 , 6] , [0 , 0] ]</span></pre><p id="c26a" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">让我们试试元素式乘法</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="f9bd" class="ko kp hu kk b fv kq kr l ks kt">[ [1*5 , 2*6] , [3*0 , 4*0] ] = [ [5 , 12] , [0 , 0] ]</span></pre><h2 id="5013" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">矩阵运算</h2><p id="31b2" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">矩阵运算遵循线性代数的规则，与多维数组不兼容。彼此相关的输入所需的尺寸和形状取决于操作。对于非标量输入，矩阵运算符通常会计算出与数组运算符不同的答案。</p><p id="af6b" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">示例:</p><p id="e171" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">使用矩阵运算将两个矩阵相乘将导致</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="a8fa" class="ko kp hu kk b fv kq kr l ks kt">[ [(1*5)+(2*0) , (6*1)+(2*0)] , [(3*5)+(4*0) , (3*6)+(4*0)] ]</span></pre><p id="081c" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">这相当于:</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="9080" class="ko kp hu kk b fv kq kr l ks kt">[ [5 ,   6] ,    [15 , 18] ]</span></pre><blockquote class="mj mk ml"><p id="6490" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated"><strong class="je hv">关键词</strong></p><p id="b199" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated">Memops:内存操作。向内存写入或读取数据。</p><p id="2373" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated">Flops:计算操作。计算一条指令所需的时间。</p></blockquote><h2 id="eb78" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">基本线性代数子程序</h2><blockquote class="ir"><p id="8cdb" class="is it hu bd iu iv no np nq nr ns jb ek translated">密集的线性代数运算通常是科学计算的核心，即使是最快的计算机也会面临压力。因此，重要的是，计算这些操作的例程获得高性能，因为它们执行最少的操作，并获得尽可能高的执行速率。</p></blockquote><h2 id="c644" class="ko kp hu bd kx ky nt la lb lc nu le lf jn nv lh li jr nw lk ll jv nx ln lo lp dt translated">一级:AXPY</h2><p id="b597" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">表示以下形式的向量-向量运算</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="81d6" class="ko kp hu kk b fv kq kr l ks kt">y &lt;- αx + y</span></pre><p id="4f72" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">或者y等于ax+y，这里</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="beea" class="ko kp hu kk b fv kq kr l ks kt">α ∈ R </span></pre><p id="e80f" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">和</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="7a16" class="ko kp hu kk b fv kq kr l ks kt">x,y ∈ R^n</span></pre><p id="2951" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">这里' a '，' x '和' y '存放在主存中。axpy的有效实现会将“a”从内存加载到寄存器中，然后用“x”和“y”进行计算，这两个值也必须从内存中提取。更新的结果“y”也必须被存储，对于执行的2n个触发器总共大约3n个memops。因此，每两个触发器需要三个memops。如果memops比flops贵(通常是这样)，那么限制axpy性能的就是memops。</p><p id="bbfc" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">即将内容加载到存储器和从存储器加载内容的速度形成了瓶颈。</p><h2 id="3f06" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">第二级:GEMV</h2><p id="eb3d" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">表示以下形式的一般矩阵向量运算</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="b752" class="ko kp hu kk b fv kq kr l ks kt">y &lt;- Ax + y</span></pre><p id="434e" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">这里的x和y是矢量，而A是矩阵。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="04b5" class="ko kp hu kk b fv kq kr l ks kt">x ,  y ∈ R^n</span><span id="bbcb" class="ko kp hu kk b fv ny kr l ks kt">A ∈ R^(nXn)</span></pre><p id="f0a4" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">该操作大致涉及最初存储在存储器中的n^2数据(用于矩阵)和2n^2触发器。因此，一个最佳的实现将恰好一次提取‘A’的每个元素，产生每两个触发器一个memop的比率。尽管这比axpy的比率好，但如果memops比flops慢得多，它仍然是算法成本的主要部分。</p><h2 id="ce59" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">第三级:GEMM</h2><p id="4d05" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">表示以下形式的通用矩阵矩阵运算</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="1bd9" class="ko kp hu kk b fv kq kr l ks kt">C &lt;- α op(A) op(B) + βC</span></pre><p id="79e0" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">这里</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="69db" class="ko kp hu kk b fv kq kr l ks kt">α , β ∈ R</span><span id="a607" class="ko kp hu kk b fv ny kr l ks kt">op(A) ∈ R^m×k </span><span id="fe6d" class="ko kp hu kk b fv ny kr l ks kt">op(B) ∈ R^k×n </span><span id="4599" class="ko kp hu kk b fv ny kr l ks kt">C ∈ R^m×n</span></pre><p id="3f5d" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">术语“op(X)”在这里表示矩阵可以是x或X^T(转置)。</p><p id="0dcc" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">因此，该等式的基本含义是，上述等式可以采用以下形式:</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="b50d" class="ko kp hu kk b fv kq kr l ks kt">C &lt;- α (A B) + βC<br/>C &lt;- α (A^T B) + βC<br/>C &lt;- α A B^T + βC<br/>C &lt;- α (A^T B^T) + βC</span></pre><p id="a24c" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">考虑乘积C := AB + C，其中所有三个矩阵都是n阶的平方。该运算涉及4n^2 memops (A和b必须从存储器中取出，而c必须同时取出和存储),并且需要2n^3触发器，4n^2 /2n^3 = 2/n memops/flops。因此，如果n足够大，则执行memops的成本相对于使用数据执行有用计算的成本来说是小的，并且有机会在许多计算中分摊将数据提取到高速缓存中的成本。</p><p id="12c4" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">现在有许多基于m，n，k(矩阵维数)的GEMM实现</p><p id="a8b5" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">示例:</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="5f04" class="ko kp hu kk b fv kq kr l ks kt">C &lt;- A^(m X k) B^(k X n) + C^(m^n)</span></pre><p id="d751" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">以下是执行它的方法</p><figure class="kf kg kh ki fq ku fe ff paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="fe ff nz"><img src="../Images/a50971b2127a8817c01606ca805491d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ld6P6UpSUkEXigDOVerzfg.jpeg"/></div></div><figcaption class="og oh fg fe ff oi oj bd b be z ek">Algorithms for GEMM</figcaption></figure><p id="28e0" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">GEMM仍然是最优化的计算方式之一，唯一的问题是，它在内存中加载了大量的信息。所以我们把矩阵分解成更小的矩阵，批量相乘。</p><p id="396f" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">基于高斯估计的方法，如LU分解法，通常用于解决MatMul问题。在适用的情况下，Cholesky分解的效率几乎是LU因式分解的三倍。</p><p id="449b" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">如果你不熟悉高斯估计，那么这个视频会很有帮助</p><figure class="kf kg kh ki fq ku"><div class="bz el l di"><div class="kv kw l"/></div></figure><p id="2721" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">示例:</p><p id="d5d6" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">因此，像CNN(卷积神经网络)这样的一些深度学习器可以在本质上比像T2·RNN(递归神经网络)这样的其他深度学习器更大程度地并行化。</p><p id="0741" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">在CNN的情况下，让我们以一个4096*4096大小的图像为例进行分析。这意味着基本上有16，777，216个像素需要分析。在这里的<a class="ae ke" href="http://cs231n.github.io/convolutional-networks/#pool" rel="noopener ugc nofollow" target="_blank">池层</a>中，每个块都可以看作是独立的计算。因此，可以独立地求解每个块，并且可以组合结果。因此可以实现高度并行。</p><p id="e67a" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">这也意味着，如果不是所有的1600万像素都适合内存，它可以很容易地分成几批。因此，我们可以在内存中加载这1600万像素的小块，并优化它们和应用GEMM。</p><p id="d635" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">让我们假设这是一个图像</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="e468" class="ko kp hu kk b fv kq kr l ks kt">[[1,2,3],[4,5,6],[7,8,9]]</span></pre><p id="6c6f" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">这个块将被分解成更小的矩阵</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="ce4c" class="ko kp hu kk b fv kq kr l ks kt">[[1,2],[3,4]]</span><span id="b037" class="ko kp hu kk b fv ny kr l ks kt">[[2,3],[5,6]]</span><span id="64b8" class="ko kp hu kk b fv ny kr l ks kt">[[4,5],[7,8]]</span><span id="7cd8" class="ko kp hu kk b fv ny kr l ks kt">[[5,6],[8,9]]</span></pre></div><div class="ab cl mq mr hc ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hn ho hp hq hr"><h1 id="ef42" class="mx kp hu bd kx my mz na lb nb nc nd lf ne nf ng li nh ni nj ll nk nl nm lo nn dt translated">GPU计算</h1><p id="9dca" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated"><strong class="je hv"><em class="mm">GPU计算的架构是怎样的？</em>T3】</strong></p><h2 id="6ade" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated"><strong class="ak"> GPGPU </strong></h2><p id="ae13" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">它代表<strong class="je hv">图形处理单元上的通用计算</strong>，基本上意味着使用GPU进行计算。</p><blockquote class="ir"><p id="7701" class="is it hu bd iu iv no np nq nr ns jb ek translated">从本质上讲，GPGPU管道是一种在一个或多个GPU和CPU之间的并行处理，它分析数据，就像它是图像或其他图形形式一样。将数据迁移到图形形式，然后使用GPU扫描和分析它，可以大大加快速度。</p><p id="56e4" class="is it hu bd iu iv no np nq nr ns jb ek translated">—维基百科</p></blockquote></div><div class="ab cl mq mr hc ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hn ho hp hq hr"><h1 id="7a35" class="mx kp hu bd kx my mz na lb nb nc nd lf ne nf ng li nh ni nj ll nk nl nm lo nn dt translated">基于GPU的例程</h1><p id="17f5" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated"><strong class="je hv"><em class="mm">GPU上的计算是如何在基础层面完成的？而且为什么这么有效？</em>T11】</strong></p><h2 id="9aeb" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">地图</h2><p id="458a" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">map操作简单地将给定的函数(内核)应用于流中的每个元素。一个简单的例子是将流中的每个值乘以一个常数。CPU为屏幕上的每个像素生成一个片段，并对每个像素应用一个片段程序。相同大小的结果流存储在输出缓冲区中。</p><h2 id="599e" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">减少</h2><p id="4185" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">一些计算需要从较大的流中计算较小的流(可能只有1个元素的流)。这被称为流的缩减。通常，还原可以分多个步骤进行。来自前一步骤的结果被用作当前步骤的输入，并且应用该操作的范围被减小，直到只剩下一个流元素。</p><h2 id="8986" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">流过滤</h2><p id="dc2d" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">流过滤本质上是一种非均匀归约。过滤包括根据某些标准从流中删除项目。</p><h2 id="86b0" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">扫描</h2><p id="a85f" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">扫描操作，也称为<em class="mm">并行前缀求和</em>，接收数据元素的向量(流)和带有单位元素‘I’的(任意)关联二元函数’+’。</p><blockquote class="mj mk ml"><p id="eae1" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated">如果输入为[a0，a1，a2，a3，...]，则<em class="hu">独占扫描</em>产生输出[i，a0，a0 + a1，a0 + a1 + a2，...]，而<em class="hu">包含扫描</em>产生输出[a0，a0 + a1，a0 + a1 + a2，a0 + a1 + a2 + a3，...]。虽然乍一看，该操作似乎固有地是串行的，但是有效的并行扫描算法是可能的，并且已经在图形处理单元上实现。扫描操作用于例如快速排序和稀疏矩阵向量乘法。</p></blockquote><h2 id="a0c1" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">分散</h2><p id="b2f2" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">分散操作最自然地在顶点处理器上定义。顶点处理器能够调整顶点的位置，这使得程序能够控制信息在网格上的存放位置。</p><blockquote class="mj mk ml"><p id="a0e6" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated">顶点处理器:图形系统组件，接收一组3D顶点作为输入，并处理它们以获得2D屏幕位置。目前的GPU具有多个并行工作的顶点处理器，并且可以使用顶点程序进行编程。</p><p id="6f2e" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated">片段处理器(非顶点处理器)不能执行直接分散操作，因为网格上每个片段的位置在片段创建时是固定的，程序员不能更改。但是，逻辑分散操作有时可能会通过另一个聚集步骤进行重新转换或实现。分散实现将首先发出输出值和输出地址。紧接着的收集操作使用地址比较来查看输出值是否映射到当前输出槽。</p></blockquote><h2 id="14a7" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">聚集</h2><p id="f4d3" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">聚集与分散相反，在分散根据贴图对元素重新排序后，聚集可以根据使用的贴图分散恢复元素的顺序。</p><h2 id="1fe6" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">分类</h2><p id="5b4b" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">排序操作将无序的元素集转换为有序的元素集。GPU上最常见的实现是对整数和浮点数据使用基数排序，对一般可比数据使用粗粒度合并排序和细粒度排序网络。</p><h2 id="0390" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">搜索</h2><p id="1c29" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">搜索操作允许程序员在流中找到给定的元素，或者可能找到指定元素的邻居。GPU不是用来加速单个元素的搜索，而是用来并行运行多个搜索。最常用的搜索方法是排序元素的二分搜索法。</p></div><div class="ab cl mq mr hc ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hn ho hp hq hr"><h1 id="57de" class="mx kp hu bd kx my mz na lb nb nc nd lf ne nf ng li nh ni nj ll nk nl nm lo nn dt translated">流式计算</h1><p id="a177" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated"><strong class="je hv"> <em class="mm">那么什么是蒸汽计算呢？而且为什么这么有效？</em>T3】</strong></p><p id="7877" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">将GPU用于实时渲染之外的目的的关键是将其视为一台<em class="mm">流</em>、<em class="mm">数据并行</em>计算机。</p><p id="b0c5" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">GPU等流处理器的编程方式与如今的CPU等串行处理器完全不同。CPU可以在程序中的任何时候写入内存中的任何位置。相反，流处理器可以以更加结构化的方式访问存储器。在流模型中，程序被表示为对数据流的一系列操作。<em class="mm">流</em>中的元素(即数据的有序数组)由<em class="mm">内核</em>中的指令处理。内核对流中的每个元素进行操作，并将结果写入输出流。</p><p id="2435" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated"><strong class="je hv"> <em class="mm">工作:</em> </strong> <em class="mm">流编程模型限制允许GPU并行执行内核，因此可以同时处理许多数据元素。通过确保一个流元素上的计算不会影响同一流中另一个元素上的计算，这种数据并行性成为可能。因此，在内核计算中唯一可以使用的值是内核和全局内存读取的输入。此外，GPU要求内核的输出是独立的:内核不能随机写入全局内存(换句话说，它们只能写入输出流的单个流元素位置)。该模型提供的数据并行性是GPU在串行处理器上提供加速的基础。</em></p><figure class="kf kg kh ki fq ku fe ff paragraph-image"><div class="fe ff ok"><img src="../Images/ad630797273abc5b65bc12368d5c7b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*QnZ4JQGce2CMW3Y-0SwMCQ.jpeg"/></div><figcaption class="og oh fg fe ff oi oj bd b be z ek">Stream of Data</figcaption></figure><p id="6aab" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated"><strong class="je hv"> <em class="mm">另外:</em> </strong> <em class="mm">目前的GPU片段处理器都是</em> <a class="ae ke" href="https://en.wikipedia.org/wiki/SIMD" rel="noopener ugc nofollow" target="_blank"> <em class="mm">单指令、多数据(SIMD) </em> </a> <em class="mm">并行处理器。当前的顶点处理器是</em> <a class="ae ke" href="https://en.wikipedia.org/wiki/MIMD" rel="noopener ugc nofollow" target="_blank"> <em class="mm">【多指令】【MIMD】</em></a><em class="mm">机器。</em></p><figure class="kf kg kh ki fq ku fe ff paragraph-image"><div class="fe ff ol"><img src="../Images/6731be425cba907d40f01bcc6fc01815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*2ljebpygwLlW0UWOeWY33w.jpeg"/></div><figcaption class="og oh fg fe ff oi oj bd b be z ek">Stream Flow</figcaption></figure></div><div class="ab cl mq mr hc ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hn ho hp hq hr"><h1 id="e813" class="mx kp hu bd kx my mz na lb nb nc nd lf ne nf ng li nh ni nj ll nk nl nm lo nn dt translated">GPU数据结构</h1><p id="3279" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated"><strong class="je hv"><em class="mm">GPU计算实现了哪些数据结构？为什么以及何时使用它们？</em> </strong></p><h2 id="9b4d" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">通常</h2><p id="711d" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">各种数据结构可以在GPU上表示:</p><ul class=""><li id="d56e" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb om mb mc md dt translated"><strong class="je hv">密集阵列</strong></li><li id="2ebd" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated"><strong class="je hv">稀疏矩阵</strong>(稀疏阵列)【静态或动态】</li><li id="7c8f" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated"><strong class="je hv">自适应结构</strong>(联合型)</li></ul><h2 id="a1ad" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated"><strong class="ak">英伟达GPU架构</strong></h2><h2 id="c6a8" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated"><strong class="ak"> 1。多维数组</strong></h2><p id="4108" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">当前的GPU仅提供2D光栅化和2D帧缓冲。即当前的GPU不支持具有超过4096个元素的1D纹理。</p><p id="c653" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">因此，当前的GPU可以表示包含多达16，777，216 (4，096×4，096)个元素的1D数组，因为每次从片段或顶点程序访问这个打包的数组时，1D地址都被转换为2D坐标。</p><p id="79bb" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">而三维数组可以以两种方式之一存储:</p><ul class=""><li id="5936" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb om mb mc md dt translated"><em class="mm"> 3D纹理，每个切片存储在单独的2D纹理中</em></li></ul><figure class="kf kg kh ki fq ku fe ff paragraph-image"><div class="fe ff on"><img src="../Images/fa333e40dce6f47128400128a28b0a1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*kmc1RnCErOpoyS2CGOl1cQ.jpeg"/></div><figcaption class="og oh fg fe ff oi oj bd b be z ek">Storing a 3D Texture with Separate 2D Slices</figcaption></figure><ul class=""><li id="cd19" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb om mb mc md dt translated"><em class="mm">打包成单个2D纹理(Harris等人，2003年，Lefohn等人，2003年，Goodnight等人，2003年)</em></li></ul><figure class="kf kg kh ki fq ku fe ff paragraph-image"><div class="fe ff oo"><img src="../Images/8af400e486ea52006238904dfa27c2b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*-aufDVcr5mG9LnStkQaHJA.jpeg"/></div><figcaption class="og oh fg fe ff oi oj bd b be z ek">3D Arrays Flattened into a Single 2D Texture</figcaption></figure><p id="1df6" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">更高维的数组可以用一种通用的形式打包成2D纹理<em class="mm">(巴克等人2004) </em>。</p><h2 id="fd1e" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">2.结构</h2><p id="a19f" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">“结构流”必须被定义为“流的结构”。在这个构造中，为每个结构成员创建一个单独的流。此外，这些结构包含的数据可能不会超过GPU对每个片段输出的数据。这些限制是由于片段程序不能指定它们的帧缓冲结果被写入的地址(也就是说，它们不能执行<em class="mm">分散</em>操作)。通过将结构指定为“流的结构”，每个结构成员具有相同的流索引，因此所有成员可以由单个片段程序更新。</p><h2 id="694c" class="ko kp hu bd kx ky kz la lb lc ld le lf jn lg lh li jr lj lk ll jv lm ln lo lp dt translated">3.稀疏数据结构</h2><p id="6f52" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">阵列和结构是<em class="mm">密集</em>结构。换句话说，数组地址空间中的所有元素都包含有效数据。然而，有许多问题需要稀疏的数据结构(如列表、树或稀疏矩阵)才能有效解决。稀疏数据结构是许多基于CPU的优化算法的重要组成部分；使用密集数据结构的强力GPU实现通常比优化的CPU实现要慢。此外，稀疏数据结构可以减少算法的内存需求——鉴于可用GPU内存量有限，这是一个重要的考虑因素。</p><p id="a73e" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated"><strong class="je hv"> 3.1静态稀疏结构:</strong>在这些结构中，稀疏元素的位置和数量在整个GPU计算中是固定的。例如，光线跟踪场景中三角形的位置和数量不会改变。因为这些结构是静态的，所以它们不必写入计算出的内存地址。</p><p id="5343" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">所有这些结构都使用一个或多个间接层来表示内存中的稀疏结构。例如，Purcell的光线加速结构从三角形列表指针的规则3D网格开始。3D网格纹理包含一个指针，指向该网格单元的三角形列表(存储在第二个纹理中)的起点。三角形列表中的每个条目又包含指向存储在第三个纹理中的顶点数据的指针。类似地，稀疏矩阵结构使用固定数量的间接层来寻找非零矩阵元素。</p><figure class="kf kg kh ki fq ku fe ff paragraph-image"><div class="fe ff op"><img src="../Images/79df148c80fd3c71587c0d35bb520d5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*KfqOoBPMZv_Wk3EU_ufcTg.jpeg"/></div><figcaption class="og oh fg fe ff oi oj bd b be z ek">Purcell’s Sparse Ray-Tracing Data Structure</figcaption></figure><p id="f2c3" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated"><strong class="je hv"> 3.2动态稀疏结构:</strong>在GPU计算期间更新的基于GPU的稀疏数据结构是一个活跃的研究领域。两个值得注意的例子是Purcell等人2003年中的<em class="mm">光子图和Lefohn等人2003年、2004年</em>中的<em class="mm">可变形隐式表面表示。</em></p><p id="c860" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">光子贴图是一种稀疏的自适应数据结构。Purcell等人(2003)描述了一个完全基于GPU的光子贴图渲染器。为了在GPU上创建光子图，他们设计了两种方案来将数据写入当前GPU上计算的内存地址(即<em class="mm">分散</em>)</p><ol class=""><li id="6a15" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb ma mb mc md dt translated">计算内存地址和存储在这些地址的数据。然后，它通过对这些缓冲区执行数据并行排序操作来执行分散。</li><li id="9da8" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated"><em class="mm">模板布线</em>，使用顶点处理器在计算出的内存地址定义的位置绘制大点。如果你想详细研究这个，这里是<a class="ae ke" href="http://developer.download.nvidia.com/presentations/2007/siggraph/stencil_routed_a-Buffer_sigg07.ppt" rel="noopener ugc nofollow" target="_blank">链接</a>。</li></ol><blockquote class="mj mk ml"><p id="92e4" class="jc jd mm je b jf jz jh ji jj ka jl jm mn kb jp jq mo kc jt ju mp kd jx jy jb hn dt translated">另一种基于GPU的动态稀疏数据结构是Lefohn等人(2003，2004)用于隐式表面变形的稀疏体结构。</p></blockquote><p id="3ad0" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">该系统的一个关键组件是GPU请求CPU分配或释放图块的方式。总之，当GPU数据结构需要更新时，这种动态稀疏数据结构通过向CPU发送小消息来解决需要分散功能的问题。该结构使用有效的阻塞策略，原因如下:</p><ol class=""><li id="74f9" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb ma mb mc md dt translated">通过使用压缩的位向量消息格式，GPU-CPU通信的数量被最小化。</li><li id="6a58" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">CPU仅充当内存管理器，让GPU执行所有“繁重”的计算。请注意，在整个变形过程中，隐式曲面数据仅驻留在GPU上。</li><li id="0307" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb ma mb mc md dt translated">动态稀疏表示使得计算和存储器需求能够随隐式表面的表面积而不是其边界框的体积而缩放。这是一个重要的优化，如果忽略这一点，基于CPU的实现将很容易超过GPU版本。</li></ol></div><div class="ab cl mq mr hc ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hn ho hp hq hr"><h1 id="e7a4" class="mx kp hu bd kx my mz na lb nb nc nd lf ne nf ng li nh ni nj ll nk nl nm lo nn dt translated">库达</h1><p id="9a0c" class="pw-post-body-paragraph jc jd hu je b jf lq jh ji jj lr jl jm jn ls jp jq jr lt jt ju jv lu jx jy jb hn dt translated">CUDA是NVIDIA发明的并行计算平台和编程模型。它通过利用图形处理单元(GPU)的能力，大幅提高了计算性能。</p><p id="16cc" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">CUDA 8.0附带了以下库:</p><ul class=""><li id="5a43" class="lv lw hu je b jf jz jj ka jn lx jr ly jv lz jb om mb mc md dt translated">CUBLAS — CUDA基本线性代数子程序库</li><li id="94ae" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">CUDART — CUDA运行时库</li><li id="27f9" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">CUFFT — CUDA快速傅立叶变换库</li><li id="6879" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">CURAND — CUDA随机数生成库</li><li id="4bdb" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">CUSOLVER —基于CUDA的密集和稀疏直接解算器集合</li><li id="36ed" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">CUSPARSE — CUDA稀疏矩阵库</li><li id="e384" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">NPP — NVIDIA性能原语库</li><li id="01c0" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">NVGRAPH — NVIDIA图形分析库</li><li id="c26f" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">NVML — NVIDIA管理库</li><li id="b660" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">NVRTC —用于CUDA C++的NVRTC运行时编译库</li></ul></div><div class="ab cl mq mr hc ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hn ho hp hq hr"><h1 id="1db5" class="mx kp hu bd kx my mz na lb nb nc nd lf ne nf ng li nh ni nj ll nk nl nm lo nn dt translated">结论</h1><ul class=""><li id="ea6c" class="lv lw hu je b jf lq jj lr jn oq jr or jv os jb om mb mc md dt translated">计算世界正在发生范式转变。</li><li id="ea48" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">这种转变主要是当前水平的深度学习成为可能的原因。</li><li id="b39f" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">对越来越有效的计算方法的渴望只会增加。</li><li id="75da" class="lv lw hu je b jf me jj mf jn mg jr mh jv mi jb om mb mc md dt translated">对GPU计算的投资正呈指数增长，因为GPU做同样的工作只需要CPU成本的一小部分。</li></ul><p id="ba37" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">这个博客有最少的数学。如果你想详细研究有效的计算方法，那么罗伯特·a·范·德·盖因的《编程矩阵计算的科学》</p><p id="9c60" class="pw-post-body-paragraph jc jd hu je b jf jz jh ji jj ka jl jm jn kb jp jq jr kc jt ju jv kd jx jy jb hn dt translated">要阅读更多关于NVIDIA GPU的信息，这个<a class="ae ke" href="http://http.developer.nvidia.com/GPUGems2/gpugems2_part01.html" rel="noopener ugc nofollow" target="_blank">链接</a>会很有帮助。关于CUDA的详细信息，这是<a class="ae ke" href="http://docs.nvidia.com/cuda/index.html#axzz4SbuzU6I7" rel="noopener ugc nofollow" target="_blank">索引链接</a>。</p><figure class="kf kg kh ki fq ku"><div class="bz el l di"><div class="ot kw l"/></div></figure></div></div>    
</body>
</html>