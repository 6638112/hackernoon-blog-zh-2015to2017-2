# 大卫 vs 歌利亚:为什么小数据能赢

> 原文：<https://medium.com/hackernoon/david-vs-goliath-why-small-data-can-win-d7d5e1d9fe2b>

一家价值 10 亿美元的公司的工程负责人要求候选人告诉他他们遇到的数据规模。我听说有个工程师被拒绝了，因为“他只处理过千兆字节的数据，而不是兆兆字节的数据”。作为一名工程师和企业家，我通过专门研究这种规模来谋生。我曾就如何对万亿字节的数据运行算法向公司提供建议，这些天我看到[大数据](https://hackernoon.com/tagged/big-data)是必要的，公司似乎认为数据的大小与其能够产生的价值成比例。

因此，公司实际上忽略了不大的数据。工程师对处理小数据不感兴趣，因为基础设施在技术上并不具有挑战性。数据科学家忽略小数据，因为运行简单的回归听起来不如使用深度学习算法令人印象深刻。业务主管不使用小数据，因为他们希望通过处理与规模和管理大数据团队相关的复杂性来获得可信度。所以，每个人都忽略了小数据。

然而，这是因为内部偏见，推理与业务成果完全无关。事实上，我认为数据集的规模和它所能产生的洞察力之间几乎没有关联。你的数据不大不代表没用。我们一直在使用小数据，直到 2010 年代，Hadoop 和大数据成为主流。早在大数据和分布式计算时代之前，统计学就已经存在了。您可以继续使用算法和可视化从小数据中挖掘有价值的见解。

小数据不仅有用，而且更容易处理。虽然这是工程师和数据科学家忽略它的原因，但这也是小数据有价值的部分原因。您可以轻松提取信息，而无需围绕数据分析建立大型团队。您不需要使用像 Apache Spark 这样的分布式计算引擎，也不需要花费数百万从供应商那里购买分布式数据解决方案。你也不需要雇佣在深度学习方面有专长的博士

令人惊讶的是，一些处理大量数据的公司很难使用他们的小数据。我清楚地记得，当我的一个客户的营销分析师抱怨说，“我所有的数据都躺在这个庞大的基础设施中的某个地方，我需要请数据工程师为我运行 Hadoop 工作，而我只想下载一个 CSV 并使用 Excel。”那么，如何从小数据中获取价值呢？

首先，认识到您已经拥有小数据，并且不需要新的基础架构、计划或新员工来从您的小数据中获取价值—有一些简单的方法来最大化其价值。记住古老的原则:“保持简单，笨蛋。”

接下来，再次开始使用描述性分析。这包括总结，“切片和切块”，列表和其他探索技术。并不是每一项分析都需要底层人工智能模型的支持。当数据集足够小时，这些点可以被可视化。人眼被低估；一旦数据被绘制出来，通常就可以看到模式。

第三，清理数据。较小的数据集更容易出现错误、缺失值和噪声。如果数据集足够小，您可以手动移除明显的差异。诚然，这种手动方法不会在大数据级别扩展，但大多数在更大规模上工作的模型通过正则化或其他方法解决了这些问题。

最后，远离复杂的机器学习模型。随着公司建立基础设施来支持数万亿个数据点并开发深度学习模型，他们发现这些构造不适用于较小的数据集。例如，很容易使他们的模型过度适应数据。这种过度拟合使得模型更加敏感，尤其是对测量误差。问问自己是否可以使用更简单的模型，如逻辑/线性回归来分析数据集。

我不是唯一一个称赞小数据的人，小数据现在正重新成为人们关注的焦点。斯坦福大学在 2017 年秋季开设了一门名为[“小”数据](https://web.stanford.edu/class/msande226/)的课程，马丁·林德斯特罗姆写了一本关于公司如何通过更小的观察而不是完全依赖大数据来创造优质产品和服务的书。林德斯特罗姆在书中宣称，“我们这个时代最大的 100 项创新中，大约 60%到 65%都是基于小数据的。”甚至传统上基于大数据的技术也可能利用小数据。Alphabet 执行董事长 Eric Schmidt，[表示](https://twitter.com/ericschmidt/status/920409378121011200)人工智能可能会迎来小数据时代，因为更智能的系统可以通过更少的训练学习更多。并非我们所有人都有大数据，但我们都有小数据，而且我们现在就可以轻松使用它。